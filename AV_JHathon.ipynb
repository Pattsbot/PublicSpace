{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AV-JHathon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N9KfLRXl29y"
      },
      "source": [
        "# **Health Insurance Lead Prediction**\r\n",
        "\r\n",
        "Your Client FinMan is a financial services company that provides various \r\n",
        "\r\n",
        "financial services like loan, investment funds, insurance etc. to its customers. FinMan wishes to cross-sell health insurance to the existing customers who may or may not hold insurance policies with the company. The company recommend health insurance to it's customers based on their profile once these customers land on the website. Customers might browse the recommended health insurance policy and consequently fill up a form to apply. When these customers fill-up the form, their Response towards the policy is considered positive and they are classified as a lead.\r\n",
        "\r\n",
        "Once these leads are acquired, the sales advisors approach them to convert and thus the company can sell proposed health insurance to these leads in a more efficient manner.\r\n",
        "\r\n",
        "Now the company needs your help in building a model to predict whether the person will be interested in their proposed Health plan/policy given the information about:\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "> Demographics (city, age, region etc.)\r\n",
        "\r\n",
        "> Information regarding holding policies of the customer\r\n",
        "\r\n",
        "> Recommended Policy Information\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDnHt74joZa8"
      },
      "source": [
        "# **Data Dictionary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSBc-kvqo9Ip"
      },
      "source": [
        "**Train Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byIJGVuhuuBZ"
      },
      "source": [
        "![picture](https://drive.google.com/file/d/1nOAJrHnJBteW8fteUYP4kg2V5Cb7Ztch/view?usp=sharing)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAMsc6tqrw90"
      },
      "source": [
        "**Test Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avwA3XKfuwyW"
      },
      "source": [
        "![picture](https://drive.google.com/file/d/1QXp2ds_mp8g93fCk8Bf2srJEMqro-sLz/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcvgwfKhsFqc"
      },
      "source": [
        "**Sample Submission**\r\n",
        "\r\n",
        "This file contains the exact submission format for the predictions. Please submit CSV file only.\r\n",
        "\r\n",
        "![picture](https://drive.google.com/file/d/1RHfQCoRbhoCAuQIk2qzOZvHrXieKabGe/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imsMGxbVsLWu"
      },
      "source": [
        "## **Evaluation**\r\n",
        "\r\n",
        "The evaluation metric for this competition is roc_auc_score across all entries in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKiPZkKZr1vc",
        "outputId": "8dd818be-cf61-479c-ec4c-302b45481f6f"
      },
      "source": [
        "# Authenticate Google colab to import files from drive\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "P8OoB9ZxwIHV",
        "outputId": "ce937f1b-3132-4899-dc35-99ad5bcd789f"
      },
      "source": [
        "#Upload the files from local here .rar format or .zip format -clean.rar\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "uploaded = files.upload()\r\n",
        "\r\n",
        "for fn in uploaded.keys():\r\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\r\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-18cec603-7779-4a1a-81bc-973ac4e83e99\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-18cec603-7779-4a1a-81bc-973ac4e83e99\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sample_submission_QrCyCoT.csv to sample_submission_QrCyCoT.csv\n",
            "Saving test_YCcRUnU.csv to test_YCcRUnU.csv\n",
            "Saving train_Df64byy.csv to train_Df64byy.csv\n",
            "User uploaded file \"sample_submission_QrCyCoT.csv\" with length 174452 bytes\n",
            "User uploaded file \"test_YCcRUnU.csv\" with length 1268506 bytes\n",
            "User uploaded file \"train_Df64byy.csv\" with length 3049673 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QeCnTKqwUhC"
      },
      "source": [
        "# import standard libraries\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhSKGM7o12zM"
      },
      "source": [
        "# import all the related libraries\r\n",
        "\r\n",
        "from sklearn.preprocessing import LabelEncoder,StandardScaler,MinMaxScaler\r\n",
        "from sklearn.metrics import precision_recall_curve\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold,cross_val_score,cross_val_predict\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "import xgboost as xgb\r\n",
        "import lightgbm as lgb\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.model_selection import RandomizedSearchCV,KFold\r\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8g3gdHV17hp",
        "outputId": "9007742c-e3d4-4d29-f0a7-c544e8c3040a"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/3b/bb419654adcf7efff42ed8a3f84e50c8f236424b7ed1cc8ccd290852e003/catboost-0.24.4-cp37-none-manylinux1_x86_64.whl (65.7MB)\n",
            "\u001b[K     |████████████████████████████████| 65.7MB 64kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85p79PYQ2wYU"
      },
      "source": [
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoCss9G322ge"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfndY7bH3OIl"
      },
      "source": [
        "# Read the data files - Training, Test and Submition sample  data\r\n",
        "\r\n",
        "train = pd.read_csv('/content/train_Df64byy.csv')\r\n",
        "\r\n",
        "test  = pd.read_csv('/content/test_YCcRUnU.csv')\r\n",
        "\r\n",
        "subm = pd.read_csv('/content/sample_submission_QrCyCoT.csv')\r\n"
      ],
      "execution_count": 364,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSI2zWnU50R7",
        "outputId": "3c40bd4b-935f-43db-fdd9-b4194adfd520"
      },
      "source": [
        "train.shape,test.shape,subm.shape"
      ],
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50882, 14), (21805, 13), (21805, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "Li6mSDSR3YWU",
        "outputId": "f6405d07-c39a-4d92-b991-32bf8201ac6f"
      },
      "source": [
        "# Train details\r\n",
        "\r\n",
        "train.head()"
      ],
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>City_Code</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Accomodation_Type</th>\n",
              "      <th>Reco_Insurance_Type</th>\n",
              "      <th>Upper_Age</th>\n",
              "      <th>Lower_Age</th>\n",
              "      <th>Is_Spouse</th>\n",
              "      <th>Health Indicator</th>\n",
              "      <th>Holding_Policy_Duration</th>\n",
              "      <th>Holding_Policy_Type</th>\n",
              "      <th>Reco_Policy_Cat</th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "      <th>Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>C3</td>\n",
              "      <td>3213</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>No</td>\n",
              "      <td>X1</td>\n",
              "      <td>14+</td>\n",
              "      <td>3.0</td>\n",
              "      <td>22</td>\n",
              "      <td>11628.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>C5</td>\n",
              "      <td>1117</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Joint</td>\n",
              "      <td>75</td>\n",
              "      <td>22</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22</td>\n",
              "      <td>30510.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>C5</td>\n",
              "      <td>3732</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19</td>\n",
              "      <td>7450.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>C24</td>\n",
              "      <td>4378</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Joint</td>\n",
              "      <td>52</td>\n",
              "      <td>48</td>\n",
              "      <td>No</td>\n",
              "      <td>X1</td>\n",
              "      <td>14+</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19</td>\n",
              "      <td>17780.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>C8</td>\n",
              "      <td>2190</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>10404.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID City_Code  Region_Code  ... Reco_Policy_Cat Reco_Policy_Premium  Response\n",
              "0   1        C3         3213  ...              22             11628.0         0\n",
              "1   2        C5         1117  ...              22             30510.0         0\n",
              "2   3        C5         3732  ...              19              7450.0         1\n",
              "3   4       C24         4378  ...              19             17780.0         0\n",
              "4   5        C8         2190  ...              16             10404.0         0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDeojQArL9O2",
        "outputId": "7528891f-2dfd-451f-e9cd-87217c953cde"
      },
      "source": [
        "train[train.Response==1]['Accomodation_Type'].value_counts(),train[train.Response==0]['Accomodation_Type'].value_counts()"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Owned     6763\n",
              " Rented    5446\n",
              " Name: Accomodation_Type, dtype: int64, Owned     21188\n",
              " Rented    17485\n",
              " Name: Accomodation_Type, dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyJ6OnRpUK-a",
        "outputId": "ac303fe6-9a5a-43fc-c1c8-af3fbce7ce49"
      },
      "source": [
        "train[train.Response==1]['Reco_Insurance_Type'].value_counts(),train[train.Response==0]['Reco_Insurance_Type'].value_counts()"
      ],
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Individual    9640\n",
              " Joint         2569\n",
              " Name: Reco_Insurance_Type, dtype: int64, Individual    30896\n",
              " Joint          7777\n",
              " Name: Reco_Insurance_Type, dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_s97cgiWZjZ",
        "outputId": "41368bf8-2c1b-4cfe-c161-d19e59f16652"
      },
      "source": [
        "_IO = 6763 / (6763+ 5446) * ( 9640 / (9640+2569)) # Individual Owned who opted for Insurance\r\n",
        "\r\n",
        "_IR = 5446 / (6763+ 5446) * ( 9640 / (9640+2569)) # Individual Rented who opted for Insurance\r\n",
        "\r\n",
        "_JO = 6763 / (6763+ 5446) * ( 2569 / (9640+2569)) # Joint and Owned who opted for Insurance\r\n",
        "\r\n",
        "_JR =  5446 / (6763+ 5446) * ( 2569 / (9640+2569)) # Joint and Rented who opted for Insurance\r\n",
        "\r\n",
        "_IO,_IR,_IO,_IR\r\n"
      ],
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.43737729453479773,\n",
              " 0.3522041617679297,\n",
              " 0.43737729453479773,\n",
              " 0.3522041617679297)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sivv4kic4NHE",
        "outputId": "ab4a8976-5390-4552-e8d2-548318585855"
      },
      "source": [
        "train.dtypes  # check the data types categorical and continuous variables"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                           int64\n",
              "City_Code                   object\n",
              "Region_Code                  int64\n",
              "Accomodation_Type           object\n",
              "Reco_Insurance_Type         object\n",
              "Upper_Age                    int64\n",
              "Lower_Age                    int64\n",
              "Is_Spouse                   object\n",
              "Health Indicator            object\n",
              "Holding_Policy_Duration     object\n",
              "Holding_Policy_Type        float64\n",
              "Reco_Policy_Cat              int64\n",
              "Reco_Policy_Premium        float64\n",
              "Response                     int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDgHQwKp5YjA",
        "outputId": "9f5642d2-c0b0-403f-9d6e-17582c418fe5"
      },
      "source": [
        "train.isnull().sum() / train.shape[0]  # % of NAN in the data"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                         0.000000\n",
              "City_Code                  0.000000\n",
              "Region_Code                0.000000\n",
              "Accomodation_Type          0.000000\n",
              "Reco_Insurance_Type        0.000000\n",
              "Upper_Age                  0.000000\n",
              "Lower_Age                  0.000000\n",
              "Is_Spouse                  0.000000\n",
              "Health Indicator           0.229767\n",
              "Holding_Policy_Duration    0.397999\n",
              "Holding_Policy_Type        0.397999\n",
              "Reco_Policy_Cat            0.000000\n",
              "Reco_Policy_Premium        0.000000\n",
              "Response                   0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "DZIo0EZogAs6",
        "outputId": "3782db3f-b2db-4517-c140-857e9b08c68d"
      },
      "source": [
        "train[train['Holding_Policy_Duration'].isna()]"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>City_Code</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Accomodation_Type</th>\n",
              "      <th>Reco_Insurance_Type</th>\n",
              "      <th>Upper_Age</th>\n",
              "      <th>Lower_Age</th>\n",
              "      <th>Is_Spouse</th>\n",
              "      <th>Health Indicator</th>\n",
              "      <th>Holding_Policy_Duration</th>\n",
              "      <th>Holding_Policy_Type</th>\n",
              "      <th>Reco_Policy_Cat</th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "      <th>Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>C5</td>\n",
              "      <td>1117</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Joint</td>\n",
              "      <td>75</td>\n",
              "      <td>22</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22</td>\n",
              "      <td>30510.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>C3</td>\n",
              "      <td>679</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>10640.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>C28</td>\n",
              "      <td>600</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21</td>\n",
              "      <td>4068.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>C5</td>\n",
              "      <td>900</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18</td>\n",
              "      <td>8364.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>C3</td>\n",
              "      <td>1484</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>No</td>\n",
              "      <td>X3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>4912.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50863</th>\n",
              "      <td>50864</td>\n",
              "      <td>C1</td>\n",
              "      <td>3705</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>No</td>\n",
              "      <td>X3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50864</th>\n",
              "      <td>50865</td>\n",
              "      <td>C27</td>\n",
              "      <td>3469</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>72</td>\n",
              "      <td>72</td>\n",
              "      <td>No</td>\n",
              "      <td>X4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>17312.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50865</th>\n",
              "      <td>50866</td>\n",
              "      <td>C21</td>\n",
              "      <td>4915</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>74</td>\n",
              "      <td>74</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14</td>\n",
              "      <td>19944.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50867</th>\n",
              "      <td>50868</td>\n",
              "      <td>C6</td>\n",
              "      <td>2040</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20</td>\n",
              "      <td>10016.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50877</th>\n",
              "      <td>50878</td>\n",
              "      <td>C4</td>\n",
              "      <td>845</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>No</td>\n",
              "      <td>X3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18</td>\n",
              "      <td>7704.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20251 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID City_Code  ...  Reco_Policy_Premium Response\n",
              "1          2        C5  ...              30510.0        0\n",
              "6          7        C3  ...              10640.0        0\n",
              "10        11       C28  ...               4068.0        1\n",
              "13        14        C5  ...               8364.0        0\n",
              "15        16        C3  ...               4912.0        0\n",
              "...      ...       ...  ...                  ...      ...\n",
              "50863  50864        C1  ...              17850.0        1\n",
              "50864  50865       C27  ...              17312.0        0\n",
              "50865  50866       C21  ...              19944.0        0\n",
              "50867  50868        C6  ...              10016.0        0\n",
              "50877  50878        C4  ...               7704.0        0\n",
              "\n",
              "[20251 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "KChKfsp-hMgR",
        "outputId": "8557a5ad-e29c-4ebc-9328-bf82e711da75"
      },
      "source": [
        "train[train['Response'] == 1]"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>City_Code</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Accomodation_Type</th>\n",
              "      <th>Reco_Insurance_Type</th>\n",
              "      <th>Upper_Age</th>\n",
              "      <th>Lower_Age</th>\n",
              "      <th>Is_Spouse</th>\n",
              "      <th>Health Indicator</th>\n",
              "      <th>Holding_Policy_Duration</th>\n",
              "      <th>Holding_Policy_Type</th>\n",
              "      <th>Reco_Policy_Cat</th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "      <th>Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>C5</td>\n",
              "      <td>3732</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19</td>\n",
              "      <td>7450.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>C9</td>\n",
              "      <td>1785</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22</td>\n",
              "      <td>15264.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>C1</td>\n",
              "      <td>3175</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Joint</td>\n",
              "      <td>75</td>\n",
              "      <td>73</td>\n",
              "      <td>Yes</td>\n",
              "      <td>X4</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17</td>\n",
              "      <td>29344.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>C1</td>\n",
              "      <td>530</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Joint</td>\n",
              "      <td>59</td>\n",
              "      <td>26</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18</td>\n",
              "      <td>21100.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>C28</td>\n",
              "      <td>600</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21</td>\n",
              "      <td>4068.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50858</th>\n",
              "      <td>50859</td>\n",
              "      <td>C1</td>\n",
              "      <td>494</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Joint</td>\n",
              "      <td>62</td>\n",
              "      <td>29</td>\n",
              "      <td>Yes</td>\n",
              "      <td>X1</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18</td>\n",
              "      <td>24323.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50863</th>\n",
              "      <td>50864</td>\n",
              "      <td>C1</td>\n",
              "      <td>3705</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>No</td>\n",
              "      <td>X3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868</th>\n",
              "      <td>50869</td>\n",
              "      <td>C1</td>\n",
              "      <td>2327</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>No</td>\n",
              "      <td>X3</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18</td>\n",
              "      <td>22066.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50875</th>\n",
              "      <td>50876</td>\n",
              "      <td>C6</td>\n",
              "      <td>231</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>No</td>\n",
              "      <td>X3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20</td>\n",
              "      <td>13574.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50880</th>\n",
              "      <td>50881</td>\n",
              "      <td>C1</td>\n",
              "      <td>4</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Joint</td>\n",
              "      <td>71</td>\n",
              "      <td>49</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16</td>\n",
              "      <td>28179.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12209 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID City_Code  ...  Reco_Policy_Premium Response\n",
              "2          3        C5  ...               7450.0        1\n",
              "5          6        C9  ...              15264.0        1\n",
              "7          8        C1  ...              29344.0        1\n",
              "9         10        C1  ...              21100.8        1\n",
              "10        11       C28  ...               4068.0        1\n",
              "...      ...       ...  ...                  ...      ...\n",
              "50858  50859        C1  ...              24323.2        1\n",
              "50863  50864        C1  ...              17850.0        1\n",
              "50868  50869        C1  ...              22066.0        1\n",
              "50875  50876        C6  ...              13574.0        1\n",
              "50880  50881        C1  ...              28179.2        1\n",
              "\n",
              "[12209 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "_98QEC1XhbGa",
        "outputId": "9cea1271-9d5a-4135-bab9-b693628be26a"
      },
      "source": [
        "train[train['Response'] == 0]"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>City_Code</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Accomodation_Type</th>\n",
              "      <th>Reco_Insurance_Type</th>\n",
              "      <th>Upper_Age</th>\n",
              "      <th>Lower_Age</th>\n",
              "      <th>Is_Spouse</th>\n",
              "      <th>Health Indicator</th>\n",
              "      <th>Holding_Policy_Duration</th>\n",
              "      <th>Holding_Policy_Type</th>\n",
              "      <th>Reco_Policy_Cat</th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "      <th>Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>C3</td>\n",
              "      <td>3213</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>No</td>\n",
              "      <td>X1</td>\n",
              "      <td>14+</td>\n",
              "      <td>3.0</td>\n",
              "      <td>22</td>\n",
              "      <td>11628.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>C5</td>\n",
              "      <td>1117</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Joint</td>\n",
              "      <td>75</td>\n",
              "      <td>22</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22</td>\n",
              "      <td>30510.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>C24</td>\n",
              "      <td>4378</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Joint</td>\n",
              "      <td>52</td>\n",
              "      <td>48</td>\n",
              "      <td>No</td>\n",
              "      <td>X1</td>\n",
              "      <td>14+</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19</td>\n",
              "      <td>17780.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>C8</td>\n",
              "      <td>2190</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>10404.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>C3</td>\n",
              "      <td>679</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>10640.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50876</th>\n",
              "      <td>50877</td>\n",
              "      <td>C26</td>\n",
              "      <td>579</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12</td>\n",
              "      <td>13222.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50877</th>\n",
              "      <td>50878</td>\n",
              "      <td>C4</td>\n",
              "      <td>845</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>No</td>\n",
              "      <td>X3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18</td>\n",
              "      <td>7704.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50878</th>\n",
              "      <td>50879</td>\n",
              "      <td>C5</td>\n",
              "      <td>4188</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>No</td>\n",
              "      <td>X3</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>5408.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50879</th>\n",
              "      <td>50880</td>\n",
              "      <td>C1</td>\n",
              "      <td>442</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>14+</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12</td>\n",
              "      <td>11374.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50881</th>\n",
              "      <td>50882</td>\n",
              "      <td>C3</td>\n",
              "      <td>3866</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>No</td>\n",
              "      <td>X3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18</td>\n",
              "      <td>11424.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38673 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID City_Code  ...  Reco_Policy_Premium Response\n",
              "0          1        C3  ...              11628.0        0\n",
              "1          2        C5  ...              30510.0        0\n",
              "3          4       C24  ...              17780.0        0\n",
              "4          5        C8  ...              10404.0        0\n",
              "6          7        C3  ...              10640.0        0\n",
              "...      ...       ...  ...                  ...      ...\n",
              "50876  50877       C26  ...              13222.0        0\n",
              "50877  50878        C4  ...               7704.0        0\n",
              "50878  50879        C5  ...               5408.0        0\n",
              "50879  50880        C1  ...              11374.0        0\n",
              "50881  50882        C3  ...              11424.0        0\n",
              "\n",
              "[38673 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuVqqg5PD5kC",
        "outputId": "b3bce962-857f-4491-b10b-402d7b401e7d"
      },
      "source": [
        "train['Reco_Policy_Premium'].min(),train['Reco_Policy_Premium'].max()"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2280.0, 43350.4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJXgofzCETYM",
        "outputId": "32923065-1f94-409d-c1dc-519c146bf69e"
      },
      "source": [
        "train[train.Response == 1]['Reco_Policy_Premium'].min(),train[train.Response == 1]['Reco_Policy_Premium'].max()"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2408.0, 42316.8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9lj55M4GT6v",
        "outputId": "7354b039-6f29-4254-9f7b-79320a6c6aa2"
      },
      "source": [
        "test.dtypes"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                           int64\n",
              "City_Code                   object\n",
              "Region_Code                  int64\n",
              "Accomodation_Type           object\n",
              "Reco_Insurance_Type         object\n",
              "Upper_Age                    int64\n",
              "Lower_Age                    int64\n",
              "Is_Spouse                   object\n",
              "Health Indicator            object\n",
              "Holding_Policy_Duration     object\n",
              "Holding_Policy_Type        float64\n",
              "Reco_Policy_Cat              int64\n",
              "Reco_Policy_Premium        float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDq549sSGXAu",
        "outputId": "b7c43ebd-9abc-4e8e-bf42-e2920cfedeee"
      },
      "source": [
        "test.isnull().sum() / test.shape[0]"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                         0.000000\n",
              "City_Code                  0.000000\n",
              "Region_Code                0.000000\n",
              "Accomodation_Type          0.000000\n",
              "Reco_Insurance_Type        0.000000\n",
              "Upper_Age                  0.000000\n",
              "Lower_Age                  0.000000\n",
              "Is_Spouse                  0.000000\n",
              "Health Indicator           0.230543\n",
              "Holding_Policy_Duration    0.394543\n",
              "Holding_Policy_Type        0.394543\n",
              "Reco_Policy_Cat            0.000000\n",
              "Reco_Policy_Premium        0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbUo9BrB5n6q",
        "outputId": "f21dd990-21e9-4d3b-f4d8-88d05fb04b20"
      },
      "source": [
        "# exploration of train data set\r\n",
        "\r\n",
        "train.City_Code.nunique(),train.Region_Code.nunique(),train.Accomodation_Type .nunique(),train.Reco_Insurance_Type.nunique()"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 5316, 2, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMMb0IhG6QwY",
        "outputId": "9a787520-74cf-4413-b0e9-2b1d8351cc89"
      },
      "source": [
        "train['Health Indicator'].unique()"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['X1', 'X2', nan, 'X4', 'X3', 'X6', 'X5', 'X8', 'X7', 'X9'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3SNDanm8oCo",
        "outputId": "41a4106b-f6cd-4bbd-a00c-8b45e4b1d33b"
      },
      "source": [
        "train['Holding_Policy_Duration'].unique()"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['14+', nan, '1.0', '3.0', '5.0', '9.0', '14.0', '7.0', '2.0',\n",
              "       '11.0', '10.0', '8.0', '6.0', '4.0', '13.0', '12.0'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-6RSbQE_cJ5",
        "outputId": "20ae12ae-fadf-4301-f368-bedf1d46f32a"
      },
      "source": [
        "train['Reco_Policy_Cat'].unique()"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22, 19, 16, 17,  1, 18, 21, 13, 20,  9,  2,  4, 12,  6, 14, 11,  3,\n",
              "        8,  7, 10, 15,  5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gRMIOnl-ecN"
      },
      "source": [
        "new_data = { \"14+\":\"15\",\"1.0\":\"1\",\"2.0\":\"2\",\"3.0\":\"3\",\"4.0\":\"4\",\"5.0\":\"5\",\r\n",
        "             \"6.0\":\"6\",\"7.0\":\"7\",\"8.0\":\"8\",\"9.0\" :\"9\",\"10.0\":\"10\",\"11.0\":\"11\",\r\n",
        "             \"12.0\":\"12\",\"13.0\":\"13\",\"14.0\":\"14\" } \r\n",
        "  \r\n",
        "# combine this new data with existing DataFrame \r\n",
        "train[\"Holding_Policy_Duration_YRS\"] = (train[\"Holding_Policy_Duration\"].map(new_data))\r\n",
        "train['Holding_Policy_Duration_YRS'] = train['Holding_Policy_Duration_YRS'].fillna('20')\r\n",
        "train['Holding_Policy_Duration_YRS'] = train['Holding_Policy_Duration_YRS'].astype(int)\r\n",
        "\r\n",
        "test[\"Holding_Policy_Duration_YRS\"] = (test[\"Holding_Policy_Duration\"].map(new_data))\r\n",
        "test['Holding_Policy_Duration_YRS'] = test['Holding_Policy_Duration_YRS'].fillna('20')\r\n",
        "test['Holding_Policy_Duration_YRS'] = test['Holding_Policy_Duration_YRS'].astype(int)"
      ],
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgp6piVLBjmq",
        "outputId": "c228ff3b-bfb2-4cb4-c832-fc53418f6086"
      },
      "source": [
        "train.dtypes"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                               int64\n",
              "City_Code                       object\n",
              "Region_Code                      int64\n",
              "Accomodation_Type               object\n",
              "Reco_Insurance_Type             object\n",
              "Upper_Age                        int64\n",
              "Lower_Age                        int64\n",
              "Is_Spouse                       object\n",
              "Health Indicator                object\n",
              "Holding_Policy_Duration         object\n",
              "Holding_Policy_Type            float64\n",
              "Reco_Policy_Cat                  int64\n",
              "Reco_Policy_Premium            float64\n",
              "Response                         int64\n",
              "Holding_Policy_Duration_YRS      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf2L_Emv8zpt",
        "outputId": "4396929d-34c2-43ef-8c64-e2ed80f43c6b"
      },
      "source": [
        "train['Holding_Policy_Type'].unique()"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3., nan,  1.,  4.,  2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WbQfhELGiS8",
        "outputId": "2071cae3-198c-4018-a74a-d7d3f8a9b262"
      },
      "source": [
        "test['Health Indicator'].unique()"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan, 'X1', 'X3', 'X2', 'X5', 'X4', 'X7', 'X6', 'X9', 'X8'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR8lAjjDGicp",
        "outputId": "96af33ea-1b65-4a1f-849d-3498bedac903"
      },
      "source": [
        "test['Holding_Policy_Duration'].unique()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['6.0', '3.0', '2.0', nan, '14+', '5.0', '1.0', '4.0', '12.0',\n",
              "       '11.0', '7.0', '9.0', '13.0', '8.0', '14.0', '10.0'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WOa6tBMGimx",
        "outputId": "832adaed-dbff-4baf-eecf-69a8ca1c23e4"
      },
      "source": [
        "test['Holding_Policy_Type'].unique()"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.,  4., nan,  1.,  2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su1FWkE5hKar"
      },
      "source": [
        "## Some Bssic Exploratory Data Ananlysis and plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "crWgRj5088b8",
        "outputId": "e3447fb0-c309-4b5b-96d8-b11f493d2f3e"
      },
      "source": [
        "sns.barplot(train['Health Indicator'],train['Response'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f00380ac910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "BX7L3QXA9aaS",
        "outputId": "98361ed0-7859-4088-b640-834c002a5e24"
      },
      "source": [
        "# impute new category X10 for all the missing values of Health Indicator\r\n",
        "train['Health Indicator'] = train['Health Indicator'].fillna('X10')\r\n",
        "sns.barplot(train['Health Indicator'],train['Response'])"
      ],
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fef6c924310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 368
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "dgebHFzI99Kb",
        "outputId": "1b60836c-caad-442b-eab0-4eea87a3fc68"
      },
      "source": [
        "sns.barplot(train['Holding_Policy_Duration'],train['Response'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7feb6e5595d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "ZiioK7gM-diM",
        "outputId": "79abf409-1a1b-46e3-c919-236344b6c60e"
      },
      "source": [
        "# impute new category X10 for all the missing values of Health Indicator\r\n",
        "train['Holding_Policy_Duration'] = train['Holding_Policy_Duration'].fillna('20+')\r\n",
        "sns.barplot(train['Holding_Policy_Duration'],train['Response'])"
      ],
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fef61886050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 369
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "Jj3G2GpC_SGM",
        "outputId": "f98513c8-5558-4003-c9d4-e63fe8fcea7c"
      },
      "source": [
        "sns.barplot(train['Holding_Policy_Type'],train['Response'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7feb6e397d50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "1cbT0LXg_q21",
        "outputId": "34456f6a-a582-45f8-e6e2-6a611b1da298"
      },
      "source": [
        "# impute new category X10 for all the missing values of Health Indicator\r\n",
        "train['Holding_Policy_Type'] = train['Holding_Policy_Type'].fillna(0)\r\n",
        "sns.barplot(train['Holding_Policy_Type'],train['Response'])"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fef617f0110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 370
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "HppFZtqlA-Gk",
        "outputId": "dcb17a65-0e52-456f-f934-d522dbdffd0c"
      },
      "source": [
        "# Label encoding the categorical columns\r\n",
        "\r\n",
        "le = LabelEncoder()\r\n",
        "\r\n",
        "train['City_Code']                 = le.fit_transform(train['City_Code'])\r\n",
        "train['Accomodation_Type']         = le.fit_transform(train['Accomodation_Type'])\r\n",
        "train['Reco_Insurance_Type']       = le.fit_transform(train['Reco_Insurance_Type'])\r\n",
        "train['Is_Spouse']                 = le.fit_transform(train['Is_Spouse'])\r\n",
        "train['Health Indicator']          = le.fit_transform(train['Health Indicator'])\r\n",
        "#train['Holding_Policy_Duration']   = le.fit_transform(train['Holding_Policy_Duration'])\r\n",
        "\r\n",
        "train.head()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>City_Code</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Accomodation_Type</th>\n",
              "      <th>Reco_Insurance_Type</th>\n",
              "      <th>Upper_Age</th>\n",
              "      <th>Lower_Age</th>\n",
              "      <th>Is_Spouse</th>\n",
              "      <th>Health Indicator</th>\n",
              "      <th>Holding_Policy_Duration</th>\n",
              "      <th>Holding_Policy_Type</th>\n",
              "      <th>Reco_Policy_Cat</th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "      <th>Response</th>\n",
              "      <th>Holding_Policy_Duration_YRS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>3213</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14+</td>\n",
              "      <td>3.0</td>\n",
              "      <td>22</td>\n",
              "      <td>11628.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>31</td>\n",
              "      <td>1117</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>75</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22</td>\n",
              "      <td>30510.0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "      <td>3732</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19</td>\n",
              "      <td>7450.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>4378</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14+</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19</td>\n",
              "      <td>17780.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>34</td>\n",
              "      <td>2190</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>10404.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  City_Code  ...  Response  Holding_Policy_Duration_YRS\n",
              "0   1         22  ...         0                           15\n",
              "1   2         31  ...         0                           20\n",
              "2   3         31  ...         1                            1\n",
              "3   4         16  ...         0                           15\n",
              "4   5         34  ...         0                            3\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlC_NcdYcDrf"
      },
      "source": [
        "#train = train.drop(columns=['Holding_Policy_Duration'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqOtSyzcYklh",
        "outputId": "6211736b-cc50-4e48-b960-be992bbfeceb"
      },
      "source": [
        "train['Holding_Policy_Duration'].unique()"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['14+', '20+', '1.0', '3.0', '5.0', '9.0', '14.0', '7.0', '2.0',\n",
              "       '11.0', '10.0', '8.0', '6.0', '4.0', '13.0', '12.0'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6xE15Yc4_R4",
        "outputId": "76ff80ab-f793-44dc-b1d7-28360d3474ee"
      },
      "source": [
        "train['Holding_Policy_Type'].unique()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3., 0., 1., 4., 2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "rSirMVwe5LI7",
        "outputId": "b4f807e5-3a8d-4f41-ec39-bde75a4ac264"
      },
      "source": [
        "sns.countplot(train.Response,hue=train.Holding_Policy_Type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f003793ac10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "S1DS0FYz59k0",
        "outputId": "6fb663ba-3c40-4793-b574-cd7c86bf23eb"
      },
      "source": [
        "sns.countplot(train.Response,hue=train['Health Indicator'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f00376c7910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "cz3EAwCv6gLl",
        "outputId": "96ea9941-9858-4f6e-8d08-63aace852bc4"
      },
      "source": [
        "sns.countplot(train['Health Indicator'],hue=train.Response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0037579f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "NDsFUxhq7Gnp",
        "outputId": "7c0e4ac0-6489-4962-e4be-cf59c974736e"
      },
      "source": [
        "sns.countplot(train.Holding_Policy_Type,hue=train.Response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0037832610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "vte6Si9D_7tZ",
        "outputId": "07ac91d1-7067-4bb3-c37d-d271724aa6ca"
      },
      "source": [
        "sns.countplot(train['Reco_Policy_Cat'],hue=train.Response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0037347590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "SHThvYCT7-41",
        "outputId": "e8940645-247e-497c-9fe5-847b7f2d3a19"
      },
      "source": [
        "train.groupby('Response').count()"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>City_Code</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Accomodation_Type</th>\n",
              "      <th>Reco_Insurance_Type</th>\n",
              "      <th>Upper_Age</th>\n",
              "      <th>Lower_Age</th>\n",
              "      <th>Is_Spouse</th>\n",
              "      <th>Health Indicator</th>\n",
              "      <th>Holding_Policy_Duration</th>\n",
              "      <th>Holding_Policy_Type</th>\n",
              "      <th>Reco_Policy_Cat</th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "      <th>Holding_Policy_Duration_YRS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Response</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "      <td>38673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "      <td>12209</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID  City_Code  ...  Reco_Policy_Premium  Holding_Policy_Duration_YRS\n",
              "Response                    ...                                                  \n",
              "0         38673      38673  ...                38673                        38673\n",
              "1         12209      12209  ...                12209                        12209\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3dNqha4HXA1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "396c05de-024e-469e-9462-13af565631b4"
      },
      "source": [
        "# Total number of cases  of Premium availed by the policy holders in  ( city wise) TRAIN\r\n",
        "\r\n",
        "dfcr = train[['City_Code','Region_Code','Reco_Policy_Premium']]\r\n",
        "dfcr_0 = dfcr.groupby(['City_Code','Region_Code']).count()\r\n",
        "dfcr_0"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>City_Code</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">C1</th>\n",
              "      <th>4</th>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">C9</th>\n",
              "      <th>5891</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5909</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5922</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6092</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5316 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Reco_Policy_Premium\n",
              "City_Code Region_Code                     \n",
              "C1        4                             73\n",
              "          5                             75\n",
              "          6                             73\n",
              "          8                             64\n",
              "          15                            54\n",
              "...                                    ...\n",
              "C9        5891                           1\n",
              "          5909                           1\n",
              "          5922                           1\n",
              "          6092                           1\n",
              "          6123                           1\n",
              "\n",
              "[5316 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vgwk-JalVpZ"
      },
      "source": [
        "# Total number of cases  of Premium availed by the policy holders in  ( city wise) TEST\r\n",
        "\r\n",
        "dfcrT = test[['City_Code','Region_Code','Reco_Policy_Premium']]\r\n",
        "dfcrT_0 = dfcrT.groupby(['City_Code','Region_Code']).count()"
      ],
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "OP7aQgq-QnH7",
        "outputId": "dbf496ca-0cb8-4348-8ca1-0d64589d8a79"
      },
      "source": [
        "dfcr_0"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>City_Code</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">C1</th>\n",
              "      <th>4</th>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">C9</th>\n",
              "      <th>5891</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5909</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5922</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6092</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5316 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Reco_Policy_Premium\n",
              "City_Code Region_Code                     \n",
              "C1        4                             73\n",
              "          5                             75\n",
              "          6                             73\n",
              "          8                             64\n",
              "          15                            54\n",
              "...                                    ...\n",
              "C9        5891                           1\n",
              "          5909                           1\n",
              "          5922                           1\n",
              "          6092                           1\n",
              "          6123                           1\n",
              "\n",
              "[5316 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "o_OPnMvoQnTA",
        "outputId": "c0511818-5cee-4773-d54f-b1ac4f450d7e"
      },
      "source": [
        "dfcrT_0"
      ],
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>City_Code</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">C1</th>\n",
              "      <th>4</th>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">C9</th>\n",
              "      <th>5477</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5587</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6078</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6084</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6089</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4694 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Reco_Policy_Premium\n",
              "City_Code Region_Code                     \n",
              "C1        4                             29\n",
              "          5                             30\n",
              "          6                             29\n",
              "          8                             28\n",
              "          15                            26\n",
              "...                                    ...\n",
              "C9        5477                           1\n",
              "          5587                           1\n",
              "          6078                           1\n",
              "          6084                           1\n",
              "          6089                           1\n",
              "\n",
              "[4694 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcQX2ASWfYuT",
        "outputId": "9cb0483f-c13a-4620-ecd2-f6d88f759d11"
      },
      "source": [
        "try:\r\n",
        "    x = dfcr_1.loc[6,3497]\r\n",
        "    print(int(x.values))\r\n",
        "except KeyError:\r\n",
        "    x = 0\r\n",
        "    print(x)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6YxAJXxROfW"
      },
      "source": [
        "def _optedPolicy(row) :\r\n",
        "  try:\r\n",
        "    x = dfcr_0.loc[row.City_Code,row.Region_Code].values\r\n",
        "    return(int(x))\r\n",
        "  except KeyError:\r\n",
        "    x = 0\r\n",
        "    return x\r\n",
        "\r\n",
        "def _optedPolicyT(row) :\r\n",
        "  try:\r\n",
        "    x = dfcrT_0.loc[row.City_Code,row.Region_Code].values\r\n",
        "    return(int(x))\r\n",
        "  except KeyError:\r\n",
        "    x = 0\r\n",
        "    return x\r\n",
        " "
      ],
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5LAD270QxWa"
      },
      "source": [
        "train['Total_Policy_Cases'] = train[['City_Code','Region_Code']].apply(lambda row : _optedPolicy(row),axis=1)  # No of cases who opted for policy from this city /region"
      ],
      "execution_count": 376,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIL_xjkvkwRI"
      },
      "source": [
        "test['Total_Policy_Cases'] = test[['City_Code','Region_Code']].apply(lambda row : _optedPolicyT(row),axis=1)   # No of cases who did not opt for policy from this city /region"
      ],
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "MSRyPmTYkfh8",
        "outputId": "98c60442-7aa3-4441-d4d1-2aac02b39ffb"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>City_Code</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Accomodation_Type</th>\n",
              "      <th>Reco_Insurance_Type</th>\n",
              "      <th>Upper_Age</th>\n",
              "      <th>Lower_Age</th>\n",
              "      <th>Is_Spouse</th>\n",
              "      <th>Health Indicator</th>\n",
              "      <th>Holding_Policy_Duration</th>\n",
              "      <th>Holding_Policy_Type</th>\n",
              "      <th>Reco_Policy_Cat</th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "      <th>Response</th>\n",
              "      <th>Holding_Policy_Duration_YRS</th>\n",
              "      <th>Total_Policy_Cases</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>C3</td>\n",
              "      <td>3213</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>No</td>\n",
              "      <td>X1</td>\n",
              "      <td>14+</td>\n",
              "      <td>3.0</td>\n",
              "      <td>22</td>\n",
              "      <td>11628.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>C5</td>\n",
              "      <td>1117</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Joint</td>\n",
              "      <td>75</td>\n",
              "      <td>22</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>20+</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22</td>\n",
              "      <td>30510.0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>C5</td>\n",
              "      <td>3732</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Individual</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>No</td>\n",
              "      <td>X10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19</td>\n",
              "      <td>7450.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>C24</td>\n",
              "      <td>4378</td>\n",
              "      <td>Owned</td>\n",
              "      <td>Joint</td>\n",
              "      <td>52</td>\n",
              "      <td>48</td>\n",
              "      <td>No</td>\n",
              "      <td>X1</td>\n",
              "      <td>14+</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19</td>\n",
              "      <td>17780.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>C8</td>\n",
              "      <td>2190</td>\n",
              "      <td>Rented</td>\n",
              "      <td>Individual</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>No</td>\n",
              "      <td>X2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>10404.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID City_Code  ...  Holding_Policy_Duration_YRS Total_Policy_Cases\n",
              "0   1        C3  ...                           15                  8\n",
              "1   2        C5  ...                           20                 17\n",
              "2   3        C5  ...                            1                  7\n",
              "3   4       C24  ...                           15                  5\n",
              "4   5        C8  ...                            3                 11\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvCnBRga2bTz"
      },
      "source": [
        "# New Feature Engineering\r\n",
        "\r\n",
        "# Insurance coverge period in years = UpperAge - LowerAge\r\n",
        "\r\n",
        "train['Insurance_Cover_yrs'] = (train['Upper_Age'] - train['Lower_Age']) +1\r\n",
        "test['Insurance_Cover_yrs']  = (test['Upper_Age']  - test['Lower_Age']) +1\r\n",
        "\r\n"
      ],
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLOxEVRQDjyD"
      },
      "source": [
        "# Total Insurance Amount Payable \r\n",
        "\r\n",
        "train['Total_Insurance_Payable'] = (train['Holding_Policy_Duration_YRS'] * train['Reco_Policy_Premium']) \r\n",
        "test['Total_Insurance_Payable']  = (test['Holding_Policy_Duration_YRS'] * test['Reco_Policy_Premium']) \r\n",
        "\r\n",
        "# Total Insurance Amount Fraction \r\n",
        "train['Total_Insurance_Payable_FR'] = train['Reco_Policy_Premium'] / train['Holding_Policy_Duration_YRS']\r\n",
        "test['Total_Insurance_Payable_FR']  = test['Reco_Policy_Premium'] / test['Holding_Policy_Duration_YRS']\r\n"
      ],
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwAWv1XLHV6x"
      },
      "source": [
        "train = pd.get_dummies(train)  # One Hot Encoding of Categorical variables"
      ],
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtiIsmucUM4v",
        "outputId": "05bb3fb9-b2b4-4942-847c-9cd616fe20cd"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50882, 81)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 381
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Kf3QS3H22b5A",
        "outputId": "571e0364-df47-4236-d72e-3ab3950dfac8"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Upper_Age</th>\n",
              "      <th>Lower_Age</th>\n",
              "      <th>Holding_Policy_Type</th>\n",
              "      <th>Reco_Policy_Cat</th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "      <th>Response</th>\n",
              "      <th>Holding_Policy_Duration_YRS</th>\n",
              "      <th>Total_Policy_Cases</th>\n",
              "      <th>Insurance_Cover_yrs</th>\n",
              "      <th>Total_Insurance_Payable</th>\n",
              "      <th>Total_Insurance_Payable_FR</th>\n",
              "      <th>City_Code_C1</th>\n",
              "      <th>City_Code_C10</th>\n",
              "      <th>City_Code_C11</th>\n",
              "      <th>City_Code_C12</th>\n",
              "      <th>City_Code_C13</th>\n",
              "      <th>City_Code_C14</th>\n",
              "      <th>City_Code_C15</th>\n",
              "      <th>City_Code_C16</th>\n",
              "      <th>City_Code_C17</th>\n",
              "      <th>City_Code_C18</th>\n",
              "      <th>City_Code_C19</th>\n",
              "      <th>City_Code_C2</th>\n",
              "      <th>City_Code_C20</th>\n",
              "      <th>City_Code_C21</th>\n",
              "      <th>City_Code_C22</th>\n",
              "      <th>City_Code_C23</th>\n",
              "      <th>City_Code_C24</th>\n",
              "      <th>City_Code_C25</th>\n",
              "      <th>City_Code_C26</th>\n",
              "      <th>City_Code_C27</th>\n",
              "      <th>City_Code_C28</th>\n",
              "      <th>City_Code_C29</th>\n",
              "      <th>City_Code_C3</th>\n",
              "      <th>City_Code_C30</th>\n",
              "      <th>City_Code_C31</th>\n",
              "      <th>City_Code_C32</th>\n",
              "      <th>City_Code_C33</th>\n",
              "      <th>...</th>\n",
              "      <th>City_Code_C35</th>\n",
              "      <th>City_Code_C36</th>\n",
              "      <th>City_Code_C4</th>\n",
              "      <th>City_Code_C5</th>\n",
              "      <th>City_Code_C6</th>\n",
              "      <th>City_Code_C7</th>\n",
              "      <th>City_Code_C8</th>\n",
              "      <th>City_Code_C9</th>\n",
              "      <th>Accomodation_Type_Owned</th>\n",
              "      <th>Accomodation_Type_Rented</th>\n",
              "      <th>Reco_Insurance_Type_Individual</th>\n",
              "      <th>Reco_Insurance_Type_Joint</th>\n",
              "      <th>Is_Spouse_No</th>\n",
              "      <th>Is_Spouse_Yes</th>\n",
              "      <th>Health Indicator_X1</th>\n",
              "      <th>Health Indicator_X10</th>\n",
              "      <th>Health Indicator_X2</th>\n",
              "      <th>Health Indicator_X3</th>\n",
              "      <th>Health Indicator_X4</th>\n",
              "      <th>Health Indicator_X5</th>\n",
              "      <th>Health Indicator_X6</th>\n",
              "      <th>Health Indicator_X7</th>\n",
              "      <th>Health Indicator_X8</th>\n",
              "      <th>Health Indicator_X9</th>\n",
              "      <th>Holding_Policy_Duration_1.0</th>\n",
              "      <th>Holding_Policy_Duration_10.0</th>\n",
              "      <th>Holding_Policy_Duration_11.0</th>\n",
              "      <th>Holding_Policy_Duration_12.0</th>\n",
              "      <th>Holding_Policy_Duration_13.0</th>\n",
              "      <th>Holding_Policy_Duration_14+</th>\n",
              "      <th>Holding_Policy_Duration_14.0</th>\n",
              "      <th>Holding_Policy_Duration_2.0</th>\n",
              "      <th>Holding_Policy_Duration_20+</th>\n",
              "      <th>Holding_Policy_Duration_3.0</th>\n",
              "      <th>Holding_Policy_Duration_4.0</th>\n",
              "      <th>Holding_Policy_Duration_5.0</th>\n",
              "      <th>Holding_Policy_Duration_6.0</th>\n",
              "      <th>Holding_Policy_Duration_7.0</th>\n",
              "      <th>Holding_Policy_Duration_8.0</th>\n",
              "      <th>Holding_Policy_Duration_9.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3213</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>3.0</td>\n",
              "      <td>22</td>\n",
              "      <td>11628.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>174420.0</td>\n",
              "      <td>775.200000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1117</td>\n",
              "      <td>75</td>\n",
              "      <td>22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22</td>\n",
              "      <td>30510.0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>54</td>\n",
              "      <td>610200.0</td>\n",
              "      <td>1525.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3732</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19</td>\n",
              "      <td>7450.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7450.0</td>\n",
              "      <td>7450.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4378</td>\n",
              "      <td>52</td>\n",
              "      <td>48</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19</td>\n",
              "      <td>17780.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>266700.0</td>\n",
              "      <td>1185.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2190</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>10404.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>31212.0</td>\n",
              "      <td>3468.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  Region_Code  ...  Holding_Policy_Duration_8.0  Holding_Policy_Duration_9.0\n",
              "0   1         3213  ...                            0                            0\n",
              "1   2         1117  ...                            0                            0\n",
              "2   3         3732  ...                            0                            0\n",
              "3   4         4378  ...                            0                            0\n",
              "4   5         2190  ...                            0                            0\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "WYUUKf1a2caZ",
        "outputId": "68ba78d2-9e6b-42e9-9ed2-386c031654f2"
      },
      "source": [
        "train[train.Response ==0]"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Upper_Age</th>\n",
              "      <th>Lower_Age</th>\n",
              "      <th>Holding_Policy_Type</th>\n",
              "      <th>Reco_Policy_Cat</th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "      <th>Response</th>\n",
              "      <th>Holding_Policy_Duration_YRS</th>\n",
              "      <th>Total_Policy_Cases</th>\n",
              "      <th>Insurance_Cover_yrs</th>\n",
              "      <th>Total_Insurance_Payable</th>\n",
              "      <th>Total_Insurance_Payable_FR</th>\n",
              "      <th>City_Code_C1</th>\n",
              "      <th>City_Code_C10</th>\n",
              "      <th>City_Code_C11</th>\n",
              "      <th>City_Code_C12</th>\n",
              "      <th>City_Code_C13</th>\n",
              "      <th>City_Code_C14</th>\n",
              "      <th>City_Code_C15</th>\n",
              "      <th>City_Code_C16</th>\n",
              "      <th>City_Code_C17</th>\n",
              "      <th>City_Code_C18</th>\n",
              "      <th>City_Code_C19</th>\n",
              "      <th>City_Code_C2</th>\n",
              "      <th>City_Code_C20</th>\n",
              "      <th>City_Code_C21</th>\n",
              "      <th>City_Code_C22</th>\n",
              "      <th>City_Code_C23</th>\n",
              "      <th>City_Code_C24</th>\n",
              "      <th>City_Code_C25</th>\n",
              "      <th>City_Code_C26</th>\n",
              "      <th>City_Code_C27</th>\n",
              "      <th>City_Code_C28</th>\n",
              "      <th>City_Code_C29</th>\n",
              "      <th>City_Code_C3</th>\n",
              "      <th>City_Code_C30</th>\n",
              "      <th>City_Code_C31</th>\n",
              "      <th>City_Code_C32</th>\n",
              "      <th>City_Code_C33</th>\n",
              "      <th>...</th>\n",
              "      <th>City_Code_C35</th>\n",
              "      <th>City_Code_C36</th>\n",
              "      <th>City_Code_C4</th>\n",
              "      <th>City_Code_C5</th>\n",
              "      <th>City_Code_C6</th>\n",
              "      <th>City_Code_C7</th>\n",
              "      <th>City_Code_C8</th>\n",
              "      <th>City_Code_C9</th>\n",
              "      <th>Accomodation_Type_Owned</th>\n",
              "      <th>Accomodation_Type_Rented</th>\n",
              "      <th>Reco_Insurance_Type_Individual</th>\n",
              "      <th>Reco_Insurance_Type_Joint</th>\n",
              "      <th>Is_Spouse_No</th>\n",
              "      <th>Is_Spouse_Yes</th>\n",
              "      <th>Health Indicator_X1</th>\n",
              "      <th>Health Indicator_X10</th>\n",
              "      <th>Health Indicator_X2</th>\n",
              "      <th>Health Indicator_X3</th>\n",
              "      <th>Health Indicator_X4</th>\n",
              "      <th>Health Indicator_X5</th>\n",
              "      <th>Health Indicator_X6</th>\n",
              "      <th>Health Indicator_X7</th>\n",
              "      <th>Health Indicator_X8</th>\n",
              "      <th>Health Indicator_X9</th>\n",
              "      <th>Holding_Policy_Duration_1.0</th>\n",
              "      <th>Holding_Policy_Duration_10.0</th>\n",
              "      <th>Holding_Policy_Duration_11.0</th>\n",
              "      <th>Holding_Policy_Duration_12.0</th>\n",
              "      <th>Holding_Policy_Duration_13.0</th>\n",
              "      <th>Holding_Policy_Duration_14+</th>\n",
              "      <th>Holding_Policy_Duration_14.0</th>\n",
              "      <th>Holding_Policy_Duration_2.0</th>\n",
              "      <th>Holding_Policy_Duration_20+</th>\n",
              "      <th>Holding_Policy_Duration_3.0</th>\n",
              "      <th>Holding_Policy_Duration_4.0</th>\n",
              "      <th>Holding_Policy_Duration_5.0</th>\n",
              "      <th>Holding_Policy_Duration_6.0</th>\n",
              "      <th>Holding_Policy_Duration_7.0</th>\n",
              "      <th>Holding_Policy_Duration_8.0</th>\n",
              "      <th>Holding_Policy_Duration_9.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3213</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>3.0</td>\n",
              "      <td>22</td>\n",
              "      <td>11628.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>174420.0</td>\n",
              "      <td>775.200000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1117</td>\n",
              "      <td>75</td>\n",
              "      <td>22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22</td>\n",
              "      <td>30510.0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>54</td>\n",
              "      <td>610200.0</td>\n",
              "      <td>1525.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4378</td>\n",
              "      <td>52</td>\n",
              "      <td>48</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19</td>\n",
              "      <td>17780.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>266700.0</td>\n",
              "      <td>1185.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2190</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>10404.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>31212.0</td>\n",
              "      <td>3468.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>679</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17</td>\n",
              "      <td>10640.0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>212800.0</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50876</th>\n",
              "      <td>50877</td>\n",
              "      <td>579</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12</td>\n",
              "      <td>13222.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>26444.0</td>\n",
              "      <td>6611.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50877</th>\n",
              "      <td>50878</td>\n",
              "      <td>845</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18</td>\n",
              "      <td>7704.0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>154080.0</td>\n",
              "      <td>385.200000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50878</th>\n",
              "      <td>50879</td>\n",
              "      <td>4188</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>5408.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>37856.0</td>\n",
              "      <td>772.571429</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50879</th>\n",
              "      <td>50880</td>\n",
              "      <td>442</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12</td>\n",
              "      <td>11374.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>170610.0</td>\n",
              "      <td>758.266667</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50881</th>\n",
              "      <td>50882</td>\n",
              "      <td>3866</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18</td>\n",
              "      <td>11424.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>22848.0</td>\n",
              "      <td>5712.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38673 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  ...  Holding_Policy_Duration_9.0\n",
              "0          1  ...                            0\n",
              "1          2  ...                            0\n",
              "3          4  ...                            0\n",
              "4          5  ...                            0\n",
              "6          7  ...                            0\n",
              "...      ...  ...                          ...\n",
              "50876  50877  ...                            0\n",
              "50877  50878  ...                            0\n",
              "50878  50879  ...                            0\n",
              "50879  50880  ...                            0\n",
              "50881  50882  ...                            0\n",
              "\n",
              "[38673 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "Usufd0nUS1NF",
        "outputId": "1e9fcc83-fa6f-4237-9f98-f7e3939b9d07"
      },
      "source": [
        "train[train.Response ==1]"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Upper_Age</th>\n",
              "      <th>Lower_Age</th>\n",
              "      <th>Holding_Policy_Type</th>\n",
              "      <th>Reco_Policy_Cat</th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "      <th>Response</th>\n",
              "      <th>Holding_Policy_Duration_YRS</th>\n",
              "      <th>Total_Policy_Cases</th>\n",
              "      <th>Insurance_Cover_yrs</th>\n",
              "      <th>Total_Insurance_Payable</th>\n",
              "      <th>Total_Insurance_Payable_FR</th>\n",
              "      <th>City_Code_C1</th>\n",
              "      <th>City_Code_C10</th>\n",
              "      <th>City_Code_C11</th>\n",
              "      <th>City_Code_C12</th>\n",
              "      <th>City_Code_C13</th>\n",
              "      <th>City_Code_C14</th>\n",
              "      <th>City_Code_C15</th>\n",
              "      <th>City_Code_C16</th>\n",
              "      <th>City_Code_C17</th>\n",
              "      <th>City_Code_C18</th>\n",
              "      <th>City_Code_C19</th>\n",
              "      <th>City_Code_C2</th>\n",
              "      <th>City_Code_C20</th>\n",
              "      <th>City_Code_C21</th>\n",
              "      <th>City_Code_C22</th>\n",
              "      <th>City_Code_C23</th>\n",
              "      <th>City_Code_C24</th>\n",
              "      <th>City_Code_C25</th>\n",
              "      <th>City_Code_C26</th>\n",
              "      <th>City_Code_C27</th>\n",
              "      <th>City_Code_C28</th>\n",
              "      <th>City_Code_C29</th>\n",
              "      <th>City_Code_C3</th>\n",
              "      <th>City_Code_C30</th>\n",
              "      <th>City_Code_C31</th>\n",
              "      <th>City_Code_C32</th>\n",
              "      <th>City_Code_C33</th>\n",
              "      <th>...</th>\n",
              "      <th>City_Code_C35</th>\n",
              "      <th>City_Code_C36</th>\n",
              "      <th>City_Code_C4</th>\n",
              "      <th>City_Code_C5</th>\n",
              "      <th>City_Code_C6</th>\n",
              "      <th>City_Code_C7</th>\n",
              "      <th>City_Code_C8</th>\n",
              "      <th>City_Code_C9</th>\n",
              "      <th>Accomodation_Type_Owned</th>\n",
              "      <th>Accomodation_Type_Rented</th>\n",
              "      <th>Reco_Insurance_Type_Individual</th>\n",
              "      <th>Reco_Insurance_Type_Joint</th>\n",
              "      <th>Is_Spouse_No</th>\n",
              "      <th>Is_Spouse_Yes</th>\n",
              "      <th>Health Indicator_X1</th>\n",
              "      <th>Health Indicator_X10</th>\n",
              "      <th>Health Indicator_X2</th>\n",
              "      <th>Health Indicator_X3</th>\n",
              "      <th>Health Indicator_X4</th>\n",
              "      <th>Health Indicator_X5</th>\n",
              "      <th>Health Indicator_X6</th>\n",
              "      <th>Health Indicator_X7</th>\n",
              "      <th>Health Indicator_X8</th>\n",
              "      <th>Health Indicator_X9</th>\n",
              "      <th>Holding_Policy_Duration_1.0</th>\n",
              "      <th>Holding_Policy_Duration_10.0</th>\n",
              "      <th>Holding_Policy_Duration_11.0</th>\n",
              "      <th>Holding_Policy_Duration_12.0</th>\n",
              "      <th>Holding_Policy_Duration_13.0</th>\n",
              "      <th>Holding_Policy_Duration_14+</th>\n",
              "      <th>Holding_Policy_Duration_14.0</th>\n",
              "      <th>Holding_Policy_Duration_2.0</th>\n",
              "      <th>Holding_Policy_Duration_20+</th>\n",
              "      <th>Holding_Policy_Duration_3.0</th>\n",
              "      <th>Holding_Policy_Duration_4.0</th>\n",
              "      <th>Holding_Policy_Duration_5.0</th>\n",
              "      <th>Holding_Policy_Duration_6.0</th>\n",
              "      <th>Holding_Policy_Duration_7.0</th>\n",
              "      <th>Holding_Policy_Duration_8.0</th>\n",
              "      <th>Holding_Policy_Duration_9.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3732</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19</td>\n",
              "      <td>7450.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7450.0</td>\n",
              "      <td>7450.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1785</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22</td>\n",
              "      <td>15264.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>76320.0</td>\n",
              "      <td>3052.800000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>3175</td>\n",
              "      <td>75</td>\n",
              "      <td>73</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17</td>\n",
              "      <td>29344.0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>264096.0</td>\n",
              "      <td>3260.444444</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>530</td>\n",
              "      <td>59</td>\n",
              "      <td>26</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18</td>\n",
              "      <td>21100.8</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>34</td>\n",
              "      <td>147705.6</td>\n",
              "      <td>3014.400000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>600</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21</td>\n",
              "      <td>4068.0</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>81360.0</td>\n",
              "      <td>203.400000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50858</th>\n",
              "      <td>50859</td>\n",
              "      <td>494</td>\n",
              "      <td>62</td>\n",
              "      <td>29</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18</td>\n",
              "      <td>24323.2</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>34</td>\n",
              "      <td>316201.6</td>\n",
              "      <td>1871.015385</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50863</th>\n",
              "      <td>50864</td>\n",
              "      <td>3705</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>357000.0</td>\n",
              "      <td>892.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868</th>\n",
              "      <td>50869</td>\n",
              "      <td>2327</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18</td>\n",
              "      <td>22066.0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>198594.0</td>\n",
              "      <td>2451.777778</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50875</th>\n",
              "      <td>50876</td>\n",
              "      <td>231</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20</td>\n",
              "      <td>13574.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>27148.0</td>\n",
              "      <td>6787.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50880</th>\n",
              "      <td>50881</td>\n",
              "      <td>4</td>\n",
              "      <td>71</td>\n",
              "      <td>49</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16</td>\n",
              "      <td>28179.2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>73</td>\n",
              "      <td>23</td>\n",
              "      <td>56358.4</td>\n",
              "      <td>14089.600000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12209 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  ...  Holding_Policy_Duration_9.0\n",
              "2          3  ...                            0\n",
              "5          6  ...                            0\n",
              "7          8  ...                            1\n",
              "9         10  ...                            0\n",
              "10        11  ...                            0\n",
              "...      ...  ...                          ...\n",
              "50858  50859  ...                            0\n",
              "50863  50864  ...                            0\n",
              "50868  50869  ...                            1\n",
              "50875  50876  ...                            0\n",
              "50880  50881  ...                            0\n",
              "\n",
              "[12209 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCRoHRWYCohz",
        "outputId": "254e1355-fc36-4785-ea4d-fbdac6ef4abf"
      },
      "source": [
        "train.isnull().sum()"
      ],
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                             0\n",
              "Region_Code                    0\n",
              "Upper_Age                      0\n",
              "Lower_Age                      0\n",
              "Holding_Policy_Type            0\n",
              "                              ..\n",
              "Holding_Policy_Duration_5.0    0\n",
              "Holding_Policy_Duration_6.0    0\n",
              "Holding_Policy_Duration_7.0    0\n",
              "Holding_Policy_Duration_8.0    0\n",
              "Holding_Policy_Duration_9.0    0\n",
              "Length: 81, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 382
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrAezj9vD9gs"
      },
      "source": [
        "# impute new category X10 for all the missing values of Health Indicator\r\n",
        "test['Health Indicator'] = test['Health Indicator'].fillna('X10')"
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7_3V8LzHc6h"
      },
      "source": [
        "# impute new category 20+ for all the missing values of Holding_Policy_Duration\r\n",
        "test['Holding_Policy_Duration'] = test['Holding_Policy_Duration'].fillna('20+')"
      ],
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4wEL_jtHhMa"
      },
      "source": [
        "# impute new category 0 for all the missing values of Holding_Policy_Type\r\n",
        "test['Holding_Policy_Type'] = test['Holding_Policy_Type'].fillna(0)"
      ],
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "VPxwIAtDITw_",
        "outputId": "59c8124b-80cb-4c9b-8a51-af6dbcda1e0d"
      },
      "source": [
        "# Label encoding the categorical columns\r\n",
        "\r\n",
        "test['City_Code']                 = le.fit_transform(test['City_Code'])\r\n",
        "test['Accomodation_Type']         = le.fit_transform(test['Accomodation_Type'])\r\n",
        "test['Reco_Insurance_Type']       = le.fit_transform(test['Reco_Insurance_Type'])\r\n",
        "test['Is_Spouse']                 = le.fit_transform(test['Is_Spouse'])\r\n",
        "test['Health Indicator']          = le.fit_transform(test['Health Indicator'])\r\n",
        "#test['Holding_Policy_Duration']   = le.fit_transform(test['Holding_Policy_Duration'])\r\n",
        "\r\n",
        "test.head()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>City_Code</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Accomodation_Type</th>\n",
              "      <th>Reco_Insurance_Type</th>\n",
              "      <th>Upper_Age</th>\n",
              "      <th>Lower_Age</th>\n",
              "      <th>Is_Spouse</th>\n",
              "      <th>Health Indicator</th>\n",
              "      <th>Holding_Policy_Duration</th>\n",
              "      <th>Holding_Policy_Type</th>\n",
              "      <th>Reco_Policy_Cat</th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "      <th>Holding_Policy_Duration_YRS</th>\n",
              "      <th>Total_Policy_Cases</th>\n",
              "      <th>Insurance_Cover_yrs</th>\n",
              "      <th>Total_Insurance_Payable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50883</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>11934.0</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>71604.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50884</td>\n",
              "      <td>30</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>69</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18</td>\n",
              "      <td>32204.8</td>\n",
              "      <td>3</td>\n",
              "      <td>35</td>\n",
              "      <td>2</td>\n",
              "      <td>96614.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50885</td>\n",
              "      <td>0</td>\n",
              "      <td>564</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17</td>\n",
              "      <td>9240.0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>18480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50886</td>\n",
              "      <td>22</td>\n",
              "      <td>1177</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18</td>\n",
              "      <td>9086.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>27258.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50887</td>\n",
              "      <td>0</td>\n",
              "      <td>951</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>22534.0</td>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>450680.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID  City_Code  ...  Insurance_Cover_yrs  Total_Insurance_Payable\n",
              "0  50883          0  ...                    1                  71604.0\n",
              "1  50884         30  ...                    2                  96614.4\n",
              "2  50885          0  ...                    1                  18480.0\n",
              "3  50886         22  ...                    1                  27258.0\n",
              "4  50887          0  ...                    1                 450680.0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IF4bGM0UrNB",
        "outputId": "dcde8285-acd6-47bf-905b-50d89201fb9d"
      },
      "source": [
        "test = pd.get_dummies(test)  # One Hot Encoding the test set\r\n",
        "test.shape"
      ],
      "execution_count": 386,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21805, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "x5cvEk_TVFhV",
        "outputId": "87afe1e3-f812-4d49-ae02-bf6294ea4bec"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Upper_Age</th>\n",
              "      <th>Lower_Age</th>\n",
              "      <th>Holding_Policy_Type</th>\n",
              "      <th>Reco_Policy_Cat</th>\n",
              "      <th>Reco_Policy_Premium</th>\n",
              "      <th>Holding_Policy_Duration_YRS</th>\n",
              "      <th>Total_Policy_Cases</th>\n",
              "      <th>Insurance_Cover_yrs</th>\n",
              "      <th>Total_Insurance_Payable</th>\n",
              "      <th>Total_Insurance_Payable_FR</th>\n",
              "      <th>City_Code_C1</th>\n",
              "      <th>City_Code_C10</th>\n",
              "      <th>City_Code_C11</th>\n",
              "      <th>City_Code_C12</th>\n",
              "      <th>City_Code_C13</th>\n",
              "      <th>City_Code_C14</th>\n",
              "      <th>City_Code_C15</th>\n",
              "      <th>City_Code_C16</th>\n",
              "      <th>City_Code_C17</th>\n",
              "      <th>City_Code_C18</th>\n",
              "      <th>City_Code_C19</th>\n",
              "      <th>City_Code_C2</th>\n",
              "      <th>City_Code_C20</th>\n",
              "      <th>City_Code_C21</th>\n",
              "      <th>City_Code_C22</th>\n",
              "      <th>City_Code_C23</th>\n",
              "      <th>City_Code_C24</th>\n",
              "      <th>City_Code_C25</th>\n",
              "      <th>City_Code_C26</th>\n",
              "      <th>City_Code_C27</th>\n",
              "      <th>City_Code_C28</th>\n",
              "      <th>City_Code_C29</th>\n",
              "      <th>City_Code_C3</th>\n",
              "      <th>City_Code_C30</th>\n",
              "      <th>City_Code_C31</th>\n",
              "      <th>City_Code_C32</th>\n",
              "      <th>City_Code_C33</th>\n",
              "      <th>City_Code_C34</th>\n",
              "      <th>City_Code_C35</th>\n",
              "      <th>City_Code_C36</th>\n",
              "      <th>City_Code_C4</th>\n",
              "      <th>City_Code_C5</th>\n",
              "      <th>City_Code_C6</th>\n",
              "      <th>City_Code_C7</th>\n",
              "      <th>City_Code_C8</th>\n",
              "      <th>City_Code_C9</th>\n",
              "      <th>Accomodation_Type_Owned</th>\n",
              "      <th>Accomodation_Type_Rented</th>\n",
              "      <th>Reco_Insurance_Type_Individual</th>\n",
              "      <th>Reco_Insurance_Type_Joint</th>\n",
              "      <th>Is_Spouse_No</th>\n",
              "      <th>Is_Spouse_Yes</th>\n",
              "      <th>Health Indicator_X1</th>\n",
              "      <th>Health Indicator_X10</th>\n",
              "      <th>Health Indicator_X2</th>\n",
              "      <th>Health Indicator_X3</th>\n",
              "      <th>Health Indicator_X4</th>\n",
              "      <th>Health Indicator_X5</th>\n",
              "      <th>Health Indicator_X6</th>\n",
              "      <th>Health Indicator_X7</th>\n",
              "      <th>Health Indicator_X8</th>\n",
              "      <th>Health Indicator_X9</th>\n",
              "      <th>Holding_Policy_Duration_1.0</th>\n",
              "      <th>Holding_Policy_Duration_10.0</th>\n",
              "      <th>Holding_Policy_Duration_11.0</th>\n",
              "      <th>Holding_Policy_Duration_12.0</th>\n",
              "      <th>Holding_Policy_Duration_13.0</th>\n",
              "      <th>Holding_Policy_Duration_14+</th>\n",
              "      <th>Holding_Policy_Duration_14.0</th>\n",
              "      <th>Holding_Policy_Duration_2.0</th>\n",
              "      <th>Holding_Policy_Duration_20+</th>\n",
              "      <th>Holding_Policy_Duration_3.0</th>\n",
              "      <th>Holding_Policy_Duration_4.0</th>\n",
              "      <th>Holding_Policy_Duration_5.0</th>\n",
              "      <th>Holding_Policy_Duration_6.0</th>\n",
              "      <th>Holding_Policy_Duration_7.0</th>\n",
              "      <th>Holding_Policy_Duration_8.0</th>\n",
              "      <th>Holding_Policy_Duration_9.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50883</td>\n",
              "      <td>156</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>11934.0</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>71604.0</td>\n",
              "      <td>1989.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50884</td>\n",
              "      <td>7</td>\n",
              "      <td>69</td>\n",
              "      <td>68</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18</td>\n",
              "      <td>32204.8</td>\n",
              "      <td>3</td>\n",
              "      <td>35</td>\n",
              "      <td>2</td>\n",
              "      <td>96614.4</td>\n",
              "      <td>10734.933333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50885</td>\n",
              "      <td>564</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17</td>\n",
              "      <td>9240.0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>18480.0</td>\n",
              "      <td>4620.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50886</td>\n",
              "      <td>1177</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18</td>\n",
              "      <td>9086.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>27258.0</td>\n",
              "      <td>3028.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50887</td>\n",
              "      <td>951</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>22534.0</td>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>450680.0</td>\n",
              "      <td>1126.700000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID  Region_Code  ...  Holding_Policy_Duration_8.0  Holding_Policy_Duration_9.0\n",
              "0  50883          156  ...                            0                            0\n",
              "1  50884            7  ...                            0                            0\n",
              "2  50885          564  ...                            0                            0\n",
              "3  50886         1177  ...                            0                            0\n",
              "4  50887          951  ...                            0                            0\n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsA2JfjSIx0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7520fb8-7bd7-479f-919f-8458d3b95458"
      },
      "source": [
        "train.columns"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'Region_Code', 'Upper_Age', 'Lower_Age', 'Holding_Policy_Type',\n",
              "       'Reco_Policy_Cat', 'Reco_Policy_Premium', 'Response',\n",
              "       'Holding_Policy_Duration_YRS', 'Total_Policy_Cases',\n",
              "       'Insurance_Cover_yrs', 'Total_Insurance_Payable',\n",
              "       'Total_Insurance_Payable_FR', 'City_Code_C1', 'City_Code_C10',\n",
              "       'City_Code_C11', 'City_Code_C12', 'City_Code_C13', 'City_Code_C14',\n",
              "       'City_Code_C15', 'City_Code_C16', 'City_Code_C17', 'City_Code_C18',\n",
              "       'City_Code_C19', 'City_Code_C2', 'City_Code_C20', 'City_Code_C21',\n",
              "       'City_Code_C22', 'City_Code_C23', 'City_Code_C24', 'City_Code_C25',\n",
              "       'City_Code_C26', 'City_Code_C27', 'City_Code_C28', 'City_Code_C29',\n",
              "       'City_Code_C3', 'City_Code_C30', 'City_Code_C31', 'City_Code_C32',\n",
              "       'City_Code_C33', 'City_Code_C34', 'City_Code_C35', 'City_Code_C36',\n",
              "       'City_Code_C4', 'City_Code_C5', 'City_Code_C6', 'City_Code_C7',\n",
              "       'City_Code_C8', 'City_Code_C9', 'Accomodation_Type_Owned',\n",
              "       'Accomodation_Type_Rented', 'Reco_Insurance_Type_Individual',\n",
              "       'Reco_Insurance_Type_Joint', 'Is_Spouse_No', 'Is_Spouse_Yes',\n",
              "       'Health Indicator_X1', 'Health Indicator_X10', 'Health Indicator_X2',\n",
              "       'Health Indicator_X3', 'Health Indicator_X4', 'Health Indicator_X5',\n",
              "       'Health Indicator_X6', 'Health Indicator_X7', 'Health Indicator_X8',\n",
              "       'Health Indicator_X9', 'Holding_Policy_Duration_1.0',\n",
              "       'Holding_Policy_Duration_10.0', 'Holding_Policy_Duration_11.0',\n",
              "       'Holding_Policy_Duration_12.0', 'Holding_Policy_Duration_13.0',\n",
              "       'Holding_Policy_Duration_14+', 'Holding_Policy_Duration_14.0',\n",
              "       'Holding_Policy_Duration_2.0', 'Holding_Policy_Duration_20+',\n",
              "       'Holding_Policy_Duration_3.0', 'Holding_Policy_Duration_4.0',\n",
              "       'Holding_Policy_Duration_5.0', 'Holding_Policy_Duration_6.0',\n",
              "       'Holding_Policy_Duration_7.0', 'Holding_Policy_Duration_8.0',\n",
              "       'Holding_Policy_Duration_9.0'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 388
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogtF-3IMZvsT",
        "outputId": "e8f59eb4-6184-403f-e94c-88d70a2d6ced"
      },
      "source": [
        "train.columns  # New feature added"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'City_Code', 'Region_Code', 'Accomodation_Type',\n",
              "       'Reco_Insurance_Type', 'Upper_Age', 'Lower_Age', 'Is_Spouse',\n",
              "       'Health Indicator', 'Holding_Policy_Duration', 'Holding_Policy_Type',\n",
              "       'Reco_Policy_Cat', 'Reco_Policy_Premium', 'Response'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfkQtDTrvUbm",
        "outputId": "9eee4bc6-4afa-47d0-e3d6-0297dce8d3e4"
      },
      "source": [
        "test.columns"
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'Region_Code', 'Upper_Age', 'Lower_Age', 'Holding_Policy_Type',\n",
              "       'Reco_Policy_Cat', 'Reco_Policy_Premium', 'Holding_Policy_Duration_YRS',\n",
              "       'Total_Policy_Cases', 'Insurance_Cover_yrs', 'Total_Insurance_Payable',\n",
              "       'Total_Insurance_Payable_FR', 'City_Code_C1', 'City_Code_C10',\n",
              "       'City_Code_C11', 'City_Code_C12', 'City_Code_C13', 'City_Code_C14',\n",
              "       'City_Code_C15', 'City_Code_C16', 'City_Code_C17', 'City_Code_C18',\n",
              "       'City_Code_C19', 'City_Code_C2', 'City_Code_C20', 'City_Code_C21',\n",
              "       'City_Code_C22', 'City_Code_C23', 'City_Code_C24', 'City_Code_C25',\n",
              "       'City_Code_C26', 'City_Code_C27', 'City_Code_C28', 'City_Code_C29',\n",
              "       'City_Code_C3', 'City_Code_C30', 'City_Code_C31', 'City_Code_C32',\n",
              "       'City_Code_C33', 'City_Code_C34', 'City_Code_C35', 'City_Code_C36',\n",
              "       'City_Code_C4', 'City_Code_C5', 'City_Code_C6', 'City_Code_C7',\n",
              "       'City_Code_C8', 'City_Code_C9', 'Accomodation_Type_Owned',\n",
              "       'Accomodation_Type_Rented', 'Reco_Insurance_Type_Individual',\n",
              "       'Reco_Insurance_Type_Joint', 'Is_Spouse_No', 'Is_Spouse_Yes',\n",
              "       'Health Indicator_X1', 'Health Indicator_X10', 'Health Indicator_X2',\n",
              "       'Health Indicator_X3', 'Health Indicator_X4', 'Health Indicator_X5',\n",
              "       'Health Indicator_X6', 'Health Indicator_X7', 'Health Indicator_X8',\n",
              "       'Health Indicator_X9', 'Holding_Policy_Duration_1.0',\n",
              "       'Holding_Policy_Duration_10.0', 'Holding_Policy_Duration_11.0',\n",
              "       'Holding_Policy_Duration_12.0', 'Holding_Policy_Duration_13.0',\n",
              "       'Holding_Policy_Duration_14+', 'Holding_Policy_Duration_14.0',\n",
              "       'Holding_Policy_Duration_2.0', 'Holding_Policy_Duration_20+',\n",
              "       'Holding_Policy_Duration_3.0', 'Holding_Policy_Duration_4.0',\n",
              "       'Holding_Policy_Duration_5.0', 'Holding_Policy_Duration_6.0',\n",
              "       'Holding_Policy_Duration_7.0', 'Holding_Policy_Duration_8.0',\n",
              "       'Holding_Policy_Duration_9.0'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3TqbnHjZ33b",
        "outputId": "96d8d480-02ad-4325-8ea6-de34161394a7"
      },
      "source": [
        "test.columns  # New feature added"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'City_Code', 'Region_Code', 'Accomodation_Type',\n",
              "       'Reco_Insurance_Type', 'Upper_Age', 'Lower_Age', 'Is_Spouse',\n",
              "       'Health Indicator', 'Holding_Policy_Duration', 'Holding_Policy_Type',\n",
              "       'Reco_Policy_Cat', 'Reco_Policy_Premium'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "8c-NV9HuyL-w",
        "outputId": "47dfc18f-e414-4585-ff67-583899a38d63"
      },
      "source": [
        "sns.countplot(train['Response'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7feb778effd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Thot6L6kaLBc",
        "outputId": "7e003b9b-96e0-4360-fa47-f182d236453d"
      },
      "source": [
        "y = train['Response']\r\n",
        "X = train.drop(columns=['ID','Response'])\r\n",
        "Xt = test.drop(columns='ID')\r\n",
        "\r\n",
        "X = np.array(X)\r\n",
        "Xt = np.array(Xt)\r\n",
        "y = np.array(y)\r\n",
        "\r\n",
        "X.shape,y.shape, Xt.shape"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50882, 79), (50882,), (21805, 79))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 390
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h63bYIFmh78"
      },
      "source": [
        "scaler = MinMaxScaler()                       # MInMaxScaler - Normalize the data\r\n",
        "X      = scaler.fit_transform(X)\r\n",
        "Xt = scaler.fit_transform(Xt) "
      ],
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKjIckmairvP"
      },
      "source": [
        "scaler = StandardScaler()                       # StandardScaler - 0 mean and unit variance\r\n",
        "X  = scaler.fit_transform(X)\r\n",
        "Xt = scaler.fit_transform(Xt) "
      ],
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zitbd3zzmnKQ"
      },
      "source": [
        "# KFold Cross Validation\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\r\n",
        "def _kfoldcv(model,X,y,Xt,nsplits,seed=10) :\r\n",
        "\r\n",
        "  kf = StratifiedKFold(n_splits=nsplits,shuffle=True,random_state=seed)\r\n",
        "  pred_test_full =0\r\n",
        "  cv_score =[]\r\n",
        "  i=1  \r\n",
        "\r\n",
        "  for train_index,test_index in kf.split(X,y):\r\n",
        "    print('{} of KFold {}'.format(i,kf.n_splits))\r\n",
        "    xtr,xvl = X[train_index],X[test_index]\r\n",
        "    ytr,yvl = y[train_index],y[test_index]\r\n",
        "    \r\n",
        "    #model\r\n",
        "    clf = model\r\n",
        "    clf.fit(xtr,ytr)\r\n",
        "    score = roc_auc_score(yvl,clf.predict_proba(xvl)[:,1])\r\n",
        "    print('ROC AUC score:',score)\r\n",
        "    cv_score.append(score)    \r\n",
        "    pred_test = clf.predict_proba(Xt)[:,1]\r\n",
        "    pred_test_full +=pred_test\r\n",
        "    i+=1\r\n",
        "\r\n",
        "  print('CV mean score :', np.array(cv_score).mean())\r\n",
        "\r\n",
        "  #proba = lr.predict_proba(xvl)[:,1]\r\n",
        "  #frp,trp, threshold = roc_curve(yvl,proba)\r\n",
        "  #roc_auc_ = auc(frp,trp)\r\n",
        "\r\n",
        "  #plt.figure(figsize=(14,8))\r\n",
        "  #plt.title('Reciever Operating Characteristics')\r\n",
        "  #plt.plot(frp,trp,'r',label = 'AUC = %0.2f' % roc_auc_)\r\n",
        "  #plt.legend(loc='lower right')\r\n",
        "  #plt.plot([0,1],[0,1],'b--')\r\n",
        "  #plt.ylabel('True positive rate')\r\n",
        "  #plt.xlabel('False positive rate')\r\n",
        "\r\n",
        "  return pred_test"
      ],
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ832Rsboeov",
        "outputId": "ba4996c9-71f3-4a21-d3d5-31a62cfb38df"
      },
      "source": [
        "_kfoldcv(LogisticRegression(max_iter=1000),X,y,Xt,10,seed=10) "
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 of KFold 10\n",
            "ROC AUC score: 0.5582191432760202\n",
            "2 of KFold 10\n",
            "ROC AUC score: 0.5814109681741533\n",
            "3 of KFold 10\n",
            "ROC AUC score: 0.5529985420516385\n",
            "4 of KFold 10\n",
            "ROC AUC score: 0.5661290742749238\n",
            "5 of KFold 10\n",
            "ROC AUC score: 0.571104710747845\n",
            "6 of KFold 10\n",
            "ROC AUC score: 0.5610511421217396\n",
            "7 of KFold 10\n",
            "ROC AUC score: 0.5531396408044973\n",
            "8 of KFold 10\n",
            "ROC AUC score: 0.5616261582126594\n",
            "9 of KFold 10\n",
            "ROC AUC score: 0.5627295960887893\n",
            "10 of KFold 10\n",
            "ROC AUC score: 0.5853452013265823\n",
            "CV mean score : 0.5653754177078849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.14089853, 0.24983877, 0.23800328, ..., 0.14182066, 0.24234412,\n",
              "       0.15288102])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 394
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mYOamKNbA-i",
        "outputId": "6d97c264-33a2-4dc2-a043-121357fefc0b"
      },
      "source": [
        "# With one-hot-encoder with scaling the continuos variables\r\n",
        "\r\n",
        "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.25,random_state=40,shuffle =True,stratify =y)\r\n",
        "X_train.shape,y_train.shape,X_val.shape,y_val.shape"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((38161, 78), (38161,), (12721, 78), (12721,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gei08MzWyWUb",
        "outputId": "8ba502d7-58a5-435b-b433-4818944b0305"
      },
      "source": [
        "train.Response.value_counts('Normalize')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.760053\n",
              "1    0.239947\n",
              "Name: Response, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6aq-vthvXIK"
      },
      "source": [
        "X = train[['City_Code', 'Region_Code', 'Accomodation_Type',\r\n",
        "       'Reco_Insurance_Type', 'Upper_Age', 'Lower_Age', 'Is_Spouse',\r\n",
        "       'Health Indicator','Holding_Policy_Type',\r\n",
        "       'Reco_Policy_Cat', 'Reco_Policy_Premium','Holding_Policy_Duration_YRS', 'Total_Policy_Cases',\r\n",
        "       'Insurance_Cover_yrs', 'Total_Insurance_Payable']]\r\n",
        "y = train['Response']\r\n",
        "\r\n",
        "# Drop columns that have 40% NAN in the data\r\n",
        "\r\n",
        "#X = train[['City_Code', 'Region_Code', 'Accomodation_Type',\r\n",
        "#       'Reco_Insurance_Type', 'Upper_Age', 'Lower_Age', 'Is_Spouse',\r\n",
        "#       'Health Indicator','Reco_Policy_Cat', 'Reco_Policy_Premium']]\r\n",
        "#y = train['Response']\r\n",
        "\r\n",
        "X , y = np.array(X),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDTT9GwbaCSk"
      },
      "source": [
        "# New features added\r\n",
        "\r\n",
        "X = train[['City_Code', 'Region_Code', 'Accomodation_Type',\r\n",
        "       'Reco_Insurance_Type', 'Upper_Age', 'Lower_Age', 'Is_Spouse',\r\n",
        "       'Health Indicator', 'Holding_Policy_Duration', 'Holding_Policy_Type',\r\n",
        "       'Reco_Policy_Cat', 'Reco_Policy_Premium','Total_Premium_Payable']]\r\n",
        "y = train['Response']\r\n",
        "\r\n",
        "X , y = np.array(X),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "407B-L0ivpYV"
      },
      "source": [
        "X_test = test[['City_Code', 'Region_Code', 'Accomodation_Type',\r\n",
        "       'Reco_Insurance_Type', 'Upper_Age', 'Lower_Age', 'Is_Spouse',\r\n",
        "       'Health Indicator', 'Holding_Policy_Type',\r\n",
        "       'Reco_Policy_Cat', 'Reco_Policy_Premium','Holding_Policy_Duration_YRS', 'Total_Policy_Cases',\r\n",
        "       'Insurance_Cover_yrs', 'Total_Insurance_Payable']]\r\n",
        "\r\n",
        "# Drop columns that have 40% NAN in the data\r\n",
        "#X_test = test[['City_Code', 'Region_Code', 'Accomodation_Type',\r\n",
        "#       'Reco_Insurance_Type', 'Upper_Age', 'Lower_Age', 'Is_Spouse',\r\n",
        "#       'Health Indicator', 'Reco_Policy_Cat', 'Reco_Policy_Premium']]\r\n",
        "\r\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YcCYa4OaN8W"
      },
      "source": [
        "# New feature added\r\n",
        "\r\n",
        "X_test = test[['City_Code', 'Region_Code', 'Accomodation_Type',\r\n",
        "       'Reco_Insurance_Type', 'Upper_Age', 'Lower_Age', 'Is_Spouse',\r\n",
        "       'Health Indicator', 'Holding_Policy_Duration', 'Holding_Policy_Type',\r\n",
        "       'Reco_Policy_Cat', 'Reco_Policy_Premium','Total_Premium_Payable']]\r\n",
        "\r\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7yBZesFvrne",
        "outputId": "39419ec1-64a0-42ae-9787-cf4a7f13d6a1"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 1, 0], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fnwBLEo_UhM"
      },
      "source": [
        "scaler = MinMaxScaler()\r\n",
        "X      = scaler.fit_transform(X)\r\n",
        "Xt = scaler.fit_transform(Xt) "
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu6QHKbXcAmc"
      },
      "source": [
        "scaler = StandardScaler()\r\n",
        "X      = scaler.fit_transform(X)\r\n",
        "X_test = scaler.fit_transform(X_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZj757KT_0LV",
        "outputId": "8c5bb919-42cb-4a34-afbe-cf6fb220643e"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.28571429e-01, 5.18650089e-01, 1.00000000e+00, ...,\n",
              "        7.36842105e-02, 0.00000000e+00, 2.00921737e-01],\n",
              "       [8.85714286e-01, 1.80203456e-01, 0.00000000e+00, ...,\n",
              "        1.68421053e-01, 8.98305085e-01, 7.12739419e-01],\n",
              "       [8.85714286e-01, 6.02454384e-01, 0.00000000e+00, ...,\n",
              "        6.31578947e-02, 0.00000000e+00, 4.81774320e-03],\n",
              "       ...,\n",
              "       [0.00000000e+00, 7.12094300e-02, 1.00000000e+00, ...,\n",
              "        2.00000000e-01, 0.00000000e+00, 1.96446944e-01],\n",
              "       [0.00000000e+00, 4.84417891e-04, 0.00000000e+00, ...,\n",
              "        7.57894737e-01, 3.72881356e-01, 6.22599937e-02],\n",
              "       [6.28571429e-01, 6.24091716e-01, 1.00000000e+00, ...,\n",
              "        2.10526316e-02, 0.00000000e+00, 2.29024847e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5EshzbJwiae",
        "outputId": "5bdb31d6-af87-4b69-857d-315d9d1ac0c3"
      },
      "source": [
        "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.25,random_state=40,shuffle =True,stratify =y)\r\n",
        "X_train.shape,y_train.shape,X_val.shape,y_val.shape"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((38161, 78), (38161,), (12721, 78), (12721,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA9zfGnfu2WJ",
        "outputId": "8e044b42-b87f-46c4-dd9e-4e1d19af75e4"
      },
      "source": [
        "lgclf = LogisticRegression(random_state=0,max_iter=1000).fit(X_train, y_train)\r\n",
        "lgprd = lgclf.predict_proba(X_val)[:,1]\r\n",
        "lgprdT = lgclf.predict_proba(Xt)[:,1]\r\n",
        "lgprd"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.31196116, 0.17558785, 0.25817936, ..., 0.17695272, 0.26618781,\n",
              "       0.33048856])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La836xT_v23n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e2679a4-6f28-420e-b8cb-57b3d7ee52d9"
      },
      "source": [
        "score = roc_auc_score(y_val,lgprd)\r\n",
        "print(score)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5744151737043993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-wuvQTux38Y",
        "outputId": "96863dc2-adf0-4022-cc07-6009ab4b4936"
      },
      "source": [
        "lgprdT"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.33407474, 0.1955493 , 0.33731175, ..., 0.19418532, 0.33203889,\n",
              "       0.17981867])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVw-DBfZCR0t"
      },
      "source": [
        "def _ML_modelsPred(model,X_train,y_train,X_test) :\r\n",
        "\r\n",
        "  clf = model.fit(X_train, y_train)\r\n",
        "  mprd = clf.predict_proba(X_val)[:,1]\r\n",
        "  mprdT = clf.predict_proba(Xt)[:,1]\r\n",
        "  score = roc_auc_score(y_val,mprd,average='weighted')\r\n",
        "  #crossval_scores = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=10)\r\n",
        "  print(\"ROC Score for training set :\" ,score)\r\n",
        "  #print(\"Crossval Score :\",  crossval_scores.mean())\r\n",
        "  return mprd,mprdT"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UtAsR7wCTdk",
        "outputId": "9d6d5dd7-ea8e-451b-ce7b-9864ce40ba68"
      },
      "source": [
        "# Decisiontree classifier\r\n",
        "\r\n",
        "DTmprdT  = _ML_modelsPred(DecisionTreeClassifier(criterion='entropy',max_depth=5,\r\n",
        "                                                 max_features ='auto',random_state =0),X_train,y_train,Xt)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC Score for training set : 0.5331604042699325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0j7VI66FrOT",
        "outputId": "73deec93-7295-4a2a-de8e-82b6787742f2"
      },
      "source": [
        "# Naive Bayes classifier\r\n",
        "\r\n",
        "GNBmprdT  = _ML_modelsPred(GaussianNB(var_smoothing=1e-09),X_train,y_train,Xt)"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC Score for training set : 0.5404289417463792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp81ua5-G-0C",
        "outputId": "2ed28063-e8bf-4b61-f67b-3fdd128e3983"
      },
      "source": [
        "# Randomforest classifier\r\n",
        "\r\n",
        "RFmprdT  = _ML_modelsPred(RandomForestClassifier(n_estimators=2000,max_depth =10,\r\n",
        "                                                 random_state=0),X_train,y_train,Xt)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC Score for training set : 0.6035868844601662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUh0FCTnI0Wy",
        "outputId": "26665ad4-5e17-4474-84e3-9a77b76b2a2d"
      },
      "source": [
        "# XGBoost classifier\r\n",
        "\r\n",
        "XGBmprd,XGBmprdT  = _ML_modelsPred(xgb.XGBClassifier(n_estimators=2000,max_depth =10,\r\n",
        "                                                 random_state=0),X_train,y_train,Xt)"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC Score for training set : 0.6552946432553158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i2Av6HDNF-B"
      },
      "source": [
        "#Perform random grid search for finding the best model\r\n",
        "from time import *\r\n",
        "def findbestparamfor(X,y) :\r\n",
        "    reg = xgb.XGBClassifier(\"binary:logistic\")\r\n",
        "\r\n",
        "    param_grid = {\r\n",
        "        'silent': [False],\r\n",
        "        'max_depth': [3,4,5,6,8,10,12,15,20],\r\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 0.15,0.2,0.25, 0,3],\r\n",
        "        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\r\n",
        "        'colsample_bytree': [0.3,0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\r\n",
        "        'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\r\n",
        "        'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\r\n",
        "        'gamma': [0,0.1, 0.25,0.2,0.3,0.4, 0.5, 1.0],\r\n",
        "        'alpha': [0,0.001,0.005,0.01,0.05],\r\n",
        "        'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0]\r\n",
        "        ,'n_estimators': [200,500,1000,1500,2000]}\r\n",
        "\r\n",
        "       \r\n",
        "    rs_reg = RandomizedSearchCV(reg, param_grid,n_iter=4,\r\n",
        "                            n_jobs=-1, verbose=2,                            \r\n",
        "                            refit=False, cv =10,random_state=42)\r\n",
        "\r\n",
        "    print(\"Randomized search..\")\r\n",
        "    search_time_start = time()\r\n",
        "   # rs_reg.fit(X, y,early_stopping_rounds =50,eval_set=[(Xval,yval)])\r\n",
        "    rs_reg.fit(X,y)\r\n",
        "    print(\"Randomized search time:\", time() - search_time_start)\r\n",
        "\r\n",
        "    best_score = rs_reg.best_score_\r\n",
        "    best_params = rs_reg.best_params_\r\n",
        "    print(\"Best score: {}\".format(best_score))\r\n",
        "    print(\"Best params: \")\r\n",
        "    for param_name in sorted(best_params.keys()):\r\n",
        "        print('%s: %r' % (param_name, best_params[param_name]))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFMsGmDiNGEI",
        "outputId": "773ac996-3cfd-4c5f-eaa4-df30958e3ba1"
      },
      "source": [
        "findbestparamfor(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Randomized search..\n",
            "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  6.9min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Randomized search time: 460.00454449653625\n",
            "Best score: 0.7600429763899668\n",
            "Best params: \n",
            "alpha: 0.001\n",
            "colsample_bylevel: 0.8\n",
            "colsample_bytree: 0.6\n",
            "gamma: 0.1\n",
            "learning_rate: 0\n",
            "max_depth: 20\n",
            "min_child_weight: 10.0\n",
            "n_estimators: 1500\n",
            "reg_lambda: 50.0\n",
            "silent: False\n",
            "subsample: 0.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  7.7min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU3TH5qANGIz",
        "outputId": "9ebe6fcd-51df-413d-fcda-3a9ac60e7ec2"
      },
      "source": [
        "XGBmprd,XGBmprdT  = _ML_modelsPred(xgb.XGBClassifier(n_estimators=1500,max_depth =20,alpha=.001,colsample_bylevel=0.8,\r\n",
        "                                                 colsample_bytree=0.6,gamma=0.1,learning_rate=0,\r\n",
        "                                                 min_child_weight=10.0,reg_lambda=50.0,subsample=0.8,random_state=0),X_train,y_train,X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC Score for training set : 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "6RJs7FEeyOjq",
        "outputId": "338292b3-b4b7-4e1c-bab5-c9873383f7dc"
      },
      "source": [
        "XGBmprdT = _kfoldcv(xgb.XGBClassifier(n_estimators=2000,max_depth =10,\r\n",
        "                                                 random_state=0),X,y,Xt,10,seed=10) "
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 of KFold 10\n",
            "ROC AUC score: 0.6591529481912108\n",
            "2 of KFold 10\n",
            "ROC AUC score: 0.665776098557898\n",
            "3 of KFold 10\n",
            "ROC AUC score: 0.658054740875108\n",
            "4 of KFold 10\n",
            "ROC AUC score: 0.6556996378563485\n",
            "5 of KFold 10\n",
            "ROC AUC score: 0.6619316262450475\n",
            "6 of KFold 10\n",
            "ROC AUC score: 0.667569749028244\n",
            "7 of KFold 10\n",
            "ROC AUC score: 0.6556068728295259\n",
            "8 of KFold 10\n",
            "ROC AUC score: 0.6583097661452975\n",
            "9 of KFold 10\n",
            "ROC AUC score: 0.6568935110440154\n",
            "10 of KFold 10\n",
            "ROC AUC score: 0.6673177161928131\n",
            "CV mean score : 0.6606312666965509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1yEIWgJNGMM",
        "outputId": "7e3e6c82-0eb2-4f12-bacb-fe401c011197"
      },
      "source": [
        "XGBmprdT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.05379714, 0.07840323, 0.19107716, ..., 0.00342841, 0.12067366,\n",
              "       0.05581576], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sd2LF1UNGPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f785ca26-431c-4fa2-d187-c18a7149200a"
      },
      "source": [
        "LGBmprdT = _kfoldcv(lgb.LGBMClassifier(n_estimators=2000),X,y,Xt,10,seed=10) "
      ],
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 of KFold 10\n",
            "ROC AUC score: 0.6607646943737947\n",
            "2 of KFold 10\n",
            "ROC AUC score: 0.661226493956587\n",
            "3 of KFold 10\n",
            "ROC AUC score: 0.6418649448183499\n",
            "4 of KFold 10\n",
            "ROC AUC score: 0.6562863025236959\n",
            "5 of KFold 10\n",
            "ROC AUC score: 0.6601779860119659\n",
            "6 of KFold 10\n",
            "ROC AUC score: 0.6513000764358405\n",
            "7 of KFold 10\n",
            "ROC AUC score: 0.6500159797289355\n",
            "8 of KFold 10\n",
            "ROC AUC score: 0.6473253703664874\n",
            "9 of KFold 10\n",
            "ROC AUC score: 0.6506339896564878\n",
            "10 of KFold 10\n",
            "ROC AUC score: 0.6644534371454465\n",
            "CV mean score : 0.654404927501759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iurHwgLiTiYU",
        "outputId": "bd1d13c1-5190-4d83-ce75-d955aadf611f"
      },
      "source": [
        "# LightGBM classifier\r\n",
        "\r\n",
        "LGBmprd,LGBmprdT  =  _ML_modelsPred(lgb.LGBMClassifier(n_estimators=2000,subsample= 0.2, num_leaves =127, min_data_in_leaf =70,\r\n",
        "                                      metric= 'auc_roc',max_depth=10,learning_rate = 0.05, feature_fraction = 0.6, \r\n",
        "                                      bagging_frequency = 6, bagging_fraction =0.9) ,X_train,y_train,X_test)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC Score for training set : 0.6560825852086771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0ZINUGteaEP",
        "outputId": "e53bd79a-02b9-42cc-a5f5-6c00ce522f44"
      },
      "source": [
        "# LightGBM classifier\r\n",
        "\r\n",
        "LGBmprd,LGBmprdT  =  _ML_modelsPred(lgb.LGBMClassifier(n_estimators=2000) ,X_train,y_train,Xt)\r\n"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC Score for training set : 0.6483725332083036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTot-YXNJfdu",
        "outputId": "15ec7d5a-5387-4fb9-d88e-7f615a92d86e"
      },
      "source": [
        "# knn classifier\r\n",
        "\r\n",
        "KnnmprdT  = _ML_modelsPred(KNeighborsClassifier(n_neighbors=7),X_train,y_train,X_test)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC Score for training set : 0.5372186340342398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS1ii5vkvnTk",
        "outputId": "7300c0ee-3494-45ca-d475-0b9c831e292a"
      },
      "source": [
        "CBmprdT = _kfoldcv(CatBoostClassifier(n_estimators=2000,verbose=0),X,y,Xt,10,seed=10) "
      ],
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 of KFold 10\n",
            "ROC AUC score: 0.6770513344970429\n",
            "2 of KFold 10\n",
            "ROC AUC score: 0.6792493819381099\n",
            "3 of KFold 10\n",
            "ROC AUC score: 0.6651190092732298\n",
            "4 of KFold 10\n",
            "ROC AUC score: 0.6801078531101805\n",
            "5 of KFold 10\n",
            "ROC AUC score: 0.6729386837998165\n",
            "6 of KFold 10\n",
            "ROC AUC score: 0.6759870103547373\n",
            "7 of KFold 10\n",
            "ROC AUC score: 0.6668265698521711\n",
            "8 of KFold 10\n",
            "ROC AUC score: 0.6743843780306155\n",
            "9 of KFold 10\n",
            "ROC AUC score: 0.667128373877792\n",
            "10 of KFold 10\n",
            "ROC AUC score: 0.684405330642724\n",
            "CV mean score : 0.674319792537642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvJuuj1wxxWU",
        "outputId": "01be2065-f854-4831-8151-350650f13e5e"
      },
      "source": [
        "CBmprdT"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.26890109, 0.19156291, 0.25013399, ..., 0.02995679, 0.19203923,\n",
              "       0.14271167])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uQ6xprzVCQ4",
        "outputId": "ffd13d50-9c08-464f-881d-20775d3bc4c5"
      },
      "source": [
        "# CatBoostClassifier\r\n",
        "\r\n",
        "CBmprd,CBmprdT  = _ML_modelsPred(CatBoostClassifier(n_estimators=2000),X_train,y_train,Xt)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.025837\n",
            "0:\tlearn: 0.6846241\ttotal: 19.7ms\tremaining: 39.3s\n",
            "1:\tlearn: 0.6768837\ttotal: 31.8ms\tremaining: 31.8s\n",
            "2:\tlearn: 0.6695199\ttotal: 50.1ms\tremaining: 33.3s\n",
            "3:\tlearn: 0.6624627\ttotal: 69.4ms\tremaining: 34.6s\n",
            "4:\tlearn: 0.6560557\ttotal: 88.6ms\tremaining: 35.4s\n",
            "5:\tlearn: 0.6497440\ttotal: 107ms\tremaining: 35.5s\n",
            "6:\tlearn: 0.6427833\ttotal: 125ms\tremaining: 35.5s\n",
            "7:\tlearn: 0.6370677\ttotal: 143ms\tremaining: 35.7s\n",
            "8:\tlearn: 0.6316643\ttotal: 162ms\tremaining: 35.8s\n",
            "9:\tlearn: 0.6267241\ttotal: 180ms\tremaining: 35.7s\n",
            "10:\tlearn: 0.6220804\ttotal: 201ms\tremaining: 36.3s\n",
            "11:\tlearn: 0.6176585\ttotal: 219ms\tremaining: 36.3s\n",
            "12:\tlearn: 0.6135481\ttotal: 249ms\tremaining: 38.1s\n",
            "13:\tlearn: 0.6097442\ttotal: 268ms\tremaining: 38s\n",
            "14:\tlearn: 0.6058985\ttotal: 286ms\tremaining: 37.9s\n",
            "15:\tlearn: 0.6020943\ttotal: 305ms\tremaining: 37.8s\n",
            "16:\tlearn: 0.5986226\ttotal: 324ms\tremaining: 37.8s\n",
            "17:\tlearn: 0.5954894\ttotal: 343ms\tremaining: 37.8s\n",
            "18:\tlearn: 0.5925348\ttotal: 362ms\tremaining: 37.8s\n",
            "19:\tlearn: 0.5890881\ttotal: 380ms\tremaining: 37.6s\n",
            "20:\tlearn: 0.5866519\ttotal: 403ms\tremaining: 38s\n",
            "21:\tlearn: 0.5840110\ttotal: 421ms\tremaining: 37.9s\n",
            "22:\tlearn: 0.5818225\ttotal: 440ms\tremaining: 37.8s\n",
            "23:\tlearn: 0.5795942\ttotal: 458ms\tremaining: 37.7s\n",
            "24:\tlearn: 0.5768095\ttotal: 477ms\tremaining: 37.7s\n",
            "25:\tlearn: 0.5748178\ttotal: 495ms\tremaining: 37.6s\n",
            "26:\tlearn: 0.5729331\ttotal: 513ms\tremaining: 37.5s\n",
            "27:\tlearn: 0.5710693\ttotal: 531ms\tremaining: 37.4s\n",
            "28:\tlearn: 0.5693309\ttotal: 550ms\tremaining: 37.4s\n",
            "29:\tlearn: 0.5678788\ttotal: 562ms\tremaining: 36.9s\n",
            "30:\tlearn: 0.5662534\ttotal: 581ms\tremaining: 36.9s\n",
            "31:\tlearn: 0.5649281\ttotal: 600ms\tremaining: 36.9s\n",
            "32:\tlearn: 0.5633935\ttotal: 624ms\tremaining: 37.2s\n",
            "33:\tlearn: 0.5622085\ttotal: 644ms\tremaining: 37.2s\n",
            "34:\tlearn: 0.5609456\ttotal: 662ms\tremaining: 37.2s\n",
            "35:\tlearn: 0.5597563\ttotal: 680ms\tremaining: 37.1s\n",
            "36:\tlearn: 0.5587497\ttotal: 696ms\tremaining: 36.9s\n",
            "37:\tlearn: 0.5575037\ttotal: 714ms\tremaining: 36.9s\n",
            "38:\tlearn: 0.5565044\ttotal: 732ms\tremaining: 36.8s\n",
            "39:\tlearn: 0.5555735\ttotal: 751ms\tremaining: 36.8s\n",
            "40:\tlearn: 0.5547678\ttotal: 771ms\tremaining: 36.8s\n",
            "41:\tlearn: 0.5538121\ttotal: 789ms\tremaining: 36.8s\n",
            "42:\tlearn: 0.5530151\ttotal: 807ms\tremaining: 36.7s\n",
            "43:\tlearn: 0.5521611\ttotal: 830ms\tremaining: 36.9s\n",
            "44:\tlearn: 0.5514097\ttotal: 849ms\tremaining: 36.9s\n",
            "45:\tlearn: 0.5506593\ttotal: 868ms\tremaining: 36.9s\n",
            "46:\tlearn: 0.5499226\ttotal: 887ms\tremaining: 36.9s\n",
            "47:\tlearn: 0.5491541\ttotal: 906ms\tremaining: 36.8s\n",
            "48:\tlearn: 0.5480970\ttotal: 925ms\tremaining: 36.8s\n",
            "49:\tlearn: 0.5474922\ttotal: 945ms\tremaining: 36.8s\n",
            "50:\tlearn: 0.5469343\ttotal: 963ms\tremaining: 36.8s\n",
            "51:\tlearn: 0.5464329\ttotal: 982ms\tremaining: 36.8s\n",
            "52:\tlearn: 0.5455400\ttotal: 1s\tremaining: 36.8s\n",
            "53:\tlearn: 0.5450769\ttotal: 1.02s\tremaining: 36.7s\n",
            "54:\tlearn: 0.5443021\ttotal: 1.04s\tremaining: 36.9s\n",
            "55:\tlearn: 0.5438725\ttotal: 1.06s\tremaining: 36.9s\n",
            "56:\tlearn: 0.5435242\ttotal: 1.08s\tremaining: 36.9s\n",
            "57:\tlearn: 0.5432069\ttotal: 1.1s\tremaining: 36.8s\n",
            "58:\tlearn: 0.5429048\ttotal: 1.12s\tremaining: 36.8s\n",
            "59:\tlearn: 0.5424575\ttotal: 1.14s\tremaining: 36.8s\n",
            "60:\tlearn: 0.5420584\ttotal: 1.16s\tremaining: 36.7s\n",
            "61:\tlearn: 0.5417707\ttotal: 1.18s\tremaining: 36.7s\n",
            "62:\tlearn: 0.5415172\ttotal: 1.19s\tremaining: 36.7s\n",
            "63:\tlearn: 0.5409414\ttotal: 1.21s\tremaining: 36.7s\n",
            "64:\tlearn: 0.5403803\ttotal: 1.24s\tremaining: 36.9s\n",
            "65:\tlearn: 0.5401194\ttotal: 1.26s\tremaining: 37s\n",
            "66:\tlearn: 0.5397786\ttotal: 1.28s\tremaining: 37s\n",
            "67:\tlearn: 0.5394271\ttotal: 1.3s\tremaining: 36.9s\n",
            "68:\tlearn: 0.5391498\ttotal: 1.32s\tremaining: 36.9s\n",
            "69:\tlearn: 0.5388900\ttotal: 1.34s\tremaining: 36.9s\n",
            "70:\tlearn: 0.5386201\ttotal: 1.36s\tremaining: 36.9s\n",
            "71:\tlearn: 0.5382138\ttotal: 1.37s\tremaining: 36.8s\n",
            "72:\tlearn: 0.5378652\ttotal: 1.39s\tremaining: 36.8s\n",
            "73:\tlearn: 0.5376767\ttotal: 1.41s\tremaining: 36.7s\n",
            "74:\tlearn: 0.5375099\ttotal: 1.43s\tremaining: 36.7s\n",
            "75:\tlearn: 0.5371861\ttotal: 1.45s\tremaining: 36.8s\n",
            "76:\tlearn: 0.5368291\ttotal: 1.47s\tremaining: 36.8s\n",
            "77:\tlearn: 0.5364706\ttotal: 1.49s\tremaining: 36.8s\n",
            "78:\tlearn: 0.5359294\ttotal: 1.51s\tremaining: 36.8s\n",
            "79:\tlearn: 0.5357563\ttotal: 1.53s\tremaining: 36.8s\n",
            "80:\tlearn: 0.5356182\ttotal: 1.55s\tremaining: 36.7s\n",
            "81:\tlearn: 0.5355136\ttotal: 1.57s\tremaining: 36.7s\n",
            "82:\tlearn: 0.5353271\ttotal: 1.59s\tremaining: 36.6s\n",
            "83:\tlearn: 0.5350981\ttotal: 1.6s\tremaining: 36.6s\n",
            "84:\tlearn: 0.5349225\ttotal: 1.62s\tremaining: 36.6s\n",
            "85:\tlearn: 0.5348060\ttotal: 1.64s\tremaining: 36.6s\n",
            "86:\tlearn: 0.5346274\ttotal: 1.66s\tremaining: 36.5s\n",
            "87:\tlearn: 0.5345088\ttotal: 1.69s\tremaining: 36.6s\n",
            "88:\tlearn: 0.5341643\ttotal: 1.71s\tremaining: 36.6s\n",
            "89:\tlearn: 0.5339912\ttotal: 1.72s\tremaining: 36.6s\n",
            "90:\tlearn: 0.5338840\ttotal: 1.74s\tremaining: 36.6s\n",
            "91:\tlearn: 0.5338033\ttotal: 1.76s\tremaining: 36.5s\n",
            "92:\tlearn: 0.5336238\ttotal: 1.78s\tremaining: 36.5s\n",
            "93:\tlearn: 0.5334577\ttotal: 1.8s\tremaining: 36.5s\n",
            "94:\tlearn: 0.5333078\ttotal: 1.82s\tremaining: 36.4s\n",
            "95:\tlearn: 0.5331150\ttotal: 1.83s\tremaining: 36.4s\n",
            "96:\tlearn: 0.5329767\ttotal: 1.85s\tremaining: 36.3s\n",
            "97:\tlearn: 0.5328593\ttotal: 1.87s\tremaining: 36.3s\n",
            "98:\tlearn: 0.5327963\ttotal: 1.89s\tremaining: 36.4s\n",
            "99:\tlearn: 0.5325127\ttotal: 1.91s\tremaining: 36.3s\n",
            "100:\tlearn: 0.5322148\ttotal: 1.93s\tremaining: 36.3s\n",
            "101:\tlearn: 0.5321124\ttotal: 1.95s\tremaining: 36.3s\n",
            "102:\tlearn: 0.5319600\ttotal: 1.97s\tremaining: 36.3s\n",
            "103:\tlearn: 0.5318467\ttotal: 1.99s\tremaining: 36.3s\n",
            "104:\tlearn: 0.5317139\ttotal: 2.01s\tremaining: 36.2s\n",
            "105:\tlearn: 0.5316116\ttotal: 2.03s\tremaining: 36.2s\n",
            "106:\tlearn: 0.5312876\ttotal: 2.04s\tremaining: 36.2s\n",
            "107:\tlearn: 0.5310967\ttotal: 2.06s\tremaining: 36.1s\n",
            "108:\tlearn: 0.5310160\ttotal: 2.08s\tremaining: 36.1s\n",
            "109:\tlearn: 0.5309751\ttotal: 2.1s\tremaining: 36.2s\n",
            "110:\tlearn: 0.5308404\ttotal: 2.12s\tremaining: 36.1s\n",
            "111:\tlearn: 0.5306071\ttotal: 2.14s\tremaining: 36.1s\n",
            "112:\tlearn: 0.5303927\ttotal: 2.16s\tremaining: 36.1s\n",
            "113:\tlearn: 0.5303080\ttotal: 2.18s\tremaining: 36.1s\n",
            "114:\tlearn: 0.5301900\ttotal: 2.2s\tremaining: 36s\n",
            "115:\tlearn: 0.5300946\ttotal: 2.22s\tremaining: 36s\n",
            "116:\tlearn: 0.5299442\ttotal: 2.24s\tremaining: 36.1s\n",
            "117:\tlearn: 0.5298660\ttotal: 2.26s\tremaining: 36.1s\n",
            "118:\tlearn: 0.5296867\ttotal: 2.28s\tremaining: 36s\n",
            "119:\tlearn: 0.5295018\ttotal: 2.3s\tremaining: 36s\n",
            "120:\tlearn: 0.5293342\ttotal: 2.32s\tremaining: 36.1s\n",
            "121:\tlearn: 0.5291842\ttotal: 2.34s\tremaining: 36s\n",
            "122:\tlearn: 0.5291339\ttotal: 2.36s\tremaining: 36s\n",
            "123:\tlearn: 0.5289618\ttotal: 2.38s\tremaining: 36s\n",
            "124:\tlearn: 0.5288148\ttotal: 2.4s\tremaining: 36s\n",
            "125:\tlearn: 0.5287507\ttotal: 2.42s\tremaining: 36s\n",
            "126:\tlearn: 0.5285222\ttotal: 2.44s\tremaining: 35.9s\n",
            "127:\tlearn: 0.5284571\ttotal: 2.46s\tremaining: 36s\n",
            "128:\tlearn: 0.5283878\ttotal: 2.48s\tremaining: 35.9s\n",
            "129:\tlearn: 0.5282866\ttotal: 2.5s\tremaining: 35.9s\n",
            "130:\tlearn: 0.5281851\ttotal: 2.52s\tremaining: 35.9s\n",
            "131:\tlearn: 0.5281092\ttotal: 2.54s\tremaining: 35.9s\n",
            "132:\tlearn: 0.5280702\ttotal: 2.56s\tremaining: 35.9s\n",
            "133:\tlearn: 0.5279957\ttotal: 2.58s\tremaining: 35.9s\n",
            "134:\tlearn: 0.5278961\ttotal: 2.59s\tremaining: 35.8s\n",
            "135:\tlearn: 0.5277877\ttotal: 2.61s\tremaining: 35.8s\n",
            "136:\tlearn: 0.5276935\ttotal: 2.63s\tremaining: 35.8s\n",
            "137:\tlearn: 0.5275616\ttotal: 2.65s\tremaining: 35.8s\n",
            "138:\tlearn: 0.5274701\ttotal: 2.67s\tremaining: 35.8s\n",
            "139:\tlearn: 0.5274094\ttotal: 2.69s\tremaining: 35.7s\n",
            "140:\tlearn: 0.5273709\ttotal: 2.71s\tremaining: 35.7s\n",
            "141:\tlearn: 0.5272762\ttotal: 2.73s\tremaining: 35.7s\n",
            "142:\tlearn: 0.5271588\ttotal: 2.75s\tremaining: 35.7s\n",
            "143:\tlearn: 0.5270313\ttotal: 2.77s\tremaining: 35.7s\n",
            "144:\tlearn: 0.5269357\ttotal: 2.79s\tremaining: 35.7s\n",
            "145:\tlearn: 0.5268464\ttotal: 2.81s\tremaining: 35.7s\n",
            "146:\tlearn: 0.5267664\ttotal: 2.83s\tremaining: 35.6s\n",
            "147:\tlearn: 0.5266776\ttotal: 2.85s\tremaining: 35.6s\n",
            "148:\tlearn: 0.5266446\ttotal: 2.87s\tremaining: 35.6s\n",
            "149:\tlearn: 0.5265360\ttotal: 2.88s\tremaining: 35.6s\n",
            "150:\tlearn: 0.5264551\ttotal: 2.9s\tremaining: 35.5s\n",
            "151:\tlearn: 0.5263537\ttotal: 2.92s\tremaining: 35.5s\n",
            "152:\tlearn: 0.5261968\ttotal: 2.94s\tremaining: 35.5s\n",
            "153:\tlearn: 0.5261395\ttotal: 2.96s\tremaining: 35.5s\n",
            "154:\tlearn: 0.5260313\ttotal: 2.98s\tremaining: 35.5s\n",
            "155:\tlearn: 0.5259659\ttotal: 3s\tremaining: 35.4s\n",
            "156:\tlearn: 0.5258070\ttotal: 3.02s\tremaining: 35.4s\n",
            "157:\tlearn: 0.5257299\ttotal: 3.04s\tremaining: 35.4s\n",
            "158:\tlearn: 0.5256535\ttotal: 3.05s\tremaining: 35.4s\n",
            "159:\tlearn: 0.5255550\ttotal: 3.07s\tremaining: 35.3s\n",
            "160:\tlearn: 0.5254879\ttotal: 3.09s\tremaining: 35.3s\n",
            "161:\tlearn: 0.5253684\ttotal: 3.12s\tremaining: 35.4s\n",
            "162:\tlearn: 0.5252710\ttotal: 3.15s\tremaining: 35.5s\n",
            "163:\tlearn: 0.5251806\ttotal: 3.17s\tremaining: 35.5s\n",
            "164:\tlearn: 0.5250508\ttotal: 3.19s\tremaining: 35.5s\n",
            "165:\tlearn: 0.5249694\ttotal: 3.21s\tremaining: 35.5s\n",
            "166:\tlearn: 0.5248789\ttotal: 3.24s\tremaining: 35.5s\n",
            "167:\tlearn: 0.5247976\ttotal: 3.27s\tremaining: 35.7s\n",
            "168:\tlearn: 0.5247465\ttotal: 3.29s\tremaining: 35.7s\n",
            "169:\tlearn: 0.5246630\ttotal: 3.31s\tremaining: 35.7s\n",
            "170:\tlearn: 0.5245638\ttotal: 3.33s\tremaining: 35.6s\n",
            "171:\tlearn: 0.5244913\ttotal: 3.35s\tremaining: 35.6s\n",
            "172:\tlearn: 0.5244052\ttotal: 3.38s\tremaining: 35.8s\n",
            "173:\tlearn: 0.5243735\ttotal: 3.4s\tremaining: 35.7s\n",
            "174:\tlearn: 0.5243193\ttotal: 3.42s\tremaining: 35.7s\n",
            "175:\tlearn: 0.5242648\ttotal: 3.44s\tremaining: 35.7s\n",
            "176:\tlearn: 0.5242128\ttotal: 3.46s\tremaining: 35.7s\n",
            "177:\tlearn: 0.5241443\ttotal: 3.48s\tremaining: 35.6s\n",
            "178:\tlearn: 0.5240727\ttotal: 3.5s\tremaining: 35.6s\n",
            "179:\tlearn: 0.5240259\ttotal: 3.52s\tremaining: 35.6s\n",
            "180:\tlearn: 0.5239579\ttotal: 3.54s\tremaining: 35.5s\n",
            "181:\tlearn: 0.5238762\ttotal: 3.56s\tremaining: 35.5s\n",
            "182:\tlearn: 0.5237983\ttotal: 3.58s\tremaining: 35.5s\n",
            "183:\tlearn: 0.5237242\ttotal: 3.6s\tremaining: 35.5s\n",
            "184:\tlearn: 0.5236488\ttotal: 3.62s\tremaining: 35.5s\n",
            "185:\tlearn: 0.5235974\ttotal: 3.64s\tremaining: 35.5s\n",
            "186:\tlearn: 0.5235450\ttotal: 3.66s\tremaining: 35.5s\n",
            "187:\tlearn: 0.5234574\ttotal: 3.68s\tremaining: 35.4s\n",
            "188:\tlearn: 0.5233704\ttotal: 3.69s\tremaining: 35.4s\n",
            "189:\tlearn: 0.5232584\ttotal: 3.71s\tremaining: 35.4s\n",
            "190:\tlearn: 0.5232259\ttotal: 3.73s\tremaining: 35.4s\n",
            "191:\tlearn: 0.5231869\ttotal: 3.75s\tremaining: 35.3s\n",
            "192:\tlearn: 0.5231431\ttotal: 3.77s\tremaining: 35.3s\n",
            "193:\tlearn: 0.5230966\ttotal: 3.79s\tremaining: 35.3s\n",
            "194:\tlearn: 0.5230071\ttotal: 3.81s\tremaining: 35.3s\n",
            "195:\tlearn: 0.5229709\ttotal: 3.83s\tremaining: 35.3s\n",
            "196:\tlearn: 0.5228564\ttotal: 3.85s\tremaining: 35.3s\n",
            "197:\tlearn: 0.5227792\ttotal: 3.87s\tremaining: 35.2s\n",
            "198:\tlearn: 0.5227226\ttotal: 3.89s\tremaining: 35.2s\n",
            "199:\tlearn: 0.5226309\ttotal: 3.91s\tremaining: 35.2s\n",
            "200:\tlearn: 0.5225838\ttotal: 3.93s\tremaining: 35.1s\n",
            "201:\tlearn: 0.5225460\ttotal: 3.94s\tremaining: 35.1s\n",
            "202:\tlearn: 0.5225073\ttotal: 3.96s\tremaining: 35.1s\n",
            "203:\tlearn: 0.5224591\ttotal: 3.98s\tremaining: 35.1s\n",
            "204:\tlearn: 0.5223951\ttotal: 4s\tremaining: 35.1s\n",
            "205:\tlearn: 0.5223602\ttotal: 4.03s\tremaining: 35.1s\n",
            "206:\tlearn: 0.5222758\ttotal: 4.05s\tremaining: 35.1s\n",
            "207:\tlearn: 0.5222333\ttotal: 4.07s\tremaining: 35s\n",
            "208:\tlearn: 0.5222187\ttotal: 4.08s\tremaining: 35s\n",
            "209:\tlearn: 0.5221560\ttotal: 4.1s\tremaining: 35s\n",
            "210:\tlearn: 0.5220776\ttotal: 4.12s\tremaining: 35s\n",
            "211:\tlearn: 0.5220210\ttotal: 4.14s\tremaining: 34.9s\n",
            "212:\tlearn: 0.5219891\ttotal: 4.16s\tremaining: 34.9s\n",
            "213:\tlearn: 0.5219283\ttotal: 4.18s\tremaining: 34.9s\n",
            "214:\tlearn: 0.5218887\ttotal: 4.2s\tremaining: 34.9s\n",
            "215:\tlearn: 0.5218107\ttotal: 4.22s\tremaining: 34.8s\n",
            "216:\tlearn: 0.5217798\ttotal: 4.25s\tremaining: 34.9s\n",
            "217:\tlearn: 0.5217422\ttotal: 4.26s\tremaining: 34.9s\n",
            "218:\tlearn: 0.5217120\ttotal: 4.28s\tremaining: 34.8s\n",
            "219:\tlearn: 0.5216431\ttotal: 4.31s\tremaining: 34.9s\n",
            "220:\tlearn: 0.5215654\ttotal: 4.33s\tremaining: 34.8s\n",
            "221:\tlearn: 0.5214821\ttotal: 4.34s\tremaining: 34.8s\n",
            "222:\tlearn: 0.5214226\ttotal: 4.36s\tremaining: 34.8s\n",
            "223:\tlearn: 0.5213953\ttotal: 4.38s\tremaining: 34.7s\n",
            "224:\tlearn: 0.5213542\ttotal: 4.4s\tremaining: 34.7s\n",
            "225:\tlearn: 0.5212885\ttotal: 4.42s\tremaining: 34.7s\n",
            "226:\tlearn: 0.5212269\ttotal: 4.44s\tremaining: 34.7s\n",
            "227:\tlearn: 0.5211626\ttotal: 4.46s\tremaining: 34.7s\n",
            "228:\tlearn: 0.5210889\ttotal: 4.48s\tremaining: 34.7s\n",
            "229:\tlearn: 0.5210483\ttotal: 4.5s\tremaining: 34.6s\n",
            "230:\tlearn: 0.5209841\ttotal: 4.52s\tremaining: 34.6s\n",
            "231:\tlearn: 0.5209310\ttotal: 4.54s\tremaining: 34.6s\n",
            "232:\tlearn: 0.5208861\ttotal: 4.56s\tremaining: 34.6s\n",
            "233:\tlearn: 0.5208484\ttotal: 4.58s\tremaining: 34.6s\n",
            "234:\tlearn: 0.5207856\ttotal: 4.6s\tremaining: 34.5s\n",
            "235:\tlearn: 0.5207186\ttotal: 4.62s\tremaining: 34.5s\n",
            "236:\tlearn: 0.5206519\ttotal: 4.63s\tremaining: 34.5s\n",
            "237:\tlearn: 0.5206279\ttotal: 4.65s\tremaining: 34.5s\n",
            "238:\tlearn: 0.5205540\ttotal: 4.68s\tremaining: 34.5s\n",
            "239:\tlearn: 0.5204741\ttotal: 4.7s\tremaining: 34.4s\n",
            "240:\tlearn: 0.5203985\ttotal: 4.71s\tremaining: 34.4s\n",
            "241:\tlearn: 0.5203717\ttotal: 4.73s\tremaining: 34.4s\n",
            "242:\tlearn: 0.5203198\ttotal: 4.75s\tremaining: 34.4s\n",
            "243:\tlearn: 0.5202597\ttotal: 4.77s\tremaining: 34.3s\n",
            "244:\tlearn: 0.5202270\ttotal: 4.79s\tremaining: 34.3s\n",
            "245:\tlearn: 0.5201804\ttotal: 4.81s\tremaining: 34.3s\n",
            "246:\tlearn: 0.5201398\ttotal: 4.83s\tremaining: 34.3s\n",
            "247:\tlearn: 0.5200853\ttotal: 4.84s\tremaining: 34.2s\n",
            "248:\tlearn: 0.5200159\ttotal: 4.86s\tremaining: 34.2s\n",
            "249:\tlearn: 0.5200116\ttotal: 4.88s\tremaining: 34.2s\n",
            "250:\tlearn: 0.5199643\ttotal: 4.9s\tremaining: 34.2s\n",
            "251:\tlearn: 0.5198410\ttotal: 4.92s\tremaining: 34.1s\n",
            "252:\tlearn: 0.5198084\ttotal: 4.94s\tremaining: 34.1s\n",
            "253:\tlearn: 0.5197683\ttotal: 4.96s\tremaining: 34.1s\n",
            "254:\tlearn: 0.5196894\ttotal: 4.98s\tremaining: 34.1s\n",
            "255:\tlearn: 0.5196312\ttotal: 5s\tremaining: 34s\n",
            "256:\tlearn: 0.5195481\ttotal: 5.02s\tremaining: 34.1s\n",
            "257:\tlearn: 0.5194939\ttotal: 5.04s\tremaining: 34s\n",
            "258:\tlearn: 0.5194218\ttotal: 5.06s\tremaining: 34s\n",
            "259:\tlearn: 0.5193800\ttotal: 5.08s\tremaining: 34s\n",
            "260:\tlearn: 0.5192916\ttotal: 5.1s\tremaining: 34s\n",
            "261:\tlearn: 0.5192459\ttotal: 5.12s\tremaining: 34s\n",
            "262:\tlearn: 0.5191867\ttotal: 5.14s\tremaining: 33.9s\n",
            "263:\tlearn: 0.5191556\ttotal: 5.16s\tremaining: 33.9s\n",
            "264:\tlearn: 0.5191094\ttotal: 5.18s\tremaining: 33.9s\n",
            "265:\tlearn: 0.5190336\ttotal: 5.2s\tremaining: 33.9s\n",
            "266:\tlearn: 0.5189654\ttotal: 5.22s\tremaining: 33.9s\n",
            "267:\tlearn: 0.5189266\ttotal: 5.25s\tremaining: 33.9s\n",
            "268:\tlearn: 0.5188300\ttotal: 5.26s\tremaining: 33.9s\n",
            "269:\tlearn: 0.5187894\ttotal: 5.28s\tremaining: 33.9s\n",
            "270:\tlearn: 0.5187305\ttotal: 5.3s\tremaining: 33.8s\n",
            "271:\tlearn: 0.5186685\ttotal: 5.32s\tremaining: 33.8s\n",
            "272:\tlearn: 0.5185439\ttotal: 5.34s\tremaining: 33.8s\n",
            "273:\tlearn: 0.5185042\ttotal: 5.36s\tremaining: 33.8s\n",
            "274:\tlearn: 0.5184335\ttotal: 5.38s\tremaining: 33.8s\n",
            "275:\tlearn: 0.5184058\ttotal: 5.4s\tremaining: 33.7s\n",
            "276:\tlearn: 0.5183560\ttotal: 5.42s\tremaining: 33.7s\n",
            "277:\tlearn: 0.5183314\ttotal: 5.44s\tremaining: 33.7s\n",
            "278:\tlearn: 0.5182767\ttotal: 5.46s\tremaining: 33.7s\n",
            "279:\tlearn: 0.5182588\ttotal: 5.48s\tremaining: 33.7s\n",
            "280:\tlearn: 0.5181925\ttotal: 5.5s\tremaining: 33.6s\n",
            "281:\tlearn: 0.5181573\ttotal: 5.52s\tremaining: 33.6s\n",
            "282:\tlearn: 0.5180979\ttotal: 5.54s\tremaining: 33.6s\n",
            "283:\tlearn: 0.5180524\ttotal: 5.56s\tremaining: 33.6s\n",
            "284:\tlearn: 0.5179624\ttotal: 5.58s\tremaining: 33.6s\n",
            "285:\tlearn: 0.5179347\ttotal: 5.6s\tremaining: 33.6s\n",
            "286:\tlearn: 0.5178470\ttotal: 5.62s\tremaining: 33.5s\n",
            "287:\tlearn: 0.5178050\ttotal: 5.64s\tremaining: 33.5s\n",
            "288:\tlearn: 0.5177515\ttotal: 5.66s\tremaining: 33.5s\n",
            "289:\tlearn: 0.5176787\ttotal: 5.67s\tremaining: 33.5s\n",
            "290:\tlearn: 0.5176135\ttotal: 5.69s\tremaining: 33.4s\n",
            "291:\tlearn: 0.5175266\ttotal: 5.71s\tremaining: 33.4s\n",
            "292:\tlearn: 0.5174714\ttotal: 5.73s\tremaining: 33.4s\n",
            "293:\tlearn: 0.5174539\ttotal: 5.75s\tremaining: 33.4s\n",
            "294:\tlearn: 0.5174206\ttotal: 5.77s\tremaining: 33.4s\n",
            "295:\tlearn: 0.5173876\ttotal: 5.79s\tremaining: 33.3s\n",
            "296:\tlearn: 0.5173556\ttotal: 5.81s\tremaining: 33.3s\n",
            "297:\tlearn: 0.5173004\ttotal: 5.83s\tremaining: 33.3s\n",
            "298:\tlearn: 0.5172619\ttotal: 5.84s\tremaining: 33.2s\n",
            "299:\tlearn: 0.5171467\ttotal: 5.86s\tremaining: 33.2s\n",
            "300:\tlearn: 0.5170257\ttotal: 5.88s\tremaining: 33.2s\n",
            "301:\tlearn: 0.5169690\ttotal: 5.9s\tremaining: 33.2s\n",
            "302:\tlearn: 0.5169403\ttotal: 5.92s\tremaining: 33.1s\n",
            "303:\tlearn: 0.5168875\ttotal: 5.94s\tremaining: 33.2s\n",
            "304:\tlearn: 0.5168301\ttotal: 5.96s\tremaining: 33.1s\n",
            "305:\tlearn: 0.5167921\ttotal: 5.98s\tremaining: 33.1s\n",
            "306:\tlearn: 0.5167421\ttotal: 6s\tremaining: 33.1s\n",
            "307:\tlearn: 0.5166853\ttotal: 6.02s\tremaining: 33.1s\n",
            "308:\tlearn: 0.5166388\ttotal: 6.04s\tremaining: 33.1s\n",
            "309:\tlearn: 0.5165407\ttotal: 6.06s\tremaining: 33s\n",
            "310:\tlearn: 0.5164762\ttotal: 6.08s\tremaining: 33s\n",
            "311:\tlearn: 0.5164300\ttotal: 6.1s\tremaining: 33s\n",
            "312:\tlearn: 0.5164115\ttotal: 6.12s\tremaining: 33s\n",
            "313:\tlearn: 0.5163750\ttotal: 6.14s\tremaining: 33s\n",
            "314:\tlearn: 0.5163241\ttotal: 6.16s\tremaining: 33s\n",
            "315:\tlearn: 0.5162710\ttotal: 6.18s\tremaining: 32.9s\n",
            "316:\tlearn: 0.5161967\ttotal: 6.2s\tremaining: 32.9s\n",
            "317:\tlearn: 0.5161555\ttotal: 6.22s\tremaining: 32.9s\n",
            "318:\tlearn: 0.5160277\ttotal: 6.25s\tremaining: 32.9s\n",
            "319:\tlearn: 0.5160083\ttotal: 6.27s\tremaining: 32.9s\n",
            "320:\tlearn: 0.5159505\ttotal: 6.29s\tremaining: 32.9s\n",
            "321:\tlearn: 0.5159225\ttotal: 6.3s\tremaining: 32.9s\n",
            "322:\tlearn: 0.5158864\ttotal: 6.32s\tremaining: 32.8s\n",
            "323:\tlearn: 0.5158050\ttotal: 6.34s\tremaining: 32.8s\n",
            "324:\tlearn: 0.5157830\ttotal: 6.37s\tremaining: 32.8s\n",
            "325:\tlearn: 0.5157340\ttotal: 6.39s\tremaining: 32.8s\n",
            "326:\tlearn: 0.5157055\ttotal: 6.41s\tremaining: 32.8s\n",
            "327:\tlearn: 0.5156512\ttotal: 6.43s\tremaining: 32.8s\n",
            "328:\tlearn: 0.5155297\ttotal: 6.45s\tremaining: 32.8s\n",
            "329:\tlearn: 0.5154947\ttotal: 6.47s\tremaining: 32.7s\n",
            "330:\tlearn: 0.5154204\ttotal: 6.49s\tremaining: 32.7s\n",
            "331:\tlearn: 0.5153429\ttotal: 6.51s\tremaining: 32.7s\n",
            "332:\tlearn: 0.5152925\ttotal: 6.53s\tremaining: 32.7s\n",
            "333:\tlearn: 0.5152648\ttotal: 6.55s\tremaining: 32.7s\n",
            "334:\tlearn: 0.5152418\ttotal: 6.57s\tremaining: 32.7s\n",
            "335:\tlearn: 0.5151602\ttotal: 6.59s\tremaining: 32.7s\n",
            "336:\tlearn: 0.5151107\ttotal: 6.61s\tremaining: 32.6s\n",
            "337:\tlearn: 0.5150805\ttotal: 6.63s\tremaining: 32.6s\n",
            "338:\tlearn: 0.5150332\ttotal: 6.65s\tremaining: 32.6s\n",
            "339:\tlearn: 0.5149720\ttotal: 6.67s\tremaining: 32.6s\n",
            "340:\tlearn: 0.5149246\ttotal: 6.69s\tremaining: 32.5s\n",
            "341:\tlearn: 0.5148686\ttotal: 6.71s\tremaining: 32.5s\n",
            "342:\tlearn: 0.5148204\ttotal: 6.72s\tremaining: 32.5s\n",
            "343:\tlearn: 0.5147875\ttotal: 6.74s\tremaining: 32.5s\n",
            "344:\tlearn: 0.5147533\ttotal: 6.76s\tremaining: 32.4s\n",
            "345:\tlearn: 0.5147175\ttotal: 6.79s\tremaining: 32.5s\n",
            "346:\tlearn: 0.5146476\ttotal: 6.81s\tremaining: 32.4s\n",
            "347:\tlearn: 0.5145276\ttotal: 6.83s\tremaining: 32.4s\n",
            "348:\tlearn: 0.5144586\ttotal: 6.84s\tremaining: 32.4s\n",
            "349:\tlearn: 0.5144105\ttotal: 6.87s\tremaining: 32.4s\n",
            "350:\tlearn: 0.5143782\ttotal: 6.89s\tremaining: 32.4s\n",
            "351:\tlearn: 0.5143200\ttotal: 6.91s\tremaining: 32.3s\n",
            "352:\tlearn: 0.5142835\ttotal: 6.92s\tremaining: 32.3s\n",
            "353:\tlearn: 0.5142269\ttotal: 6.94s\tremaining: 32.3s\n",
            "354:\tlearn: 0.5141809\ttotal: 6.96s\tremaining: 32.3s\n",
            "355:\tlearn: 0.5141538\ttotal: 6.98s\tremaining: 32.2s\n",
            "356:\tlearn: 0.5140806\ttotal: 7s\tremaining: 32.2s\n",
            "357:\tlearn: 0.5140396\ttotal: 7.02s\tremaining: 32.2s\n",
            "358:\tlearn: 0.5139874\ttotal: 7.04s\tremaining: 32.2s\n",
            "359:\tlearn: 0.5139421\ttotal: 7.06s\tremaining: 32.2s\n",
            "360:\tlearn: 0.5138928\ttotal: 7.08s\tremaining: 32.2s\n",
            "361:\tlearn: 0.5138308\ttotal: 7.1s\tremaining: 32.1s\n",
            "362:\tlearn: 0.5137288\ttotal: 7.12s\tremaining: 32.1s\n",
            "363:\tlearn: 0.5136707\ttotal: 7.14s\tremaining: 32.1s\n",
            "364:\tlearn: 0.5136420\ttotal: 7.16s\tremaining: 32.1s\n",
            "365:\tlearn: 0.5135756\ttotal: 7.17s\tremaining: 32s\n",
            "366:\tlearn: 0.5135214\ttotal: 7.19s\tremaining: 32s\n",
            "367:\tlearn: 0.5134620\ttotal: 7.22s\tremaining: 32s\n",
            "368:\tlearn: 0.5134340\ttotal: 7.25s\tremaining: 32s\n",
            "369:\tlearn: 0.5134004\ttotal: 7.27s\tremaining: 32s\n",
            "370:\tlearn: 0.5133473\ttotal: 7.29s\tremaining: 32s\n",
            "371:\tlearn: 0.5133129\ttotal: 7.3s\tremaining: 32s\n",
            "372:\tlearn: 0.5132535\ttotal: 7.32s\tremaining: 31.9s\n",
            "373:\tlearn: 0.5132241\ttotal: 7.35s\tremaining: 31.9s\n",
            "374:\tlearn: 0.5131949\ttotal: 7.37s\tremaining: 31.9s\n",
            "375:\tlearn: 0.5131567\ttotal: 7.39s\tremaining: 31.9s\n",
            "376:\tlearn: 0.5131124\ttotal: 7.41s\tremaining: 31.9s\n",
            "377:\tlearn: 0.5130550\ttotal: 7.43s\tremaining: 31.9s\n",
            "378:\tlearn: 0.5129533\ttotal: 7.45s\tremaining: 31.9s\n",
            "379:\tlearn: 0.5128933\ttotal: 7.47s\tremaining: 31.8s\n",
            "380:\tlearn: 0.5127900\ttotal: 7.49s\tremaining: 31.8s\n",
            "381:\tlearn: 0.5127327\ttotal: 7.51s\tremaining: 31.8s\n",
            "382:\tlearn: 0.5126920\ttotal: 7.53s\tremaining: 31.8s\n",
            "383:\tlearn: 0.5126503\ttotal: 7.54s\tremaining: 31.8s\n",
            "384:\tlearn: 0.5126070\ttotal: 7.56s\tremaining: 31.7s\n",
            "385:\tlearn: 0.5125631\ttotal: 7.58s\tremaining: 31.7s\n",
            "386:\tlearn: 0.5125202\ttotal: 7.6s\tremaining: 31.7s\n",
            "387:\tlearn: 0.5124522\ttotal: 7.62s\tremaining: 31.7s\n",
            "388:\tlearn: 0.5124174\ttotal: 7.64s\tremaining: 31.7s\n",
            "389:\tlearn: 0.5123583\ttotal: 7.66s\tremaining: 31.6s\n",
            "390:\tlearn: 0.5123166\ttotal: 7.68s\tremaining: 31.6s\n",
            "391:\tlearn: 0.5122672\ttotal: 7.7s\tremaining: 31.6s\n",
            "392:\tlearn: 0.5122205\ttotal: 7.72s\tremaining: 31.6s\n",
            "393:\tlearn: 0.5121760\ttotal: 7.74s\tremaining: 31.5s\n",
            "394:\tlearn: 0.5121200\ttotal: 7.75s\tremaining: 31.5s\n",
            "395:\tlearn: 0.5120339\ttotal: 7.77s\tremaining: 31.5s\n",
            "396:\tlearn: 0.5119604\ttotal: 7.79s\tremaining: 31.5s\n",
            "397:\tlearn: 0.5118915\ttotal: 7.81s\tremaining: 31.4s\n",
            "398:\tlearn: 0.5118155\ttotal: 7.83s\tremaining: 31.4s\n",
            "399:\tlearn: 0.5117766\ttotal: 7.86s\tremaining: 31.4s\n",
            "400:\tlearn: 0.5117343\ttotal: 7.88s\tremaining: 31.4s\n",
            "401:\tlearn: 0.5116421\ttotal: 7.89s\tremaining: 31.4s\n",
            "402:\tlearn: 0.5115964\ttotal: 7.91s\tremaining: 31.4s\n",
            "403:\tlearn: 0.5115305\ttotal: 7.93s\tremaining: 31.3s\n",
            "404:\tlearn: 0.5114840\ttotal: 7.95s\tremaining: 31.3s\n",
            "405:\tlearn: 0.5114223\ttotal: 7.97s\tremaining: 31.3s\n",
            "406:\tlearn: 0.5113766\ttotal: 7.99s\tremaining: 31.3s\n",
            "407:\tlearn: 0.5113366\ttotal: 8.01s\tremaining: 31.2s\n",
            "408:\tlearn: 0.5112610\ttotal: 8.03s\tremaining: 31.2s\n",
            "409:\tlearn: 0.5112204\ttotal: 8.04s\tremaining: 31.2s\n",
            "410:\tlearn: 0.5111780\ttotal: 8.07s\tremaining: 31.2s\n",
            "411:\tlearn: 0.5111322\ttotal: 8.09s\tremaining: 31.2s\n",
            "412:\tlearn: 0.5110666\ttotal: 8.11s\tremaining: 31.1s\n",
            "413:\tlearn: 0.5110160\ttotal: 8.12s\tremaining: 31.1s\n",
            "414:\tlearn: 0.5109682\ttotal: 8.14s\tremaining: 31.1s\n",
            "415:\tlearn: 0.5109162\ttotal: 8.16s\tremaining: 31.1s\n",
            "416:\tlearn: 0.5108577\ttotal: 8.18s\tremaining: 31.1s\n",
            "417:\tlearn: 0.5108010\ttotal: 8.2s\tremaining: 31s\n",
            "418:\tlearn: 0.5107446\ttotal: 8.22s\tremaining: 31s\n",
            "419:\tlearn: 0.5106774\ttotal: 8.25s\tremaining: 31s\n",
            "420:\tlearn: 0.5105639\ttotal: 8.27s\tremaining: 31s\n",
            "421:\tlearn: 0.5105118\ttotal: 8.29s\tremaining: 31s\n",
            "422:\tlearn: 0.5104463\ttotal: 8.31s\tremaining: 31s\n",
            "423:\tlearn: 0.5103863\ttotal: 8.33s\tremaining: 31s\n",
            "424:\tlearn: 0.5103191\ttotal: 8.35s\tremaining: 30.9s\n",
            "425:\tlearn: 0.5102747\ttotal: 8.37s\tremaining: 30.9s\n",
            "426:\tlearn: 0.5102259\ttotal: 8.39s\tremaining: 30.9s\n",
            "427:\tlearn: 0.5101993\ttotal: 8.41s\tremaining: 30.9s\n",
            "428:\tlearn: 0.5101052\ttotal: 8.43s\tremaining: 30.9s\n",
            "429:\tlearn: 0.5100782\ttotal: 8.44s\tremaining: 30.8s\n",
            "430:\tlearn: 0.5099913\ttotal: 8.46s\tremaining: 30.8s\n",
            "431:\tlearn: 0.5099161\ttotal: 8.49s\tremaining: 30.8s\n",
            "432:\tlearn: 0.5098693\ttotal: 8.51s\tremaining: 30.8s\n",
            "433:\tlearn: 0.5098407\ttotal: 8.53s\tremaining: 30.8s\n",
            "434:\tlearn: 0.5097801\ttotal: 8.54s\tremaining: 30.7s\n",
            "435:\tlearn: 0.5097210\ttotal: 8.56s\tremaining: 30.7s\n",
            "436:\tlearn: 0.5096757\ttotal: 8.58s\tremaining: 30.7s\n",
            "437:\tlearn: 0.5096415\ttotal: 8.6s\tremaining: 30.7s\n",
            "438:\tlearn: 0.5095727\ttotal: 8.62s\tremaining: 30.6s\n",
            "439:\tlearn: 0.5095281\ttotal: 8.63s\tremaining: 30.6s\n",
            "440:\tlearn: 0.5094885\ttotal: 8.65s\tremaining: 30.6s\n",
            "441:\tlearn: 0.5093604\ttotal: 8.68s\tremaining: 30.6s\n",
            "442:\tlearn: 0.5093092\ttotal: 8.7s\tremaining: 30.6s\n",
            "443:\tlearn: 0.5092484\ttotal: 8.71s\tremaining: 30.5s\n",
            "444:\tlearn: 0.5091943\ttotal: 8.73s\tremaining: 30.5s\n",
            "445:\tlearn: 0.5091518\ttotal: 8.75s\tremaining: 30.5s\n",
            "446:\tlearn: 0.5091074\ttotal: 8.77s\tremaining: 30.5s\n",
            "447:\tlearn: 0.5090665\ttotal: 8.79s\tremaining: 30.4s\n",
            "448:\tlearn: 0.5090357\ttotal: 8.81s\tremaining: 30.4s\n",
            "449:\tlearn: 0.5089735\ttotal: 8.82s\tremaining: 30.4s\n",
            "450:\tlearn: 0.5088960\ttotal: 8.84s\tremaining: 30.4s\n",
            "451:\tlearn: 0.5088302\ttotal: 8.87s\tremaining: 30.4s\n",
            "452:\tlearn: 0.5087797\ttotal: 8.89s\tremaining: 30.4s\n",
            "453:\tlearn: 0.5087007\ttotal: 8.91s\tremaining: 30.3s\n",
            "454:\tlearn: 0.5086206\ttotal: 8.93s\tremaining: 30.3s\n",
            "455:\tlearn: 0.5085349\ttotal: 8.95s\tremaining: 30.3s\n",
            "456:\tlearn: 0.5084615\ttotal: 8.97s\tremaining: 30.3s\n",
            "457:\tlearn: 0.5083812\ttotal: 8.98s\tremaining: 30.3s\n",
            "458:\tlearn: 0.5083232\ttotal: 9.01s\tremaining: 30.2s\n",
            "459:\tlearn: 0.5082717\ttotal: 9.02s\tremaining: 30.2s\n",
            "460:\tlearn: 0.5081752\ttotal: 9.04s\tremaining: 30.2s\n",
            "461:\tlearn: 0.5081019\ttotal: 9.06s\tremaining: 30.2s\n",
            "462:\tlearn: 0.5080213\ttotal: 9.08s\tremaining: 30.1s\n",
            "463:\tlearn: 0.5079625\ttotal: 9.1s\tremaining: 30.1s\n",
            "464:\tlearn: 0.5079215\ttotal: 9.12s\tremaining: 30.1s\n",
            "465:\tlearn: 0.5078814\ttotal: 9.14s\tremaining: 30.1s\n",
            "466:\tlearn: 0.5078071\ttotal: 9.16s\tremaining: 30.1s\n",
            "467:\tlearn: 0.5077382\ttotal: 9.18s\tremaining: 30s\n",
            "468:\tlearn: 0.5076638\ttotal: 9.2s\tremaining: 30s\n",
            "469:\tlearn: 0.5075667\ttotal: 9.21s\tremaining: 30s\n",
            "470:\tlearn: 0.5075248\ttotal: 9.24s\tremaining: 30s\n",
            "471:\tlearn: 0.5074949\ttotal: 9.26s\tremaining: 30s\n",
            "472:\tlearn: 0.5074062\ttotal: 9.28s\tremaining: 30s\n",
            "473:\tlearn: 0.5073631\ttotal: 9.3s\tremaining: 29.9s\n",
            "474:\tlearn: 0.5073033\ttotal: 9.32s\tremaining: 29.9s\n",
            "475:\tlearn: 0.5072435\ttotal: 9.35s\tremaining: 29.9s\n",
            "476:\tlearn: 0.5071946\ttotal: 9.37s\tremaining: 29.9s\n",
            "477:\tlearn: 0.5071553\ttotal: 9.38s\tremaining: 29.9s\n",
            "478:\tlearn: 0.5070839\ttotal: 9.4s\tremaining: 29.9s\n",
            "479:\tlearn: 0.5070335\ttotal: 9.42s\tremaining: 29.8s\n",
            "480:\tlearn: 0.5069471\ttotal: 9.44s\tremaining: 29.8s\n",
            "481:\tlearn: 0.5069100\ttotal: 9.46s\tremaining: 29.8s\n",
            "482:\tlearn: 0.5068271\ttotal: 9.48s\tremaining: 29.8s\n",
            "483:\tlearn: 0.5067733\ttotal: 9.5s\tremaining: 29.8s\n",
            "484:\tlearn: 0.5066482\ttotal: 9.52s\tremaining: 29.7s\n",
            "485:\tlearn: 0.5065733\ttotal: 9.54s\tremaining: 29.7s\n",
            "486:\tlearn: 0.5065399\ttotal: 9.56s\tremaining: 29.7s\n",
            "487:\tlearn: 0.5064873\ttotal: 9.58s\tremaining: 29.7s\n",
            "488:\tlearn: 0.5064411\ttotal: 9.6s\tremaining: 29.7s\n",
            "489:\tlearn: 0.5063945\ttotal: 9.62s\tremaining: 29.6s\n",
            "490:\tlearn: 0.5063185\ttotal: 9.64s\tremaining: 29.6s\n",
            "491:\tlearn: 0.5062654\ttotal: 9.66s\tremaining: 29.6s\n",
            "492:\tlearn: 0.5062226\ttotal: 9.68s\tremaining: 29.6s\n",
            "493:\tlearn: 0.5061532\ttotal: 9.7s\tremaining: 29.6s\n",
            "494:\tlearn: 0.5060801\ttotal: 9.71s\tremaining: 29.5s\n",
            "495:\tlearn: 0.5060188\ttotal: 9.73s\tremaining: 29.5s\n",
            "496:\tlearn: 0.5059608\ttotal: 9.76s\tremaining: 29.5s\n",
            "497:\tlearn: 0.5059217\ttotal: 9.78s\tremaining: 29.5s\n",
            "498:\tlearn: 0.5058719\ttotal: 9.8s\tremaining: 29.5s\n",
            "499:\tlearn: 0.5058157\ttotal: 9.82s\tremaining: 29.5s\n",
            "500:\tlearn: 0.5057483\ttotal: 9.84s\tremaining: 29.4s\n",
            "501:\tlearn: 0.5056964\ttotal: 9.86s\tremaining: 29.4s\n",
            "502:\tlearn: 0.5056680\ttotal: 9.88s\tremaining: 29.4s\n",
            "503:\tlearn: 0.5056070\ttotal: 9.89s\tremaining: 29.4s\n",
            "504:\tlearn: 0.5055431\ttotal: 9.91s\tremaining: 29.3s\n",
            "505:\tlearn: 0.5054831\ttotal: 9.93s\tremaining: 29.3s\n",
            "506:\tlearn: 0.5054460\ttotal: 9.95s\tremaining: 29.3s\n",
            "507:\tlearn: 0.5053626\ttotal: 9.98s\tremaining: 29.3s\n",
            "508:\tlearn: 0.5053053\ttotal: 9.99s\tremaining: 29.3s\n",
            "509:\tlearn: 0.5052485\ttotal: 10s\tremaining: 29.3s\n",
            "510:\tlearn: 0.5052054\ttotal: 10s\tremaining: 29.2s\n",
            "511:\tlearn: 0.5051659\ttotal: 10.1s\tremaining: 29.2s\n",
            "512:\tlearn: 0.5051157\ttotal: 10.1s\tremaining: 29.2s\n",
            "513:\tlearn: 0.5050348\ttotal: 10.1s\tremaining: 29.2s\n",
            "514:\tlearn: 0.5049788\ttotal: 10.1s\tremaining: 29.1s\n",
            "515:\tlearn: 0.5049262\ttotal: 10.1s\tremaining: 29.1s\n",
            "516:\tlearn: 0.5048617\ttotal: 10.1s\tremaining: 29.1s\n",
            "517:\tlearn: 0.5048080\ttotal: 10.2s\tremaining: 29.1s\n",
            "518:\tlearn: 0.5047606\ttotal: 10.2s\tremaining: 29.1s\n",
            "519:\tlearn: 0.5047337\ttotal: 10.2s\tremaining: 29s\n",
            "520:\tlearn: 0.5046641\ttotal: 10.2s\tremaining: 29s\n",
            "521:\tlearn: 0.5045961\ttotal: 10.3s\tremaining: 29s\n",
            "522:\tlearn: 0.5045514\ttotal: 10.3s\tremaining: 29s\n",
            "523:\tlearn: 0.5045095\ttotal: 10.3s\tremaining: 29s\n",
            "524:\tlearn: 0.5044574\ttotal: 10.3s\tremaining: 29s\n",
            "525:\tlearn: 0.5044168\ttotal: 10.3s\tremaining: 28.9s\n",
            "526:\tlearn: 0.5043695\ttotal: 10.3s\tremaining: 28.9s\n",
            "527:\tlearn: 0.5043220\ttotal: 10.4s\tremaining: 28.9s\n",
            "528:\tlearn: 0.5042682\ttotal: 10.4s\tremaining: 28.9s\n",
            "529:\tlearn: 0.5042310\ttotal: 10.4s\tremaining: 28.9s\n",
            "530:\tlearn: 0.5041814\ttotal: 10.4s\tremaining: 28.9s\n",
            "531:\tlearn: 0.5041231\ttotal: 10.5s\tremaining: 28.8s\n",
            "532:\tlearn: 0.5040650\ttotal: 10.5s\tremaining: 28.8s\n",
            "533:\tlearn: 0.5039972\ttotal: 10.5s\tremaining: 28.8s\n",
            "534:\tlearn: 0.5038835\ttotal: 10.5s\tremaining: 28.8s\n",
            "535:\tlearn: 0.5038331\ttotal: 10.5s\tremaining: 28.7s\n",
            "536:\tlearn: 0.5037909\ttotal: 10.5s\tremaining: 28.7s\n",
            "537:\tlearn: 0.5037303\ttotal: 10.6s\tremaining: 28.7s\n",
            "538:\tlearn: 0.5036864\ttotal: 10.6s\tremaining: 28.7s\n",
            "539:\tlearn: 0.5036354\ttotal: 10.6s\tremaining: 28.7s\n",
            "540:\tlearn: 0.5035653\ttotal: 10.6s\tremaining: 28.7s\n",
            "541:\tlearn: 0.5035085\ttotal: 10.6s\tremaining: 28.6s\n",
            "542:\tlearn: 0.5034610\ttotal: 10.7s\tremaining: 28.6s\n",
            "543:\tlearn: 0.5033997\ttotal: 10.7s\tremaining: 28.6s\n",
            "544:\tlearn: 0.5033199\ttotal: 10.7s\tremaining: 28.6s\n",
            "545:\tlearn: 0.5032627\ttotal: 10.7s\tremaining: 28.6s\n",
            "546:\tlearn: 0.5032199\ttotal: 10.7s\tremaining: 28.5s\n",
            "547:\tlearn: 0.5031553\ttotal: 10.8s\tremaining: 28.5s\n",
            "548:\tlearn: 0.5030973\ttotal: 10.8s\tremaining: 28.5s\n",
            "549:\tlearn: 0.5030431\ttotal: 10.8s\tremaining: 28.5s\n",
            "550:\tlearn: 0.5030068\ttotal: 10.8s\tremaining: 28.5s\n",
            "551:\tlearn: 0.5029601\ttotal: 10.8s\tremaining: 28.4s\n",
            "552:\tlearn: 0.5028664\ttotal: 10.9s\tremaining: 28.4s\n",
            "553:\tlearn: 0.5027874\ttotal: 10.9s\tremaining: 28.4s\n",
            "554:\tlearn: 0.5027247\ttotal: 10.9s\tremaining: 28.4s\n",
            "555:\tlearn: 0.5026753\ttotal: 10.9s\tremaining: 28.4s\n",
            "556:\tlearn: 0.5026189\ttotal: 10.9s\tremaining: 28.3s\n",
            "557:\tlearn: 0.5025462\ttotal: 11s\tremaining: 28.3s\n",
            "558:\tlearn: 0.5024772\ttotal: 11s\tremaining: 28.3s\n",
            "559:\tlearn: 0.5024317\ttotal: 11s\tremaining: 28.3s\n",
            "560:\tlearn: 0.5023653\ttotal: 11s\tremaining: 28.2s\n",
            "561:\tlearn: 0.5023278\ttotal: 11s\tremaining: 28.2s\n",
            "562:\tlearn: 0.5022898\ttotal: 11.1s\tremaining: 28.2s\n",
            "563:\tlearn: 0.5022541\ttotal: 11.1s\tremaining: 28.2s\n",
            "564:\tlearn: 0.5022210\ttotal: 11.1s\tremaining: 28.2s\n",
            "565:\tlearn: 0.5021799\ttotal: 11.1s\tremaining: 28.1s\n",
            "566:\tlearn: 0.5021428\ttotal: 11.1s\tremaining: 28.1s\n",
            "567:\tlearn: 0.5021025\ttotal: 11.1s\tremaining: 28.1s\n",
            "568:\tlearn: 0.5020698\ttotal: 11.2s\tremaining: 28.1s\n",
            "569:\tlearn: 0.5020205\ttotal: 11.2s\tremaining: 28.1s\n",
            "570:\tlearn: 0.5019545\ttotal: 11.2s\tremaining: 28s\n",
            "571:\tlearn: 0.5018964\ttotal: 11.2s\tremaining: 28s\n",
            "572:\tlearn: 0.5018300\ttotal: 11.2s\tremaining: 28s\n",
            "573:\tlearn: 0.5017690\ttotal: 11.3s\tremaining: 28s\n",
            "574:\tlearn: 0.5017227\ttotal: 11.3s\tremaining: 28s\n",
            "575:\tlearn: 0.5016579\ttotal: 11.3s\tremaining: 28s\n",
            "576:\tlearn: 0.5016175\ttotal: 11.3s\tremaining: 27.9s\n",
            "577:\tlearn: 0.5015764\ttotal: 11.3s\tremaining: 27.9s\n",
            "578:\tlearn: 0.5015221\ttotal: 11.4s\tremaining: 27.9s\n",
            "579:\tlearn: 0.5014579\ttotal: 11.4s\tremaining: 27.9s\n",
            "580:\tlearn: 0.5014047\ttotal: 11.4s\tremaining: 27.9s\n",
            "581:\tlearn: 0.5013697\ttotal: 11.4s\tremaining: 27.8s\n",
            "582:\tlearn: 0.5013227\ttotal: 11.4s\tremaining: 27.8s\n",
            "583:\tlearn: 0.5012758\ttotal: 11.5s\tremaining: 27.8s\n",
            "584:\tlearn: 0.5012266\ttotal: 11.5s\tremaining: 27.8s\n",
            "585:\tlearn: 0.5011709\ttotal: 11.5s\tremaining: 27.8s\n",
            "586:\tlearn: 0.5011221\ttotal: 11.5s\tremaining: 27.7s\n",
            "587:\tlearn: 0.5010529\ttotal: 11.5s\tremaining: 27.7s\n",
            "588:\tlearn: 0.5010079\ttotal: 11.6s\tremaining: 27.7s\n",
            "589:\tlearn: 0.5009311\ttotal: 11.6s\tremaining: 27.7s\n",
            "590:\tlearn: 0.5008898\ttotal: 11.6s\tremaining: 27.6s\n",
            "591:\tlearn: 0.5008391\ttotal: 11.6s\tremaining: 27.6s\n",
            "592:\tlearn: 0.5007981\ttotal: 11.6s\tremaining: 27.6s\n",
            "593:\tlearn: 0.5007523\ttotal: 11.7s\tremaining: 27.6s\n",
            "594:\tlearn: 0.5006660\ttotal: 11.7s\tremaining: 27.6s\n",
            "595:\tlearn: 0.5005961\ttotal: 11.7s\tremaining: 27.6s\n",
            "596:\tlearn: 0.5005230\ttotal: 11.7s\tremaining: 27.5s\n",
            "597:\tlearn: 0.5004651\ttotal: 11.7s\tremaining: 27.5s\n",
            "598:\tlearn: 0.5004035\ttotal: 11.8s\tremaining: 27.5s\n",
            "599:\tlearn: 0.5003635\ttotal: 11.8s\tremaining: 27.5s\n",
            "600:\tlearn: 0.5002984\ttotal: 11.8s\tremaining: 27.4s\n",
            "601:\tlearn: 0.5002452\ttotal: 11.8s\tremaining: 27.4s\n",
            "602:\tlearn: 0.5002049\ttotal: 11.8s\tremaining: 27.4s\n",
            "603:\tlearn: 0.5001685\ttotal: 11.8s\tremaining: 27.4s\n",
            "604:\tlearn: 0.5001133\ttotal: 11.9s\tremaining: 27.4s\n",
            "605:\tlearn: 0.5000810\ttotal: 11.9s\tremaining: 27.4s\n",
            "606:\tlearn: 0.5000114\ttotal: 11.9s\tremaining: 27.3s\n",
            "607:\tlearn: 0.4999603\ttotal: 11.9s\tremaining: 27.3s\n",
            "608:\tlearn: 0.4998904\ttotal: 11.9s\tremaining: 27.3s\n",
            "609:\tlearn: 0.4998215\ttotal: 12s\tremaining: 27.3s\n",
            "610:\tlearn: 0.4997629\ttotal: 12s\tremaining: 27.2s\n",
            "611:\tlearn: 0.4997093\ttotal: 12s\tremaining: 27.2s\n",
            "612:\tlearn: 0.4996600\ttotal: 12s\tremaining: 27.2s\n",
            "613:\tlearn: 0.4996402\ttotal: 12s\tremaining: 27.2s\n",
            "614:\tlearn: 0.4995902\ttotal: 12.1s\tremaining: 27.2s\n",
            "615:\tlearn: 0.4995156\ttotal: 12.1s\tremaining: 27.1s\n",
            "616:\tlearn: 0.4994624\ttotal: 12.1s\tremaining: 27.1s\n",
            "617:\tlearn: 0.4994035\ttotal: 12.1s\tremaining: 27.1s\n",
            "618:\tlearn: 0.4993493\ttotal: 12.1s\tremaining: 27.1s\n",
            "619:\tlearn: 0.4993006\ttotal: 12.2s\tremaining: 27.1s\n",
            "620:\tlearn: 0.4992605\ttotal: 12.2s\tremaining: 27s\n",
            "621:\tlearn: 0.4991951\ttotal: 12.2s\tremaining: 27s\n",
            "622:\tlearn: 0.4991481\ttotal: 12.2s\tremaining: 27s\n",
            "623:\tlearn: 0.4991101\ttotal: 12.2s\tremaining: 27s\n",
            "624:\tlearn: 0.4990599\ttotal: 12.3s\tremaining: 27s\n",
            "625:\tlearn: 0.4990063\ttotal: 12.3s\tremaining: 27s\n",
            "626:\tlearn: 0.4989511\ttotal: 12.3s\tremaining: 27s\n",
            "627:\tlearn: 0.4989033\ttotal: 12.3s\tremaining: 26.9s\n",
            "628:\tlearn: 0.4988667\ttotal: 12.3s\tremaining: 26.9s\n",
            "629:\tlearn: 0.4988274\ttotal: 12.4s\tremaining: 26.9s\n",
            "630:\tlearn: 0.4987570\ttotal: 12.4s\tremaining: 26.9s\n",
            "631:\tlearn: 0.4987106\ttotal: 12.4s\tremaining: 26.9s\n",
            "632:\tlearn: 0.4986627\ttotal: 12.4s\tremaining: 26.8s\n",
            "633:\tlearn: 0.4986155\ttotal: 12.4s\tremaining: 26.8s\n",
            "634:\tlearn: 0.4985524\ttotal: 12.5s\tremaining: 26.8s\n",
            "635:\tlearn: 0.4984802\ttotal: 12.5s\tremaining: 26.8s\n",
            "636:\tlearn: 0.4984210\ttotal: 12.5s\tremaining: 26.8s\n",
            "637:\tlearn: 0.4983795\ttotal: 12.5s\tremaining: 26.7s\n",
            "638:\tlearn: 0.4983465\ttotal: 12.5s\tremaining: 26.7s\n",
            "639:\tlearn: 0.4982803\ttotal: 12.6s\tremaining: 26.7s\n",
            "640:\tlearn: 0.4982298\ttotal: 12.6s\tremaining: 26.7s\n",
            "641:\tlearn: 0.4981984\ttotal: 12.6s\tremaining: 26.7s\n",
            "642:\tlearn: 0.4981288\ttotal: 12.6s\tremaining: 26.6s\n",
            "643:\tlearn: 0.4980946\ttotal: 12.6s\tremaining: 26.6s\n",
            "644:\tlearn: 0.4980173\ttotal: 12.7s\tremaining: 26.6s\n",
            "645:\tlearn: 0.4979767\ttotal: 12.7s\tremaining: 26.6s\n",
            "646:\tlearn: 0.4979321\ttotal: 12.7s\tremaining: 26.6s\n",
            "647:\tlearn: 0.4978953\ttotal: 12.7s\tremaining: 26.5s\n",
            "648:\tlearn: 0.4978423\ttotal: 12.7s\tremaining: 26.5s\n",
            "649:\tlearn: 0.4977927\ttotal: 12.8s\tremaining: 26.5s\n",
            "650:\tlearn: 0.4977399\ttotal: 12.8s\tremaining: 26.5s\n",
            "651:\tlearn: 0.4976879\ttotal: 12.8s\tremaining: 26.5s\n",
            "652:\tlearn: 0.4976370\ttotal: 12.8s\tremaining: 26.4s\n",
            "653:\tlearn: 0.4975822\ttotal: 12.8s\tremaining: 26.4s\n",
            "654:\tlearn: 0.4975270\ttotal: 12.9s\tremaining: 26.4s\n",
            "655:\tlearn: 0.4974925\ttotal: 12.9s\tremaining: 26.4s\n",
            "656:\tlearn: 0.4974563\ttotal: 12.9s\tremaining: 26.3s\n",
            "657:\tlearn: 0.4974309\ttotal: 12.9s\tremaining: 26.3s\n",
            "658:\tlearn: 0.4973892\ttotal: 12.9s\tremaining: 26.3s\n",
            "659:\tlearn: 0.4973473\ttotal: 13s\tremaining: 26.3s\n",
            "660:\tlearn: 0.4972874\ttotal: 13s\tremaining: 26.3s\n",
            "661:\tlearn: 0.4972167\ttotal: 13s\tremaining: 26.3s\n",
            "662:\tlearn: 0.4971764\ttotal: 13s\tremaining: 26.2s\n",
            "663:\tlearn: 0.4971126\ttotal: 13s\tremaining: 26.2s\n",
            "664:\tlearn: 0.4970624\ttotal: 13.1s\tremaining: 26.2s\n",
            "665:\tlearn: 0.4970083\ttotal: 13.1s\tremaining: 26.2s\n",
            "666:\tlearn: 0.4969618\ttotal: 13.1s\tremaining: 26.2s\n",
            "667:\tlearn: 0.4968767\ttotal: 13.1s\tremaining: 26.1s\n",
            "668:\tlearn: 0.4968365\ttotal: 13.1s\tremaining: 26.1s\n",
            "669:\tlearn: 0.4967982\ttotal: 13.1s\tremaining: 26.1s\n",
            "670:\tlearn: 0.4967662\ttotal: 13.2s\tremaining: 26.1s\n",
            "671:\tlearn: 0.4967082\ttotal: 13.2s\tremaining: 26.1s\n",
            "672:\tlearn: 0.4966771\ttotal: 13.2s\tremaining: 26s\n",
            "673:\tlearn: 0.4966287\ttotal: 13.2s\tremaining: 26s\n",
            "674:\tlearn: 0.4965945\ttotal: 13.3s\tremaining: 26s\n",
            "675:\tlearn: 0.4965584\ttotal: 13.3s\tremaining: 26s\n",
            "676:\tlearn: 0.4965282\ttotal: 13.3s\tremaining: 26s\n",
            "677:\tlearn: 0.4964805\ttotal: 13.3s\tremaining: 25.9s\n",
            "678:\tlearn: 0.4964338\ttotal: 13.3s\tremaining: 25.9s\n",
            "679:\tlearn: 0.4963901\ttotal: 13.3s\tremaining: 25.9s\n",
            "680:\tlearn: 0.4963546\ttotal: 13.4s\tremaining: 25.9s\n",
            "681:\tlearn: 0.4963291\ttotal: 13.4s\tremaining: 25.9s\n",
            "682:\tlearn: 0.4962945\ttotal: 13.4s\tremaining: 25.8s\n",
            "683:\tlearn: 0.4962383\ttotal: 13.4s\tremaining: 25.8s\n",
            "684:\tlearn: 0.4961834\ttotal: 13.5s\tremaining: 25.8s\n",
            "685:\tlearn: 0.4961445\ttotal: 13.5s\tremaining: 25.8s\n",
            "686:\tlearn: 0.4961030\ttotal: 13.5s\tremaining: 25.8s\n",
            "687:\tlearn: 0.4960603\ttotal: 13.5s\tremaining: 25.8s\n",
            "688:\tlearn: 0.4960138\ttotal: 13.5s\tremaining: 25.8s\n",
            "689:\tlearn: 0.4959709\ttotal: 13.6s\tremaining: 25.7s\n",
            "690:\tlearn: 0.4959436\ttotal: 13.6s\tremaining: 25.7s\n",
            "691:\tlearn: 0.4958868\ttotal: 13.6s\tremaining: 25.7s\n",
            "692:\tlearn: 0.4958250\ttotal: 13.6s\tremaining: 25.7s\n",
            "693:\tlearn: 0.4957753\ttotal: 13.6s\tremaining: 25.7s\n",
            "694:\tlearn: 0.4957476\ttotal: 13.7s\tremaining: 25.6s\n",
            "695:\tlearn: 0.4957109\ttotal: 13.7s\tremaining: 25.6s\n",
            "696:\tlearn: 0.4956793\ttotal: 13.7s\tremaining: 25.6s\n",
            "697:\tlearn: 0.4956453\ttotal: 13.7s\tremaining: 25.6s\n",
            "698:\tlearn: 0.4955826\ttotal: 13.7s\tremaining: 25.6s\n",
            "699:\tlearn: 0.4955350\ttotal: 13.8s\tremaining: 25.5s\n",
            "700:\tlearn: 0.4954852\ttotal: 13.8s\tremaining: 25.5s\n",
            "701:\tlearn: 0.4954386\ttotal: 13.8s\tremaining: 25.5s\n",
            "702:\tlearn: 0.4953991\ttotal: 13.8s\tremaining: 25.5s\n",
            "703:\tlearn: 0.4953364\ttotal: 13.8s\tremaining: 25.5s\n",
            "704:\tlearn: 0.4953009\ttotal: 13.8s\tremaining: 25.4s\n",
            "705:\tlearn: 0.4952541\ttotal: 13.9s\tremaining: 25.4s\n",
            "706:\tlearn: 0.4952089\ttotal: 13.9s\tremaining: 25.4s\n",
            "707:\tlearn: 0.4951704\ttotal: 13.9s\tremaining: 25.4s\n",
            "708:\tlearn: 0.4951223\ttotal: 13.9s\tremaining: 25.4s\n",
            "709:\tlearn: 0.4950794\ttotal: 13.9s\tremaining: 25.3s\n",
            "710:\tlearn: 0.4950395\ttotal: 14s\tremaining: 25.3s\n",
            "711:\tlearn: 0.4949755\ttotal: 14s\tremaining: 25.3s\n",
            "712:\tlearn: 0.4949299\ttotal: 14s\tremaining: 25.3s\n",
            "713:\tlearn: 0.4948939\ttotal: 14s\tremaining: 25.3s\n",
            "714:\tlearn: 0.4948466\ttotal: 14s\tremaining: 25.2s\n",
            "715:\tlearn: 0.4948087\ttotal: 14.1s\tremaining: 25.2s\n",
            "716:\tlearn: 0.4947523\ttotal: 14.1s\tremaining: 25.2s\n",
            "717:\tlearn: 0.4946773\ttotal: 14.1s\tremaining: 25.2s\n",
            "718:\tlearn: 0.4946230\ttotal: 14.1s\tremaining: 25.1s\n",
            "719:\tlearn: 0.4945830\ttotal: 14.1s\tremaining: 25.1s\n",
            "720:\tlearn: 0.4945419\ttotal: 14.2s\tremaining: 25.1s\n",
            "721:\tlearn: 0.4945033\ttotal: 14.2s\tremaining: 25.1s\n",
            "722:\tlearn: 0.4944723\ttotal: 14.2s\tremaining: 25.1s\n",
            "723:\tlearn: 0.4944211\ttotal: 14.2s\tremaining: 25s\n",
            "724:\tlearn: 0.4943727\ttotal: 14.2s\tremaining: 25s\n",
            "725:\tlearn: 0.4943152\ttotal: 14.3s\tremaining: 25s\n",
            "726:\tlearn: 0.4942595\ttotal: 14.3s\tremaining: 25s\n",
            "727:\tlearn: 0.4942180\ttotal: 14.3s\tremaining: 25s\n",
            "728:\tlearn: 0.4941746\ttotal: 14.3s\tremaining: 25s\n",
            "729:\tlearn: 0.4941348\ttotal: 14.3s\tremaining: 25s\n",
            "730:\tlearn: 0.4941010\ttotal: 14.4s\tremaining: 24.9s\n",
            "731:\tlearn: 0.4940573\ttotal: 14.4s\tremaining: 24.9s\n",
            "732:\tlearn: 0.4939894\ttotal: 14.4s\tremaining: 24.9s\n",
            "733:\tlearn: 0.4939513\ttotal: 14.4s\tremaining: 24.9s\n",
            "734:\tlearn: 0.4939007\ttotal: 14.4s\tremaining: 24.9s\n",
            "735:\tlearn: 0.4938608\ttotal: 14.5s\tremaining: 24.8s\n",
            "736:\tlearn: 0.4938278\ttotal: 14.5s\tremaining: 24.8s\n",
            "737:\tlearn: 0.4937880\ttotal: 14.5s\tremaining: 24.8s\n",
            "738:\tlearn: 0.4937237\ttotal: 14.5s\tremaining: 24.8s\n",
            "739:\tlearn: 0.4936792\ttotal: 14.5s\tremaining: 24.8s\n",
            "740:\tlearn: 0.4936362\ttotal: 14.6s\tremaining: 24.7s\n",
            "741:\tlearn: 0.4936004\ttotal: 14.6s\tremaining: 24.7s\n",
            "742:\tlearn: 0.4935616\ttotal: 14.6s\tremaining: 24.7s\n",
            "743:\tlearn: 0.4935064\ttotal: 14.6s\tremaining: 24.7s\n",
            "744:\tlearn: 0.4934724\ttotal: 14.6s\tremaining: 24.6s\n",
            "745:\tlearn: 0.4934383\ttotal: 14.7s\tremaining: 24.6s\n",
            "746:\tlearn: 0.4933815\ttotal: 14.7s\tremaining: 24.6s\n",
            "747:\tlearn: 0.4933309\ttotal: 14.7s\tremaining: 24.6s\n",
            "748:\tlearn: 0.4932788\ttotal: 14.7s\tremaining: 24.6s\n",
            "749:\tlearn: 0.4932378\ttotal: 14.7s\tremaining: 24.5s\n",
            "750:\tlearn: 0.4931863\ttotal: 14.7s\tremaining: 24.5s\n",
            "751:\tlearn: 0.4931401\ttotal: 14.8s\tremaining: 24.5s\n",
            "752:\tlearn: 0.4931123\ttotal: 14.8s\tremaining: 24.5s\n",
            "753:\tlearn: 0.4930809\ttotal: 14.8s\tremaining: 24.5s\n",
            "754:\tlearn: 0.4930119\ttotal: 14.8s\tremaining: 24.4s\n",
            "755:\tlearn: 0.4929754\ttotal: 14.8s\tremaining: 24.4s\n",
            "756:\tlearn: 0.4929432\ttotal: 14.9s\tremaining: 24.4s\n",
            "757:\tlearn: 0.4929068\ttotal: 14.9s\tremaining: 24.4s\n",
            "758:\tlearn: 0.4928684\ttotal: 14.9s\tremaining: 24.4s\n",
            "759:\tlearn: 0.4928289\ttotal: 14.9s\tremaining: 24.3s\n",
            "760:\tlearn: 0.4927789\ttotal: 14.9s\tremaining: 24.3s\n",
            "761:\tlearn: 0.4927361\ttotal: 15s\tremaining: 24.3s\n",
            "762:\tlearn: 0.4927026\ttotal: 15s\tremaining: 24.3s\n",
            "763:\tlearn: 0.4926619\ttotal: 15s\tremaining: 24.3s\n",
            "764:\tlearn: 0.4926225\ttotal: 15s\tremaining: 24.2s\n",
            "765:\tlearn: 0.4925756\ttotal: 15s\tremaining: 24.2s\n",
            "766:\tlearn: 0.4925235\ttotal: 15.1s\tremaining: 24.2s\n",
            "767:\tlearn: 0.4924629\ttotal: 15.1s\tremaining: 24.2s\n",
            "768:\tlearn: 0.4924190\ttotal: 15.1s\tremaining: 24.2s\n",
            "769:\tlearn: 0.4923585\ttotal: 15.1s\tremaining: 24.1s\n",
            "770:\tlearn: 0.4923124\ttotal: 15.1s\tremaining: 24.1s\n",
            "771:\tlearn: 0.4922759\ttotal: 15.2s\tremaining: 24.1s\n",
            "772:\tlearn: 0.4922418\ttotal: 15.2s\tremaining: 24.1s\n",
            "773:\tlearn: 0.4921997\ttotal: 15.2s\tremaining: 24.1s\n",
            "774:\tlearn: 0.4921370\ttotal: 15.2s\tremaining: 24s\n",
            "775:\tlearn: 0.4920842\ttotal: 15.2s\tremaining: 24s\n",
            "776:\tlearn: 0.4920429\ttotal: 15.3s\tremaining: 24s\n",
            "777:\tlearn: 0.4919448\ttotal: 15.3s\tremaining: 24s\n",
            "778:\tlearn: 0.4919001\ttotal: 15.3s\tremaining: 24s\n",
            "779:\tlearn: 0.4918642\ttotal: 15.3s\tremaining: 24s\n",
            "780:\tlearn: 0.4918286\ttotal: 15.3s\tremaining: 23.9s\n",
            "781:\tlearn: 0.4917958\ttotal: 15.4s\tremaining: 23.9s\n",
            "782:\tlearn: 0.4917509\ttotal: 15.4s\tremaining: 23.9s\n",
            "783:\tlearn: 0.4917080\ttotal: 15.4s\tremaining: 23.9s\n",
            "784:\tlearn: 0.4916767\ttotal: 15.4s\tremaining: 23.9s\n",
            "785:\tlearn: 0.4916370\ttotal: 15.4s\tremaining: 23.8s\n",
            "786:\tlearn: 0.4915802\ttotal: 15.5s\tremaining: 23.8s\n",
            "787:\tlearn: 0.4915436\ttotal: 15.5s\tremaining: 23.8s\n",
            "788:\tlearn: 0.4914975\ttotal: 15.5s\tremaining: 23.8s\n",
            "789:\tlearn: 0.4914737\ttotal: 15.5s\tremaining: 23.8s\n",
            "790:\tlearn: 0.4914292\ttotal: 15.5s\tremaining: 23.7s\n",
            "791:\tlearn: 0.4914036\ttotal: 15.6s\tremaining: 23.7s\n",
            "792:\tlearn: 0.4913486\ttotal: 15.6s\tremaining: 23.7s\n",
            "793:\tlearn: 0.4913125\ttotal: 15.6s\tremaining: 23.7s\n",
            "794:\tlearn: 0.4912625\ttotal: 15.6s\tremaining: 23.7s\n",
            "795:\tlearn: 0.4912189\ttotal: 15.6s\tremaining: 23.6s\n",
            "796:\tlearn: 0.4911799\ttotal: 15.7s\tremaining: 23.6s\n",
            "797:\tlearn: 0.4911241\ttotal: 15.7s\tremaining: 23.6s\n",
            "798:\tlearn: 0.4910787\ttotal: 15.7s\tremaining: 23.6s\n",
            "799:\tlearn: 0.4910445\ttotal: 15.7s\tremaining: 23.6s\n",
            "800:\tlearn: 0.4909787\ttotal: 15.7s\tremaining: 23.6s\n",
            "801:\tlearn: 0.4909265\ttotal: 15.8s\tremaining: 23.5s\n",
            "802:\tlearn: 0.4908926\ttotal: 15.8s\tremaining: 23.5s\n",
            "803:\tlearn: 0.4908548\ttotal: 15.8s\tremaining: 23.5s\n",
            "804:\tlearn: 0.4908120\ttotal: 15.8s\tremaining: 23.5s\n",
            "805:\tlearn: 0.4907632\ttotal: 15.8s\tremaining: 23.5s\n",
            "806:\tlearn: 0.4907307\ttotal: 15.9s\tremaining: 23.4s\n",
            "807:\tlearn: 0.4906817\ttotal: 15.9s\tremaining: 23.4s\n",
            "808:\tlearn: 0.4906402\ttotal: 15.9s\tremaining: 23.4s\n",
            "809:\tlearn: 0.4905853\ttotal: 15.9s\tremaining: 23.4s\n",
            "810:\tlearn: 0.4905547\ttotal: 15.9s\tremaining: 23.4s\n",
            "811:\tlearn: 0.4905008\ttotal: 16s\tremaining: 23.4s\n",
            "812:\tlearn: 0.4904585\ttotal: 16s\tremaining: 23.3s\n",
            "813:\tlearn: 0.4904145\ttotal: 16s\tremaining: 23.3s\n",
            "814:\tlearn: 0.4903882\ttotal: 16s\tremaining: 23.3s\n",
            "815:\tlearn: 0.4903662\ttotal: 16s\tremaining: 23.3s\n",
            "816:\tlearn: 0.4903147\ttotal: 16.1s\tremaining: 23.3s\n",
            "817:\tlearn: 0.4902913\ttotal: 16.1s\tremaining: 23.2s\n",
            "818:\tlearn: 0.4902312\ttotal: 16.1s\tremaining: 23.2s\n",
            "819:\tlearn: 0.4901837\ttotal: 16.1s\tremaining: 23.2s\n",
            "820:\tlearn: 0.4901357\ttotal: 16.1s\tremaining: 23.2s\n",
            "821:\tlearn: 0.4900864\ttotal: 16.2s\tremaining: 23.2s\n",
            "822:\tlearn: 0.4900537\ttotal: 16.2s\tremaining: 23.2s\n",
            "823:\tlearn: 0.4900151\ttotal: 16.2s\tremaining: 23.1s\n",
            "824:\tlearn: 0.4899833\ttotal: 16.2s\tremaining: 23.1s\n",
            "825:\tlearn: 0.4899442\ttotal: 16.3s\tremaining: 23.1s\n",
            "826:\tlearn: 0.4898829\ttotal: 16.3s\tremaining: 23.1s\n",
            "827:\tlearn: 0.4898487\ttotal: 16.3s\tremaining: 23.1s\n",
            "828:\tlearn: 0.4898010\ttotal: 16.3s\tremaining: 23.1s\n",
            "829:\tlearn: 0.4897595\ttotal: 16.3s\tremaining: 23s\n",
            "830:\tlearn: 0.4897308\ttotal: 16.4s\tremaining: 23s\n",
            "831:\tlearn: 0.4896750\ttotal: 16.4s\tremaining: 23s\n",
            "832:\tlearn: 0.4896431\ttotal: 16.4s\tremaining: 23s\n",
            "833:\tlearn: 0.4896065\ttotal: 16.4s\tremaining: 23s\n",
            "834:\tlearn: 0.4895630\ttotal: 16.4s\tremaining: 22.9s\n",
            "835:\tlearn: 0.4895091\ttotal: 16.5s\tremaining: 22.9s\n",
            "836:\tlearn: 0.4894822\ttotal: 16.5s\tremaining: 22.9s\n",
            "837:\tlearn: 0.4894314\ttotal: 16.5s\tremaining: 22.9s\n",
            "838:\tlearn: 0.4893949\ttotal: 16.5s\tremaining: 22.9s\n",
            "839:\tlearn: 0.4893464\ttotal: 16.5s\tremaining: 22.8s\n",
            "840:\tlearn: 0.4893115\ttotal: 16.6s\tremaining: 22.8s\n",
            "841:\tlearn: 0.4892637\ttotal: 16.6s\tremaining: 22.8s\n",
            "842:\tlearn: 0.4892315\ttotal: 16.6s\tremaining: 22.8s\n",
            "843:\tlearn: 0.4891834\ttotal: 16.6s\tremaining: 22.8s\n",
            "844:\tlearn: 0.4891500\ttotal: 16.6s\tremaining: 22.7s\n",
            "845:\tlearn: 0.4891095\ttotal: 16.7s\tremaining: 22.7s\n",
            "846:\tlearn: 0.4890642\ttotal: 16.7s\tremaining: 22.7s\n",
            "847:\tlearn: 0.4890355\ttotal: 16.7s\tremaining: 22.7s\n",
            "848:\tlearn: 0.4889800\ttotal: 16.7s\tremaining: 22.7s\n",
            "849:\tlearn: 0.4889446\ttotal: 16.7s\tremaining: 22.6s\n",
            "850:\tlearn: 0.4888860\ttotal: 16.8s\tremaining: 22.6s\n",
            "851:\tlearn: 0.4888459\ttotal: 16.8s\tremaining: 22.6s\n",
            "852:\tlearn: 0.4887966\ttotal: 16.8s\tremaining: 22.6s\n",
            "853:\tlearn: 0.4887551\ttotal: 16.8s\tremaining: 22.6s\n",
            "854:\tlearn: 0.4887292\ttotal: 16.8s\tremaining: 22.5s\n",
            "855:\tlearn: 0.4886866\ttotal: 16.9s\tremaining: 22.5s\n",
            "856:\tlearn: 0.4886545\ttotal: 16.9s\tremaining: 22.5s\n",
            "857:\tlearn: 0.4886170\ttotal: 16.9s\tremaining: 22.5s\n",
            "858:\tlearn: 0.4885845\ttotal: 16.9s\tremaining: 22.5s\n",
            "859:\tlearn: 0.4885329\ttotal: 16.9s\tremaining: 22.4s\n",
            "860:\tlearn: 0.4885052\ttotal: 16.9s\tremaining: 22.4s\n",
            "861:\tlearn: 0.4884530\ttotal: 17s\tremaining: 22.4s\n",
            "862:\tlearn: 0.4884153\ttotal: 17s\tremaining: 22.4s\n",
            "863:\tlearn: 0.4883737\ttotal: 17s\tremaining: 22.4s\n",
            "864:\tlearn: 0.4883346\ttotal: 17s\tremaining: 22.3s\n",
            "865:\tlearn: 0.4883009\ttotal: 17.1s\tremaining: 22.3s\n",
            "866:\tlearn: 0.4882524\ttotal: 17.1s\tremaining: 22.3s\n",
            "867:\tlearn: 0.4882189\ttotal: 17.1s\tremaining: 22.3s\n",
            "868:\tlearn: 0.4881825\ttotal: 17.1s\tremaining: 22.3s\n",
            "869:\tlearn: 0.4881317\ttotal: 17.1s\tremaining: 22.2s\n",
            "870:\tlearn: 0.4880921\ttotal: 17.1s\tremaining: 22.2s\n",
            "871:\tlearn: 0.4880746\ttotal: 17.2s\tremaining: 22.2s\n",
            "872:\tlearn: 0.4880297\ttotal: 17.2s\tremaining: 22.2s\n",
            "873:\tlearn: 0.4880012\ttotal: 17.2s\tremaining: 22.2s\n",
            "874:\tlearn: 0.4879548\ttotal: 17.2s\tremaining: 22.2s\n",
            "875:\tlearn: 0.4879262\ttotal: 17.3s\tremaining: 22.1s\n",
            "876:\tlearn: 0.4878881\ttotal: 17.3s\tremaining: 22.1s\n",
            "877:\tlearn: 0.4878472\ttotal: 17.3s\tremaining: 22.1s\n",
            "878:\tlearn: 0.4878079\ttotal: 17.3s\tremaining: 22.1s\n",
            "879:\tlearn: 0.4877788\ttotal: 17.3s\tremaining: 22.1s\n",
            "880:\tlearn: 0.4877331\ttotal: 17.4s\tremaining: 22s\n",
            "881:\tlearn: 0.4876922\ttotal: 17.4s\tremaining: 22s\n",
            "882:\tlearn: 0.4876591\ttotal: 17.4s\tremaining: 22s\n",
            "883:\tlearn: 0.4876209\ttotal: 17.4s\tremaining: 22s\n",
            "884:\tlearn: 0.4875845\ttotal: 17.4s\tremaining: 22s\n",
            "885:\tlearn: 0.4875495\ttotal: 17.4s\tremaining: 21.9s\n",
            "886:\tlearn: 0.4875089\ttotal: 17.5s\tremaining: 21.9s\n",
            "887:\tlearn: 0.4874701\ttotal: 17.5s\tremaining: 21.9s\n",
            "888:\tlearn: 0.4874365\ttotal: 17.5s\tremaining: 21.9s\n",
            "889:\tlearn: 0.4874120\ttotal: 17.5s\tremaining: 21.9s\n",
            "890:\tlearn: 0.4873865\ttotal: 17.5s\tremaining: 21.8s\n",
            "891:\tlearn: 0.4873496\ttotal: 17.6s\tremaining: 21.8s\n",
            "892:\tlearn: 0.4872859\ttotal: 17.6s\tremaining: 21.8s\n",
            "893:\tlearn: 0.4872626\ttotal: 17.6s\tremaining: 21.8s\n",
            "894:\tlearn: 0.4872071\ttotal: 17.6s\tremaining: 21.8s\n",
            "895:\tlearn: 0.4871679\ttotal: 17.6s\tremaining: 21.7s\n",
            "896:\tlearn: 0.4871120\ttotal: 17.7s\tremaining: 21.7s\n",
            "897:\tlearn: 0.4870523\ttotal: 17.7s\tremaining: 21.7s\n",
            "898:\tlearn: 0.4870166\ttotal: 17.7s\tremaining: 21.7s\n",
            "899:\tlearn: 0.4869814\ttotal: 17.7s\tremaining: 21.7s\n",
            "900:\tlearn: 0.4869361\ttotal: 17.7s\tremaining: 21.6s\n",
            "901:\tlearn: 0.4868898\ttotal: 17.8s\tremaining: 21.6s\n",
            "902:\tlearn: 0.4868449\ttotal: 17.8s\tremaining: 21.6s\n",
            "903:\tlearn: 0.4868042\ttotal: 17.8s\tremaining: 21.6s\n",
            "904:\tlearn: 0.4867244\ttotal: 17.8s\tremaining: 21.6s\n",
            "905:\tlearn: 0.4866655\ttotal: 17.8s\tremaining: 21.5s\n",
            "906:\tlearn: 0.4866269\ttotal: 17.9s\tremaining: 21.5s\n",
            "907:\tlearn: 0.4865782\ttotal: 17.9s\tremaining: 21.5s\n",
            "908:\tlearn: 0.4865448\ttotal: 17.9s\tremaining: 21.5s\n",
            "909:\tlearn: 0.4865024\ttotal: 17.9s\tremaining: 21.5s\n",
            "910:\tlearn: 0.4864703\ttotal: 17.9s\tremaining: 21.4s\n",
            "911:\tlearn: 0.4864316\ttotal: 18s\tremaining: 21.4s\n",
            "912:\tlearn: 0.4863978\ttotal: 18s\tremaining: 21.4s\n",
            "913:\tlearn: 0.4863697\ttotal: 18s\tremaining: 21.4s\n",
            "914:\tlearn: 0.4863335\ttotal: 18s\tremaining: 21.4s\n",
            "915:\tlearn: 0.4862968\ttotal: 18s\tremaining: 21.3s\n",
            "916:\tlearn: 0.4862575\ttotal: 18s\tremaining: 21.3s\n",
            "917:\tlearn: 0.4862316\ttotal: 18.1s\tremaining: 21.3s\n",
            "918:\tlearn: 0.4861882\ttotal: 18.1s\tremaining: 21.3s\n",
            "919:\tlearn: 0.4861424\ttotal: 18.1s\tremaining: 21.3s\n",
            "920:\tlearn: 0.4860941\ttotal: 18.1s\tremaining: 21.2s\n",
            "921:\tlearn: 0.4860485\ttotal: 18.1s\tremaining: 21.2s\n",
            "922:\tlearn: 0.4859863\ttotal: 18.2s\tremaining: 21.2s\n",
            "923:\tlearn: 0.4859506\ttotal: 18.2s\tremaining: 21.2s\n",
            "924:\tlearn: 0.4858688\ttotal: 18.2s\tremaining: 21.2s\n",
            "925:\tlearn: 0.4858306\ttotal: 18.2s\tremaining: 21.1s\n",
            "926:\tlearn: 0.4857517\ttotal: 18.2s\tremaining: 21.1s\n",
            "927:\tlearn: 0.4857124\ttotal: 18.3s\tremaining: 21.1s\n",
            "928:\tlearn: 0.4856585\ttotal: 18.3s\tremaining: 21.1s\n",
            "929:\tlearn: 0.4856136\ttotal: 18.3s\tremaining: 21.1s\n",
            "930:\tlearn: 0.4855700\ttotal: 18.3s\tremaining: 21.1s\n",
            "931:\tlearn: 0.4855219\ttotal: 18.4s\tremaining: 21s\n",
            "932:\tlearn: 0.4854892\ttotal: 18.4s\tremaining: 21s\n",
            "933:\tlearn: 0.4854375\ttotal: 18.4s\tremaining: 21s\n",
            "934:\tlearn: 0.4853687\ttotal: 18.4s\tremaining: 21s\n",
            "935:\tlearn: 0.4852987\ttotal: 18.4s\tremaining: 21s\n",
            "936:\tlearn: 0.4852563\ttotal: 18.5s\tremaining: 20.9s\n",
            "937:\tlearn: 0.4852211\ttotal: 18.5s\tremaining: 20.9s\n",
            "938:\tlearn: 0.4851825\ttotal: 18.5s\tremaining: 20.9s\n",
            "939:\tlearn: 0.4851473\ttotal: 18.5s\tremaining: 20.9s\n",
            "940:\tlearn: 0.4851085\ttotal: 18.5s\tremaining: 20.9s\n",
            "941:\tlearn: 0.4850758\ttotal: 18.6s\tremaining: 20.8s\n",
            "942:\tlearn: 0.4850330\ttotal: 18.6s\tremaining: 20.8s\n",
            "943:\tlearn: 0.4849860\ttotal: 18.6s\tremaining: 20.8s\n",
            "944:\tlearn: 0.4849469\ttotal: 18.6s\tremaining: 20.8s\n",
            "945:\tlearn: 0.4848990\ttotal: 18.6s\tremaining: 20.8s\n",
            "946:\tlearn: 0.4848629\ttotal: 18.7s\tremaining: 20.7s\n",
            "947:\tlearn: 0.4848169\ttotal: 18.7s\tremaining: 20.7s\n",
            "948:\tlearn: 0.4847777\ttotal: 18.7s\tremaining: 20.7s\n",
            "949:\tlearn: 0.4847471\ttotal: 18.7s\tremaining: 20.7s\n",
            "950:\tlearn: 0.4847217\ttotal: 18.7s\tremaining: 20.7s\n",
            "951:\tlearn: 0.4846974\ttotal: 18.8s\tremaining: 20.6s\n",
            "952:\tlearn: 0.4846589\ttotal: 18.8s\tremaining: 20.6s\n",
            "953:\tlearn: 0.4846352\ttotal: 18.8s\tremaining: 20.6s\n",
            "954:\tlearn: 0.4845949\ttotal: 18.8s\tremaining: 20.6s\n",
            "955:\tlearn: 0.4845626\ttotal: 18.8s\tremaining: 20.6s\n",
            "956:\tlearn: 0.4845273\ttotal: 18.8s\tremaining: 20.5s\n",
            "957:\tlearn: 0.4844779\ttotal: 18.9s\tremaining: 20.5s\n",
            "958:\tlearn: 0.4844345\ttotal: 18.9s\tremaining: 20.5s\n",
            "959:\tlearn: 0.4843969\ttotal: 18.9s\tremaining: 20.5s\n",
            "960:\tlearn: 0.4843474\ttotal: 18.9s\tremaining: 20.5s\n",
            "961:\tlearn: 0.4843159\ttotal: 18.9s\tremaining: 20.4s\n",
            "962:\tlearn: 0.4842581\ttotal: 19s\tremaining: 20.4s\n",
            "963:\tlearn: 0.4842099\ttotal: 19s\tremaining: 20.4s\n",
            "964:\tlearn: 0.4841655\ttotal: 19s\tremaining: 20.4s\n",
            "965:\tlearn: 0.4841219\ttotal: 19s\tremaining: 20.4s\n",
            "966:\tlearn: 0.4840779\ttotal: 19s\tremaining: 20.3s\n",
            "967:\tlearn: 0.4840449\ttotal: 19.1s\tremaining: 20.3s\n",
            "968:\tlearn: 0.4840015\ttotal: 19.1s\tremaining: 20.3s\n",
            "969:\tlearn: 0.4839590\ttotal: 19.1s\tremaining: 20.3s\n",
            "970:\tlearn: 0.4839222\ttotal: 19.1s\tremaining: 20.3s\n",
            "971:\tlearn: 0.4838827\ttotal: 19.1s\tremaining: 20.2s\n",
            "972:\tlearn: 0.4838412\ttotal: 19.2s\tremaining: 20.2s\n",
            "973:\tlearn: 0.4838096\ttotal: 19.2s\tremaining: 20.2s\n",
            "974:\tlearn: 0.4837685\ttotal: 19.2s\tremaining: 20.2s\n",
            "975:\tlearn: 0.4837362\ttotal: 19.2s\tremaining: 20.2s\n",
            "976:\tlearn: 0.4836864\ttotal: 19.2s\tremaining: 20.1s\n",
            "977:\tlearn: 0.4836376\ttotal: 19.3s\tremaining: 20.1s\n",
            "978:\tlearn: 0.4835979\ttotal: 19.3s\tremaining: 20.1s\n",
            "979:\tlearn: 0.4835568\ttotal: 19.3s\tremaining: 20.1s\n",
            "980:\tlearn: 0.4835368\ttotal: 19.3s\tremaining: 20.1s\n",
            "981:\tlearn: 0.4835061\ttotal: 19.3s\tremaining: 20s\n",
            "982:\tlearn: 0.4834746\ttotal: 19.4s\tremaining: 20s\n",
            "983:\tlearn: 0.4834284\ttotal: 19.4s\tremaining: 20s\n",
            "984:\tlearn: 0.4833999\ttotal: 19.4s\tremaining: 20s\n",
            "985:\tlearn: 0.4833529\ttotal: 19.4s\tremaining: 20s\n",
            "986:\tlearn: 0.4832998\ttotal: 19.4s\tremaining: 20s\n",
            "987:\tlearn: 0.4832670\ttotal: 19.5s\tremaining: 19.9s\n",
            "988:\tlearn: 0.4832356\ttotal: 19.5s\tremaining: 19.9s\n",
            "989:\tlearn: 0.4831940\ttotal: 19.5s\tremaining: 19.9s\n",
            "990:\tlearn: 0.4831460\ttotal: 19.5s\tremaining: 19.9s\n",
            "991:\tlearn: 0.4831063\ttotal: 19.5s\tremaining: 19.9s\n",
            "992:\tlearn: 0.4830578\ttotal: 19.6s\tremaining: 19.8s\n",
            "993:\tlearn: 0.4830144\ttotal: 19.6s\tremaining: 19.8s\n",
            "994:\tlearn: 0.4829817\ttotal: 19.6s\tremaining: 19.8s\n",
            "995:\tlearn: 0.4829263\ttotal: 19.6s\tremaining: 19.8s\n",
            "996:\tlearn: 0.4828915\ttotal: 19.6s\tremaining: 19.8s\n",
            "997:\tlearn: 0.4828202\ttotal: 19.7s\tremaining: 19.7s\n",
            "998:\tlearn: 0.4827622\ttotal: 19.7s\tremaining: 19.7s\n",
            "999:\tlearn: 0.4827291\ttotal: 19.7s\tremaining: 19.7s\n",
            "1000:\tlearn: 0.4826829\ttotal: 19.7s\tremaining: 19.7s\n",
            "1001:\tlearn: 0.4826514\ttotal: 19.7s\tremaining: 19.7s\n",
            "1002:\tlearn: 0.4826055\ttotal: 19.8s\tremaining: 19.6s\n",
            "1003:\tlearn: 0.4825771\ttotal: 19.8s\tremaining: 19.6s\n",
            "1004:\tlearn: 0.4825359\ttotal: 19.8s\tremaining: 19.6s\n",
            "1005:\tlearn: 0.4824799\ttotal: 19.8s\tremaining: 19.6s\n",
            "1006:\tlearn: 0.4824539\ttotal: 19.8s\tremaining: 19.6s\n",
            "1007:\tlearn: 0.4824039\ttotal: 19.8s\tremaining: 19.5s\n",
            "1008:\tlearn: 0.4823742\ttotal: 19.9s\tremaining: 19.5s\n",
            "1009:\tlearn: 0.4823372\ttotal: 19.9s\tremaining: 19.5s\n",
            "1010:\tlearn: 0.4822993\ttotal: 19.9s\tremaining: 19.5s\n",
            "1011:\tlearn: 0.4822734\ttotal: 19.9s\tremaining: 19.5s\n",
            "1012:\tlearn: 0.4822505\ttotal: 19.9s\tremaining: 19.4s\n",
            "1013:\tlearn: 0.4822150\ttotal: 20s\tremaining: 19.4s\n",
            "1014:\tlearn: 0.4821574\ttotal: 20s\tremaining: 19.4s\n",
            "1015:\tlearn: 0.4821108\ttotal: 20s\tremaining: 19.4s\n",
            "1016:\tlearn: 0.4820571\ttotal: 20s\tremaining: 19.4s\n",
            "1017:\tlearn: 0.4820038\ttotal: 20s\tremaining: 19.3s\n",
            "1018:\tlearn: 0.4819600\ttotal: 20.1s\tremaining: 19.3s\n",
            "1019:\tlearn: 0.4819198\ttotal: 20.1s\tremaining: 19.3s\n",
            "1020:\tlearn: 0.4818842\ttotal: 20.1s\tremaining: 19.3s\n",
            "1021:\tlearn: 0.4818443\ttotal: 20.1s\tremaining: 19.2s\n",
            "1022:\tlearn: 0.4818146\ttotal: 20.1s\tremaining: 19.2s\n",
            "1023:\tlearn: 0.4817644\ttotal: 20.2s\tremaining: 19.2s\n",
            "1024:\tlearn: 0.4817258\ttotal: 20.2s\tremaining: 19.2s\n",
            "1025:\tlearn: 0.4816940\ttotal: 20.2s\tremaining: 19.2s\n",
            "1026:\tlearn: 0.4816567\ttotal: 20.2s\tremaining: 19.2s\n",
            "1027:\tlearn: 0.4816301\ttotal: 20.2s\tremaining: 19.1s\n",
            "1028:\tlearn: 0.4815900\ttotal: 20.3s\tremaining: 19.1s\n",
            "1029:\tlearn: 0.4815546\ttotal: 20.3s\tremaining: 19.1s\n",
            "1030:\tlearn: 0.4815268\ttotal: 20.3s\tremaining: 19.1s\n",
            "1031:\tlearn: 0.4814696\ttotal: 20.3s\tremaining: 19.1s\n",
            "1032:\tlearn: 0.4814196\ttotal: 20.3s\tremaining: 19s\n",
            "1033:\tlearn: 0.4813827\ttotal: 20.4s\tremaining: 19s\n",
            "1034:\tlearn: 0.4813457\ttotal: 20.4s\tremaining: 19s\n",
            "1035:\tlearn: 0.4813115\ttotal: 20.4s\tremaining: 19s\n",
            "1036:\tlearn: 0.4812674\ttotal: 20.4s\tremaining: 19s\n",
            "1037:\tlearn: 0.4812337\ttotal: 20.5s\tremaining: 19s\n",
            "1038:\tlearn: 0.4811909\ttotal: 20.5s\tremaining: 18.9s\n",
            "1039:\tlearn: 0.4811455\ttotal: 20.5s\tremaining: 18.9s\n",
            "1040:\tlearn: 0.4811088\ttotal: 20.5s\tremaining: 18.9s\n",
            "1041:\tlearn: 0.4810573\ttotal: 20.5s\tremaining: 18.9s\n",
            "1042:\tlearn: 0.4810223\ttotal: 20.6s\tremaining: 18.9s\n",
            "1043:\tlearn: 0.4809751\ttotal: 20.6s\tremaining: 18.8s\n",
            "1044:\tlearn: 0.4809365\ttotal: 20.6s\tremaining: 18.8s\n",
            "1045:\tlearn: 0.4808764\ttotal: 20.6s\tremaining: 18.8s\n",
            "1046:\tlearn: 0.4808408\ttotal: 20.6s\tremaining: 18.8s\n",
            "1047:\tlearn: 0.4808059\ttotal: 20.7s\tremaining: 18.8s\n",
            "1048:\tlearn: 0.4807194\ttotal: 20.7s\tremaining: 18.7s\n",
            "1049:\tlearn: 0.4806789\ttotal: 20.7s\tremaining: 18.7s\n",
            "1050:\tlearn: 0.4806289\ttotal: 20.7s\tremaining: 18.7s\n",
            "1051:\tlearn: 0.4805846\ttotal: 20.7s\tremaining: 18.7s\n",
            "1052:\tlearn: 0.4805371\ttotal: 20.7s\tremaining: 18.7s\n",
            "1053:\tlearn: 0.4805003\ttotal: 20.8s\tremaining: 18.6s\n",
            "1054:\tlearn: 0.4804539\ttotal: 20.8s\tremaining: 18.6s\n",
            "1055:\tlearn: 0.4803957\ttotal: 20.8s\tremaining: 18.6s\n",
            "1056:\tlearn: 0.4803576\ttotal: 20.8s\tremaining: 18.6s\n",
            "1057:\tlearn: 0.4803110\ttotal: 20.8s\tremaining: 18.6s\n",
            "1058:\tlearn: 0.4802663\ttotal: 20.9s\tremaining: 18.5s\n",
            "1059:\tlearn: 0.4802050\ttotal: 20.9s\tremaining: 18.5s\n",
            "1060:\tlearn: 0.4801560\ttotal: 20.9s\tremaining: 18.5s\n",
            "1061:\tlearn: 0.4801338\ttotal: 20.9s\tremaining: 18.5s\n",
            "1062:\tlearn: 0.4801120\ttotal: 20.9s\tremaining: 18.5s\n",
            "1063:\tlearn: 0.4800647\ttotal: 21s\tremaining: 18.4s\n",
            "1064:\tlearn: 0.4800280\ttotal: 21s\tremaining: 18.4s\n",
            "1065:\tlearn: 0.4799830\ttotal: 21s\tremaining: 18.4s\n",
            "1066:\tlearn: 0.4799553\ttotal: 21s\tremaining: 18.4s\n",
            "1067:\tlearn: 0.4799226\ttotal: 21s\tremaining: 18.4s\n",
            "1068:\tlearn: 0.4798887\ttotal: 21.1s\tremaining: 18.3s\n",
            "1069:\tlearn: 0.4798411\ttotal: 21.1s\tremaining: 18.3s\n",
            "1070:\tlearn: 0.4797833\ttotal: 21.1s\tremaining: 18.3s\n",
            "1071:\tlearn: 0.4797501\ttotal: 21.1s\tremaining: 18.3s\n",
            "1072:\tlearn: 0.4797195\ttotal: 21.1s\tremaining: 18.3s\n",
            "1073:\tlearn: 0.4796826\ttotal: 21.2s\tremaining: 18.2s\n",
            "1074:\tlearn: 0.4796453\ttotal: 21.2s\tremaining: 18.2s\n",
            "1075:\tlearn: 0.4795964\ttotal: 21.2s\tremaining: 18.2s\n",
            "1076:\tlearn: 0.4795668\ttotal: 21.2s\tremaining: 18.2s\n",
            "1077:\tlearn: 0.4795099\ttotal: 21.2s\tremaining: 18.2s\n",
            "1078:\tlearn: 0.4794651\ttotal: 21.3s\tremaining: 18.1s\n",
            "1079:\tlearn: 0.4794121\ttotal: 21.3s\tremaining: 18.1s\n",
            "1080:\tlearn: 0.4793804\ttotal: 21.3s\tremaining: 18.1s\n",
            "1081:\tlearn: 0.4793533\ttotal: 21.3s\tremaining: 18.1s\n",
            "1082:\tlearn: 0.4793030\ttotal: 21.3s\tremaining: 18.1s\n",
            "1083:\tlearn: 0.4792677\ttotal: 21.4s\tremaining: 18s\n",
            "1084:\tlearn: 0.4792334\ttotal: 21.4s\tremaining: 18s\n",
            "1085:\tlearn: 0.4791862\ttotal: 21.4s\tremaining: 18s\n",
            "1086:\tlearn: 0.4791472\ttotal: 21.4s\tremaining: 18s\n",
            "1087:\tlearn: 0.4791122\ttotal: 21.4s\tremaining: 18s\n",
            "1088:\tlearn: 0.4790522\ttotal: 21.5s\tremaining: 18s\n",
            "1089:\tlearn: 0.4790006\ttotal: 21.5s\tremaining: 17.9s\n",
            "1090:\tlearn: 0.4789643\ttotal: 21.5s\tremaining: 17.9s\n",
            "1091:\tlearn: 0.4789214\ttotal: 21.5s\tremaining: 17.9s\n",
            "1092:\tlearn: 0.4788739\ttotal: 21.5s\tremaining: 17.9s\n",
            "1093:\tlearn: 0.4788358\ttotal: 21.6s\tremaining: 17.9s\n",
            "1094:\tlearn: 0.4788043\ttotal: 21.6s\tremaining: 17.8s\n",
            "1095:\tlearn: 0.4787772\ttotal: 21.6s\tremaining: 17.8s\n",
            "1096:\tlearn: 0.4787413\ttotal: 21.6s\tremaining: 17.8s\n",
            "1097:\tlearn: 0.4787008\ttotal: 21.6s\tremaining: 17.8s\n",
            "1098:\tlearn: 0.4786453\ttotal: 21.7s\tremaining: 17.8s\n",
            "1099:\tlearn: 0.4785893\ttotal: 21.7s\tremaining: 17.7s\n",
            "1100:\tlearn: 0.4785481\ttotal: 21.7s\tremaining: 17.7s\n",
            "1101:\tlearn: 0.4785213\ttotal: 21.7s\tremaining: 17.7s\n",
            "1102:\tlearn: 0.4784793\ttotal: 21.7s\tremaining: 17.7s\n",
            "1103:\tlearn: 0.4784447\ttotal: 21.8s\tremaining: 17.7s\n",
            "1104:\tlearn: 0.4784060\ttotal: 21.8s\tremaining: 17.6s\n",
            "1105:\tlearn: 0.4783524\ttotal: 21.8s\tremaining: 17.6s\n",
            "1106:\tlearn: 0.4783117\ttotal: 21.8s\tremaining: 17.6s\n",
            "1107:\tlearn: 0.4782843\ttotal: 21.8s\tremaining: 17.6s\n",
            "1108:\tlearn: 0.4782584\ttotal: 21.8s\tremaining: 17.6s\n",
            "1109:\tlearn: 0.4782210\ttotal: 21.9s\tremaining: 17.5s\n",
            "1110:\tlearn: 0.4781728\ttotal: 21.9s\tremaining: 17.5s\n",
            "1111:\tlearn: 0.4781448\ttotal: 21.9s\tremaining: 17.5s\n",
            "1112:\tlearn: 0.4780959\ttotal: 21.9s\tremaining: 17.5s\n",
            "1113:\tlearn: 0.4780460\ttotal: 22s\tremaining: 17.5s\n",
            "1114:\tlearn: 0.4779886\ttotal: 22s\tremaining: 17.4s\n",
            "1115:\tlearn: 0.4779493\ttotal: 22s\tremaining: 17.4s\n",
            "1116:\tlearn: 0.4779216\ttotal: 22s\tremaining: 17.4s\n",
            "1117:\tlearn: 0.4778775\ttotal: 22s\tremaining: 17.4s\n",
            "1118:\tlearn: 0.4778262\ttotal: 22.1s\tremaining: 17.4s\n",
            "1119:\tlearn: 0.4777958\ttotal: 22.1s\tremaining: 17.3s\n",
            "1120:\tlearn: 0.4777573\ttotal: 22.1s\tremaining: 17.3s\n",
            "1121:\tlearn: 0.4777212\ttotal: 22.1s\tremaining: 17.3s\n",
            "1122:\tlearn: 0.4776900\ttotal: 22.1s\tremaining: 17.3s\n",
            "1123:\tlearn: 0.4776487\ttotal: 22.2s\tremaining: 17.3s\n",
            "1124:\tlearn: 0.4776207\ttotal: 22.2s\tremaining: 17.2s\n",
            "1125:\tlearn: 0.4775974\ttotal: 22.2s\tremaining: 17.2s\n",
            "1126:\tlearn: 0.4775675\ttotal: 22.2s\tremaining: 17.2s\n",
            "1127:\tlearn: 0.4775139\ttotal: 22.2s\tremaining: 17.2s\n",
            "1128:\tlearn: 0.4774854\ttotal: 22.3s\tremaining: 17.2s\n",
            "1129:\tlearn: 0.4774471\ttotal: 22.3s\tremaining: 17.2s\n",
            "1130:\tlearn: 0.4774035\ttotal: 22.3s\tremaining: 17.1s\n",
            "1131:\tlearn: 0.4773590\ttotal: 22.3s\tremaining: 17.1s\n",
            "1132:\tlearn: 0.4773229\ttotal: 22.3s\tremaining: 17.1s\n",
            "1133:\tlearn: 0.4772791\ttotal: 22.4s\tremaining: 17.1s\n",
            "1134:\tlearn: 0.4772345\ttotal: 22.4s\tremaining: 17.1s\n",
            "1135:\tlearn: 0.4772145\ttotal: 22.4s\tremaining: 17s\n",
            "1136:\tlearn: 0.4771807\ttotal: 22.4s\tremaining: 17s\n",
            "1137:\tlearn: 0.4771583\ttotal: 22.4s\tremaining: 17s\n",
            "1138:\tlearn: 0.4771202\ttotal: 22.5s\tremaining: 17s\n",
            "1139:\tlearn: 0.4770757\ttotal: 22.5s\tremaining: 17s\n",
            "1140:\tlearn: 0.4770447\ttotal: 22.5s\tremaining: 16.9s\n",
            "1141:\tlearn: 0.4770194\ttotal: 22.5s\tremaining: 16.9s\n",
            "1142:\tlearn: 0.4769850\ttotal: 22.5s\tremaining: 16.9s\n",
            "1143:\tlearn: 0.4769364\ttotal: 22.5s\tremaining: 16.9s\n",
            "1144:\tlearn: 0.4768996\ttotal: 22.6s\tremaining: 16.9s\n",
            "1145:\tlearn: 0.4768410\ttotal: 22.6s\tremaining: 16.8s\n",
            "1146:\tlearn: 0.4767716\ttotal: 22.6s\tremaining: 16.8s\n",
            "1147:\tlearn: 0.4767412\ttotal: 22.6s\tremaining: 16.8s\n",
            "1148:\tlearn: 0.4767015\ttotal: 22.7s\tremaining: 16.8s\n",
            "1149:\tlearn: 0.4766659\ttotal: 22.7s\tremaining: 16.8s\n",
            "1150:\tlearn: 0.4766244\ttotal: 22.7s\tremaining: 16.7s\n",
            "1151:\tlearn: 0.4765987\ttotal: 22.7s\tremaining: 16.7s\n",
            "1152:\tlearn: 0.4765590\ttotal: 22.7s\tremaining: 16.7s\n",
            "1153:\tlearn: 0.4765300\ttotal: 22.7s\tremaining: 16.7s\n",
            "1154:\tlearn: 0.4764981\ttotal: 22.8s\tremaining: 16.7s\n",
            "1155:\tlearn: 0.4764774\ttotal: 22.8s\tremaining: 16.6s\n",
            "1156:\tlearn: 0.4764443\ttotal: 22.8s\tremaining: 16.6s\n",
            "1157:\tlearn: 0.4764182\ttotal: 22.8s\tremaining: 16.6s\n",
            "1158:\tlearn: 0.4763723\ttotal: 22.8s\tremaining: 16.6s\n",
            "1159:\tlearn: 0.4763312\ttotal: 22.9s\tremaining: 16.6s\n",
            "1160:\tlearn: 0.4763011\ttotal: 22.9s\tremaining: 16.5s\n",
            "1161:\tlearn: 0.4762686\ttotal: 22.9s\tremaining: 16.5s\n",
            "1162:\tlearn: 0.4762308\ttotal: 22.9s\tremaining: 16.5s\n",
            "1163:\tlearn: 0.4761942\ttotal: 22.9s\tremaining: 16.5s\n",
            "1164:\tlearn: 0.4761489\ttotal: 23s\tremaining: 16.5s\n",
            "1165:\tlearn: 0.4761128\ttotal: 23s\tremaining: 16.4s\n",
            "1166:\tlearn: 0.4760816\ttotal: 23s\tremaining: 16.4s\n",
            "1167:\tlearn: 0.4760431\ttotal: 23s\tremaining: 16.4s\n",
            "1168:\tlearn: 0.4760125\ttotal: 23s\tremaining: 16.4s\n",
            "1169:\tlearn: 0.4759645\ttotal: 23.1s\tremaining: 16.4s\n",
            "1170:\tlearn: 0.4759341\ttotal: 23.1s\tremaining: 16.3s\n",
            "1171:\tlearn: 0.4759008\ttotal: 23.1s\tremaining: 16.3s\n",
            "1172:\tlearn: 0.4758733\ttotal: 23.1s\tremaining: 16.3s\n",
            "1173:\tlearn: 0.4758455\ttotal: 23.1s\tremaining: 16.3s\n",
            "1174:\tlearn: 0.4758077\ttotal: 23.2s\tremaining: 16.3s\n",
            "1175:\tlearn: 0.4757579\ttotal: 23.2s\tremaining: 16.2s\n",
            "1176:\tlearn: 0.4757265\ttotal: 23.2s\tremaining: 16.2s\n",
            "1177:\tlearn: 0.4756842\ttotal: 23.2s\tremaining: 16.2s\n",
            "1178:\tlearn: 0.4756494\ttotal: 23.3s\tremaining: 16.2s\n",
            "1179:\tlearn: 0.4756068\ttotal: 23.3s\tremaining: 16.2s\n",
            "1180:\tlearn: 0.4755759\ttotal: 23.3s\tremaining: 16.2s\n",
            "1181:\tlearn: 0.4755410\ttotal: 23.3s\tremaining: 16.1s\n",
            "1182:\tlearn: 0.4755029\ttotal: 23.3s\tremaining: 16.1s\n",
            "1183:\tlearn: 0.4754653\ttotal: 23.3s\tremaining: 16.1s\n",
            "1184:\tlearn: 0.4754374\ttotal: 23.4s\tremaining: 16.1s\n",
            "1185:\tlearn: 0.4754170\ttotal: 23.4s\tremaining: 16s\n",
            "1186:\tlearn: 0.4753724\ttotal: 23.4s\tremaining: 16s\n",
            "1187:\tlearn: 0.4753270\ttotal: 23.4s\tremaining: 16s\n",
            "1188:\tlearn: 0.4752884\ttotal: 23.4s\tremaining: 16s\n",
            "1189:\tlearn: 0.4752621\ttotal: 23.5s\tremaining: 16s\n",
            "1190:\tlearn: 0.4752306\ttotal: 23.5s\tremaining: 16s\n",
            "1191:\tlearn: 0.4751874\ttotal: 23.5s\tremaining: 15.9s\n",
            "1192:\tlearn: 0.4751624\ttotal: 23.5s\tremaining: 15.9s\n",
            "1193:\tlearn: 0.4751187\ttotal: 23.5s\tremaining: 15.9s\n",
            "1194:\tlearn: 0.4750709\ttotal: 23.6s\tremaining: 15.9s\n",
            "1195:\tlearn: 0.4750223\ttotal: 23.6s\tremaining: 15.9s\n",
            "1196:\tlearn: 0.4749954\ttotal: 23.6s\tremaining: 15.8s\n",
            "1197:\tlearn: 0.4749436\ttotal: 23.6s\tremaining: 15.8s\n",
            "1198:\tlearn: 0.4749097\ttotal: 23.6s\tremaining: 15.8s\n",
            "1199:\tlearn: 0.4748706\ttotal: 23.7s\tremaining: 15.8s\n",
            "1200:\tlearn: 0.4748333\ttotal: 23.7s\tremaining: 15.8s\n",
            "1201:\tlearn: 0.4748113\ttotal: 23.7s\tremaining: 15.7s\n",
            "1202:\tlearn: 0.4747787\ttotal: 23.7s\tremaining: 15.7s\n",
            "1203:\tlearn: 0.4747480\ttotal: 23.7s\tremaining: 15.7s\n",
            "1204:\tlearn: 0.4747176\ttotal: 23.8s\tremaining: 15.7s\n",
            "1205:\tlearn: 0.4746909\ttotal: 23.8s\tremaining: 15.7s\n",
            "1206:\tlearn: 0.4746385\ttotal: 23.8s\tremaining: 15.6s\n",
            "1207:\tlearn: 0.4745921\ttotal: 23.8s\tremaining: 15.6s\n",
            "1208:\tlearn: 0.4745541\ttotal: 23.9s\tremaining: 15.6s\n",
            "1209:\tlearn: 0.4745143\ttotal: 23.9s\tremaining: 15.6s\n",
            "1210:\tlearn: 0.4744757\ttotal: 23.9s\tremaining: 15.6s\n",
            "1211:\tlearn: 0.4744344\ttotal: 23.9s\tremaining: 15.5s\n",
            "1212:\tlearn: 0.4744086\ttotal: 23.9s\tremaining: 15.5s\n",
            "1213:\tlearn: 0.4743701\ttotal: 24s\tremaining: 15.5s\n",
            "1214:\tlearn: 0.4743441\ttotal: 24s\tremaining: 15.5s\n",
            "1215:\tlearn: 0.4743021\ttotal: 24s\tremaining: 15.5s\n",
            "1216:\tlearn: 0.4742664\ttotal: 24s\tremaining: 15.4s\n",
            "1217:\tlearn: 0.4742330\ttotal: 24s\tremaining: 15.4s\n",
            "1218:\tlearn: 0.4741977\ttotal: 24.1s\tremaining: 15.4s\n",
            "1219:\tlearn: 0.4741655\ttotal: 24.1s\tremaining: 15.4s\n",
            "1220:\tlearn: 0.4741323\ttotal: 24.1s\tremaining: 15.4s\n",
            "1221:\tlearn: 0.4741071\ttotal: 24.1s\tremaining: 15.4s\n",
            "1222:\tlearn: 0.4740839\ttotal: 24.1s\tremaining: 15.3s\n",
            "1223:\tlearn: 0.4740413\ttotal: 24.2s\tremaining: 15.3s\n",
            "1224:\tlearn: 0.4740110\ttotal: 24.2s\tremaining: 15.3s\n",
            "1225:\tlearn: 0.4739753\ttotal: 24.2s\tremaining: 15.3s\n",
            "1226:\tlearn: 0.4739445\ttotal: 24.2s\tremaining: 15.3s\n",
            "1227:\tlearn: 0.4738899\ttotal: 24.2s\tremaining: 15.2s\n",
            "1228:\tlearn: 0.4738655\ttotal: 24.3s\tremaining: 15.2s\n",
            "1229:\tlearn: 0.4738343\ttotal: 24.3s\tremaining: 15.2s\n",
            "1230:\tlearn: 0.4737962\ttotal: 24.3s\tremaining: 15.2s\n",
            "1231:\tlearn: 0.4737629\ttotal: 24.3s\tremaining: 15.2s\n",
            "1232:\tlearn: 0.4737166\ttotal: 24.3s\tremaining: 15.1s\n",
            "1233:\tlearn: 0.4736797\ttotal: 24.4s\tremaining: 15.1s\n",
            "1234:\tlearn: 0.4736297\ttotal: 24.4s\tremaining: 15.1s\n",
            "1235:\tlearn: 0.4735938\ttotal: 24.4s\tremaining: 15.1s\n",
            "1236:\tlearn: 0.4735446\ttotal: 24.4s\tremaining: 15.1s\n",
            "1237:\tlearn: 0.4734961\ttotal: 24.4s\tremaining: 15s\n",
            "1238:\tlearn: 0.4734478\ttotal: 24.5s\tremaining: 15s\n",
            "1239:\tlearn: 0.4734053\ttotal: 24.5s\tremaining: 15s\n",
            "1240:\tlearn: 0.4733643\ttotal: 24.5s\tremaining: 15s\n",
            "1241:\tlearn: 0.4733259\ttotal: 24.5s\tremaining: 15s\n",
            "1242:\tlearn: 0.4732843\ttotal: 24.6s\tremaining: 15s\n",
            "1243:\tlearn: 0.4732243\ttotal: 24.6s\tremaining: 14.9s\n",
            "1244:\tlearn: 0.4731870\ttotal: 24.6s\tremaining: 14.9s\n",
            "1245:\tlearn: 0.4731584\ttotal: 24.6s\tremaining: 14.9s\n",
            "1246:\tlearn: 0.4731144\ttotal: 24.6s\tremaining: 14.9s\n",
            "1247:\tlearn: 0.4730724\ttotal: 24.6s\tremaining: 14.9s\n",
            "1248:\tlearn: 0.4730387\ttotal: 24.7s\tremaining: 14.8s\n",
            "1249:\tlearn: 0.4730112\ttotal: 24.7s\tremaining: 14.8s\n",
            "1250:\tlearn: 0.4729869\ttotal: 24.7s\tremaining: 14.8s\n",
            "1251:\tlearn: 0.4729660\ttotal: 24.7s\tremaining: 14.8s\n",
            "1252:\tlearn: 0.4729319\ttotal: 24.7s\tremaining: 14.8s\n",
            "1253:\tlearn: 0.4728823\ttotal: 24.8s\tremaining: 14.7s\n",
            "1254:\tlearn: 0.4728442\ttotal: 24.8s\tremaining: 14.7s\n",
            "1255:\tlearn: 0.4728015\ttotal: 24.8s\tremaining: 14.7s\n",
            "1256:\tlearn: 0.4727665\ttotal: 24.8s\tremaining: 14.7s\n",
            "1257:\tlearn: 0.4727368\ttotal: 24.8s\tremaining: 14.7s\n",
            "1258:\tlearn: 0.4726890\ttotal: 24.9s\tremaining: 14.6s\n",
            "1259:\tlearn: 0.4726461\ttotal: 24.9s\tremaining: 14.6s\n",
            "1260:\tlearn: 0.4726310\ttotal: 24.9s\tremaining: 14.6s\n",
            "1261:\tlearn: 0.4726055\ttotal: 24.9s\tremaining: 14.6s\n",
            "1262:\tlearn: 0.4725758\ttotal: 24.9s\tremaining: 14.6s\n",
            "1263:\tlearn: 0.4725291\ttotal: 25s\tremaining: 14.5s\n",
            "1264:\tlearn: 0.4724914\ttotal: 25s\tremaining: 14.5s\n",
            "1265:\tlearn: 0.4724615\ttotal: 25s\tremaining: 14.5s\n",
            "1266:\tlearn: 0.4724368\ttotal: 25s\tremaining: 14.5s\n",
            "1267:\tlearn: 0.4724010\ttotal: 25s\tremaining: 14.5s\n",
            "1268:\tlearn: 0.4723765\ttotal: 25.1s\tremaining: 14.4s\n",
            "1269:\tlearn: 0.4723517\ttotal: 25.1s\tremaining: 14.4s\n",
            "1270:\tlearn: 0.4723141\ttotal: 25.1s\tremaining: 14.4s\n",
            "1271:\tlearn: 0.4722890\ttotal: 25.1s\tremaining: 14.4s\n",
            "1272:\tlearn: 0.4722546\ttotal: 25.1s\tremaining: 14.4s\n",
            "1273:\tlearn: 0.4722274\ttotal: 25.2s\tremaining: 14.3s\n",
            "1274:\tlearn: 0.4721887\ttotal: 25.2s\tremaining: 14.3s\n",
            "1275:\tlearn: 0.4721581\ttotal: 25.2s\tremaining: 14.3s\n",
            "1276:\tlearn: 0.4721215\ttotal: 25.2s\tremaining: 14.3s\n",
            "1277:\tlearn: 0.4720868\ttotal: 25.3s\tremaining: 14.3s\n",
            "1278:\tlearn: 0.4720543\ttotal: 25.3s\tremaining: 14.2s\n",
            "1279:\tlearn: 0.4720264\ttotal: 25.3s\tremaining: 14.2s\n",
            "1280:\tlearn: 0.4719794\ttotal: 25.3s\tremaining: 14.2s\n",
            "1281:\tlearn: 0.4719631\ttotal: 25.3s\tremaining: 14.2s\n",
            "1282:\tlearn: 0.4719279\ttotal: 25.3s\tremaining: 14.2s\n",
            "1283:\tlearn: 0.4718865\ttotal: 25.4s\tremaining: 14.1s\n",
            "1284:\tlearn: 0.4718429\ttotal: 25.4s\tremaining: 14.1s\n",
            "1285:\tlearn: 0.4717975\ttotal: 25.4s\tremaining: 14.1s\n",
            "1286:\tlearn: 0.4717831\ttotal: 25.4s\tremaining: 14.1s\n",
            "1287:\tlearn: 0.4717447\ttotal: 25.4s\tremaining: 14.1s\n",
            "1288:\tlearn: 0.4717050\ttotal: 25.5s\tremaining: 14s\n",
            "1289:\tlearn: 0.4716728\ttotal: 25.5s\tremaining: 14s\n",
            "1290:\tlearn: 0.4716370\ttotal: 25.5s\tremaining: 14s\n",
            "1291:\tlearn: 0.4715990\ttotal: 25.5s\tremaining: 14s\n",
            "1292:\tlearn: 0.4715522\ttotal: 25.5s\tremaining: 14s\n",
            "1293:\tlearn: 0.4715336\ttotal: 25.6s\tremaining: 13.9s\n",
            "1294:\tlearn: 0.4714886\ttotal: 25.6s\tremaining: 13.9s\n",
            "1295:\tlearn: 0.4714587\ttotal: 25.6s\tremaining: 13.9s\n",
            "1296:\tlearn: 0.4714141\ttotal: 25.6s\tremaining: 13.9s\n",
            "1297:\tlearn: 0.4713864\ttotal: 25.6s\tremaining: 13.9s\n",
            "1298:\tlearn: 0.4713272\ttotal: 25.7s\tremaining: 13.8s\n",
            "1299:\tlearn: 0.4712910\ttotal: 25.7s\tremaining: 13.8s\n",
            "1300:\tlearn: 0.4712505\ttotal: 25.7s\tremaining: 13.8s\n",
            "1301:\tlearn: 0.4712062\ttotal: 25.7s\tremaining: 13.8s\n",
            "1302:\tlearn: 0.4711682\ttotal: 25.7s\tremaining: 13.8s\n",
            "1303:\tlearn: 0.4711116\ttotal: 25.8s\tremaining: 13.8s\n",
            "1304:\tlearn: 0.4710828\ttotal: 25.8s\tremaining: 13.7s\n",
            "1305:\tlearn: 0.4710471\ttotal: 25.8s\tremaining: 13.7s\n",
            "1306:\tlearn: 0.4710280\ttotal: 25.8s\tremaining: 13.7s\n",
            "1307:\tlearn: 0.4709732\ttotal: 25.8s\tremaining: 13.7s\n",
            "1308:\tlearn: 0.4709410\ttotal: 25.9s\tremaining: 13.7s\n",
            "1309:\tlearn: 0.4709144\ttotal: 25.9s\tremaining: 13.6s\n",
            "1310:\tlearn: 0.4708828\ttotal: 25.9s\tremaining: 13.6s\n",
            "1311:\tlearn: 0.4708582\ttotal: 25.9s\tremaining: 13.6s\n",
            "1312:\tlearn: 0.4708245\ttotal: 25.9s\tremaining: 13.6s\n",
            "1313:\tlearn: 0.4707949\ttotal: 26s\tremaining: 13.6s\n",
            "1314:\tlearn: 0.4707570\ttotal: 26s\tremaining: 13.5s\n",
            "1315:\tlearn: 0.4707103\ttotal: 26s\tremaining: 13.5s\n",
            "1316:\tlearn: 0.4706836\ttotal: 26s\tremaining: 13.5s\n",
            "1317:\tlearn: 0.4706480\ttotal: 26s\tremaining: 13.5s\n",
            "1318:\tlearn: 0.4706167\ttotal: 26.1s\tremaining: 13.5s\n",
            "1319:\tlearn: 0.4705888\ttotal: 26.1s\tremaining: 13.4s\n",
            "1320:\tlearn: 0.4705302\ttotal: 26.1s\tremaining: 13.4s\n",
            "1321:\tlearn: 0.4704842\ttotal: 26.1s\tremaining: 13.4s\n",
            "1322:\tlearn: 0.4704400\ttotal: 26.1s\tremaining: 13.4s\n",
            "1323:\tlearn: 0.4704067\ttotal: 26.2s\tremaining: 13.4s\n",
            "1324:\tlearn: 0.4703807\ttotal: 26.2s\tremaining: 13.3s\n",
            "1325:\tlearn: 0.4703628\ttotal: 26.2s\tremaining: 13.3s\n",
            "1326:\tlearn: 0.4703344\ttotal: 26.2s\tremaining: 13.3s\n",
            "1327:\tlearn: 0.4703102\ttotal: 26.2s\tremaining: 13.3s\n",
            "1328:\tlearn: 0.4702659\ttotal: 26.3s\tremaining: 13.3s\n",
            "1329:\tlearn: 0.4702354\ttotal: 26.3s\tremaining: 13.2s\n",
            "1330:\tlearn: 0.4701892\ttotal: 26.3s\tremaining: 13.2s\n",
            "1331:\tlearn: 0.4701480\ttotal: 26.3s\tremaining: 13.2s\n",
            "1332:\tlearn: 0.4701206\ttotal: 26.4s\tremaining: 13.2s\n",
            "1333:\tlearn: 0.4700912\ttotal: 26.4s\tremaining: 13.2s\n",
            "1334:\tlearn: 0.4700683\ttotal: 26.4s\tremaining: 13.1s\n",
            "1335:\tlearn: 0.4700414\ttotal: 26.4s\tremaining: 13.1s\n",
            "1336:\tlearn: 0.4699945\ttotal: 26.4s\tremaining: 13.1s\n",
            "1337:\tlearn: 0.4699567\ttotal: 26.4s\tremaining: 13.1s\n",
            "1338:\tlearn: 0.4699050\ttotal: 26.5s\tremaining: 13.1s\n",
            "1339:\tlearn: 0.4698650\ttotal: 26.5s\tremaining: 13s\n",
            "1340:\tlearn: 0.4698312\ttotal: 26.5s\tremaining: 13s\n",
            "1341:\tlearn: 0.4697830\ttotal: 26.5s\tremaining: 13s\n",
            "1342:\tlearn: 0.4697470\ttotal: 26.6s\tremaining: 13s\n",
            "1343:\tlearn: 0.4697228\ttotal: 26.6s\tremaining: 13s\n",
            "1344:\tlearn: 0.4696927\ttotal: 26.6s\tremaining: 12.9s\n",
            "1345:\tlearn: 0.4696571\ttotal: 26.6s\tremaining: 12.9s\n",
            "1346:\tlearn: 0.4696040\ttotal: 26.6s\tremaining: 12.9s\n",
            "1347:\tlearn: 0.4695425\ttotal: 26.6s\tremaining: 12.9s\n",
            "1348:\tlearn: 0.4695057\ttotal: 26.7s\tremaining: 12.9s\n",
            "1349:\tlearn: 0.4694718\ttotal: 26.7s\tremaining: 12.8s\n",
            "1350:\tlearn: 0.4694315\ttotal: 26.7s\tremaining: 12.8s\n",
            "1351:\tlearn: 0.4694085\ttotal: 26.7s\tremaining: 12.8s\n",
            "1352:\tlearn: 0.4693819\ttotal: 26.7s\tremaining: 12.8s\n",
            "1353:\tlearn: 0.4693468\ttotal: 26.8s\tremaining: 12.8s\n",
            "1354:\tlearn: 0.4693156\ttotal: 26.8s\tremaining: 12.7s\n",
            "1355:\tlearn: 0.4692820\ttotal: 26.8s\tremaining: 12.7s\n",
            "1356:\tlearn: 0.4692386\ttotal: 26.8s\tremaining: 12.7s\n",
            "1357:\tlearn: 0.4691990\ttotal: 26.8s\tremaining: 12.7s\n",
            "1358:\tlearn: 0.4691683\ttotal: 26.9s\tremaining: 12.7s\n",
            "1359:\tlearn: 0.4691377\ttotal: 26.9s\tremaining: 12.6s\n",
            "1360:\tlearn: 0.4691057\ttotal: 26.9s\tremaining: 12.6s\n",
            "1361:\tlearn: 0.4690800\ttotal: 26.9s\tremaining: 12.6s\n",
            "1362:\tlearn: 0.4690458\ttotal: 26.9s\tremaining: 12.6s\n",
            "1363:\tlearn: 0.4690044\ttotal: 27s\tremaining: 12.6s\n",
            "1364:\tlearn: 0.4689592\ttotal: 27s\tremaining: 12.5s\n",
            "1365:\tlearn: 0.4689226\ttotal: 27s\tremaining: 12.5s\n",
            "1366:\tlearn: 0.4688938\ttotal: 27s\tremaining: 12.5s\n",
            "1367:\tlearn: 0.4688406\ttotal: 27s\tremaining: 12.5s\n",
            "1368:\tlearn: 0.4688027\ttotal: 27.1s\tremaining: 12.5s\n",
            "1369:\tlearn: 0.4687649\ttotal: 27.1s\tremaining: 12.5s\n",
            "1370:\tlearn: 0.4686999\ttotal: 27.1s\tremaining: 12.4s\n",
            "1371:\tlearn: 0.4686546\ttotal: 27.1s\tremaining: 12.4s\n",
            "1372:\tlearn: 0.4686156\ttotal: 27.1s\tremaining: 12.4s\n",
            "1373:\tlearn: 0.4685789\ttotal: 27.2s\tremaining: 12.4s\n",
            "1374:\tlearn: 0.4685621\ttotal: 27.2s\tremaining: 12.4s\n",
            "1375:\tlearn: 0.4685239\ttotal: 27.2s\tremaining: 12.3s\n",
            "1376:\tlearn: 0.4684877\ttotal: 27.2s\tremaining: 12.3s\n",
            "1377:\tlearn: 0.4684385\ttotal: 27.2s\tremaining: 12.3s\n",
            "1378:\tlearn: 0.4683945\ttotal: 27.3s\tremaining: 12.3s\n",
            "1379:\tlearn: 0.4683597\ttotal: 27.3s\tremaining: 12.3s\n",
            "1380:\tlearn: 0.4683261\ttotal: 27.3s\tremaining: 12.2s\n",
            "1381:\tlearn: 0.4682907\ttotal: 27.3s\tremaining: 12.2s\n",
            "1382:\tlearn: 0.4682454\ttotal: 27.3s\tremaining: 12.2s\n",
            "1383:\tlearn: 0.4682015\ttotal: 27.4s\tremaining: 12.2s\n",
            "1384:\tlearn: 0.4681684\ttotal: 27.4s\tremaining: 12.2s\n",
            "1385:\tlearn: 0.4681428\ttotal: 27.4s\tremaining: 12.1s\n",
            "1386:\tlearn: 0.4680995\ttotal: 27.4s\tremaining: 12.1s\n",
            "1387:\tlearn: 0.4680575\ttotal: 27.4s\tremaining: 12.1s\n",
            "1388:\tlearn: 0.4680324\ttotal: 27.5s\tremaining: 12.1s\n",
            "1389:\tlearn: 0.4679822\ttotal: 27.5s\tremaining: 12.1s\n",
            "1390:\tlearn: 0.4679508\ttotal: 27.5s\tremaining: 12s\n",
            "1391:\tlearn: 0.4679257\ttotal: 27.5s\tremaining: 12s\n",
            "1392:\tlearn: 0.4679007\ttotal: 27.5s\tremaining: 12s\n",
            "1393:\tlearn: 0.4678696\ttotal: 27.6s\tremaining: 12s\n",
            "1394:\tlearn: 0.4678303\ttotal: 27.6s\tremaining: 12s\n",
            "1395:\tlearn: 0.4677992\ttotal: 27.6s\tremaining: 11.9s\n",
            "1396:\tlearn: 0.4677726\ttotal: 27.6s\tremaining: 11.9s\n",
            "1397:\tlearn: 0.4677285\ttotal: 27.6s\tremaining: 11.9s\n",
            "1398:\tlearn: 0.4676880\ttotal: 27.7s\tremaining: 11.9s\n",
            "1399:\tlearn: 0.4676541\ttotal: 27.7s\tremaining: 11.9s\n",
            "1400:\tlearn: 0.4676313\ttotal: 27.7s\tremaining: 11.8s\n",
            "1401:\tlearn: 0.4676007\ttotal: 27.7s\tremaining: 11.8s\n",
            "1402:\tlearn: 0.4675767\ttotal: 27.7s\tremaining: 11.8s\n",
            "1403:\tlearn: 0.4675475\ttotal: 27.8s\tremaining: 11.8s\n",
            "1404:\tlearn: 0.4675178\ttotal: 27.8s\tremaining: 11.8s\n",
            "1405:\tlearn: 0.4674805\ttotal: 27.8s\tremaining: 11.7s\n",
            "1406:\tlearn: 0.4674318\ttotal: 27.8s\tremaining: 11.7s\n",
            "1407:\tlearn: 0.4673925\ttotal: 27.8s\tremaining: 11.7s\n",
            "1408:\tlearn: 0.4673694\ttotal: 27.8s\tremaining: 11.7s\n",
            "1409:\tlearn: 0.4673389\ttotal: 27.9s\tremaining: 11.7s\n",
            "1410:\tlearn: 0.4673082\ttotal: 27.9s\tremaining: 11.6s\n",
            "1411:\tlearn: 0.4672781\ttotal: 27.9s\tremaining: 11.6s\n",
            "1412:\tlearn: 0.4672454\ttotal: 27.9s\tremaining: 11.6s\n",
            "1413:\tlearn: 0.4672029\ttotal: 28s\tremaining: 11.6s\n",
            "1414:\tlearn: 0.4671552\ttotal: 28s\tremaining: 11.6s\n",
            "1415:\tlearn: 0.4671048\ttotal: 28s\tremaining: 11.5s\n",
            "1416:\tlearn: 0.4670732\ttotal: 28s\tremaining: 11.5s\n",
            "1417:\tlearn: 0.4670284\ttotal: 28s\tremaining: 11.5s\n",
            "1418:\tlearn: 0.4669884\ttotal: 28.1s\tremaining: 11.5s\n",
            "1419:\tlearn: 0.4669597\ttotal: 28.1s\tremaining: 11.5s\n",
            "1420:\tlearn: 0.4669376\ttotal: 28.1s\tremaining: 11.4s\n",
            "1421:\tlearn: 0.4668953\ttotal: 28.1s\tremaining: 11.4s\n",
            "1422:\tlearn: 0.4668477\ttotal: 28.1s\tremaining: 11.4s\n",
            "1423:\tlearn: 0.4668124\ttotal: 28.1s\tremaining: 11.4s\n",
            "1424:\tlearn: 0.4667867\ttotal: 28.2s\tremaining: 11.4s\n",
            "1425:\tlearn: 0.4667563\ttotal: 28.2s\tremaining: 11.3s\n",
            "1426:\tlearn: 0.4667217\ttotal: 28.2s\tremaining: 11.3s\n",
            "1427:\tlearn: 0.4666908\ttotal: 28.2s\tremaining: 11.3s\n",
            "1428:\tlearn: 0.4666529\ttotal: 28.3s\tremaining: 11.3s\n",
            "1429:\tlearn: 0.4666231\ttotal: 28.3s\tremaining: 11.3s\n",
            "1430:\tlearn: 0.4665686\ttotal: 28.3s\tremaining: 11.2s\n",
            "1431:\tlearn: 0.4665303\ttotal: 28.3s\tremaining: 11.2s\n",
            "1432:\tlearn: 0.4665014\ttotal: 28.3s\tremaining: 11.2s\n",
            "1433:\tlearn: 0.4664760\ttotal: 28.3s\tremaining: 11.2s\n",
            "1434:\tlearn: 0.4664465\ttotal: 28.4s\tremaining: 11.2s\n",
            "1435:\tlearn: 0.4664092\ttotal: 28.4s\tremaining: 11.1s\n",
            "1436:\tlearn: 0.4663690\ttotal: 28.4s\tremaining: 11.1s\n",
            "1437:\tlearn: 0.4663360\ttotal: 28.4s\tremaining: 11.1s\n",
            "1438:\tlearn: 0.4663080\ttotal: 28.4s\tremaining: 11.1s\n",
            "1439:\tlearn: 0.4662757\ttotal: 28.5s\tremaining: 11.1s\n",
            "1440:\tlearn: 0.4662426\ttotal: 28.5s\tremaining: 11s\n",
            "1441:\tlearn: 0.4662045\ttotal: 28.5s\tremaining: 11s\n",
            "1442:\tlearn: 0.4661596\ttotal: 28.5s\tremaining: 11s\n",
            "1443:\tlearn: 0.4661290\ttotal: 28.5s\tremaining: 11s\n",
            "1444:\tlearn: 0.4660965\ttotal: 28.6s\tremaining: 11s\n",
            "1445:\tlearn: 0.4660682\ttotal: 28.6s\tremaining: 10.9s\n",
            "1446:\tlearn: 0.4660261\ttotal: 28.6s\tremaining: 10.9s\n",
            "1447:\tlearn: 0.4659836\ttotal: 28.6s\tremaining: 10.9s\n",
            "1448:\tlearn: 0.4659558\ttotal: 28.6s\tremaining: 10.9s\n",
            "1449:\tlearn: 0.4659226\ttotal: 28.7s\tremaining: 10.9s\n",
            "1450:\tlearn: 0.4658961\ttotal: 28.7s\tremaining: 10.8s\n",
            "1451:\tlearn: 0.4658638\ttotal: 28.7s\tremaining: 10.8s\n",
            "1452:\tlearn: 0.4658128\ttotal: 28.7s\tremaining: 10.8s\n",
            "1453:\tlearn: 0.4657770\ttotal: 28.7s\tremaining: 10.8s\n",
            "1454:\tlearn: 0.4657414\ttotal: 28.8s\tremaining: 10.8s\n",
            "1455:\tlearn: 0.4657130\ttotal: 28.8s\tremaining: 10.8s\n",
            "1456:\tlearn: 0.4656428\ttotal: 28.8s\tremaining: 10.7s\n",
            "1457:\tlearn: 0.4655961\ttotal: 28.8s\tremaining: 10.7s\n",
            "1458:\tlearn: 0.4655645\ttotal: 28.8s\tremaining: 10.7s\n",
            "1459:\tlearn: 0.4655381\ttotal: 28.9s\tremaining: 10.7s\n",
            "1460:\tlearn: 0.4655097\ttotal: 28.9s\tremaining: 10.7s\n",
            "1461:\tlearn: 0.4654651\ttotal: 28.9s\tremaining: 10.6s\n",
            "1462:\tlearn: 0.4654367\ttotal: 28.9s\tremaining: 10.6s\n",
            "1463:\tlearn: 0.4654140\ttotal: 28.9s\tremaining: 10.6s\n",
            "1464:\tlearn: 0.4653809\ttotal: 29s\tremaining: 10.6s\n",
            "1465:\tlearn: 0.4653479\ttotal: 29s\tremaining: 10.6s\n",
            "1466:\tlearn: 0.4653145\ttotal: 29s\tremaining: 10.5s\n",
            "1467:\tlearn: 0.4652756\ttotal: 29s\tremaining: 10.5s\n",
            "1468:\tlearn: 0.4652441\ttotal: 29s\tremaining: 10.5s\n",
            "1469:\tlearn: 0.4652254\ttotal: 29.1s\tremaining: 10.5s\n",
            "1470:\tlearn: 0.4651850\ttotal: 29.1s\tremaining: 10.5s\n",
            "1471:\tlearn: 0.4651574\ttotal: 29.1s\tremaining: 10.4s\n",
            "1472:\tlearn: 0.4651173\ttotal: 29.1s\tremaining: 10.4s\n",
            "1473:\tlearn: 0.4650849\ttotal: 29.1s\tremaining: 10.4s\n",
            "1474:\tlearn: 0.4650656\ttotal: 29.1s\tremaining: 10.4s\n",
            "1475:\tlearn: 0.4650372\ttotal: 29.2s\tremaining: 10.4s\n",
            "1476:\tlearn: 0.4650046\ttotal: 29.2s\tremaining: 10.3s\n",
            "1477:\tlearn: 0.4649826\ttotal: 29.2s\tremaining: 10.3s\n",
            "1478:\tlearn: 0.4649452\ttotal: 29.2s\tremaining: 10.3s\n",
            "1479:\tlearn: 0.4648988\ttotal: 29.2s\tremaining: 10.3s\n",
            "1480:\tlearn: 0.4648705\ttotal: 29.3s\tremaining: 10.3s\n",
            "1481:\tlearn: 0.4648222\ttotal: 29.3s\tremaining: 10.2s\n",
            "1482:\tlearn: 0.4647834\ttotal: 29.3s\tremaining: 10.2s\n",
            "1483:\tlearn: 0.4647705\ttotal: 29.3s\tremaining: 10.2s\n",
            "1484:\tlearn: 0.4647480\ttotal: 29.3s\tremaining: 10.2s\n",
            "1485:\tlearn: 0.4647232\ttotal: 29.4s\tremaining: 10.2s\n",
            "1486:\tlearn: 0.4646956\ttotal: 29.4s\tremaining: 10.1s\n",
            "1487:\tlearn: 0.4646551\ttotal: 29.4s\tremaining: 10.1s\n",
            "1488:\tlearn: 0.4646263\ttotal: 29.4s\tremaining: 10.1s\n",
            "1489:\tlearn: 0.4646013\ttotal: 29.4s\tremaining: 10.1s\n",
            "1490:\tlearn: 0.4645633\ttotal: 29.5s\tremaining: 10.1s\n",
            "1491:\tlearn: 0.4645239\ttotal: 29.5s\tremaining: 10s\n",
            "1492:\tlearn: 0.4644868\ttotal: 29.5s\tremaining: 10s\n",
            "1493:\tlearn: 0.4644315\ttotal: 29.5s\tremaining: 10s\n",
            "1494:\tlearn: 0.4643978\ttotal: 29.5s\tremaining: 9.98s\n",
            "1495:\tlearn: 0.4643584\ttotal: 29.6s\tremaining: 9.96s\n",
            "1496:\tlearn: 0.4643124\ttotal: 29.6s\tremaining: 9.94s\n",
            "1497:\tlearn: 0.4642788\ttotal: 29.6s\tremaining: 9.92s\n",
            "1498:\tlearn: 0.4642435\ttotal: 29.6s\tremaining: 9.9s\n",
            "1499:\tlearn: 0.4642167\ttotal: 29.6s\tremaining: 9.88s\n",
            "1500:\tlearn: 0.4641826\ttotal: 29.7s\tremaining: 9.86s\n",
            "1501:\tlearn: 0.4641460\ttotal: 29.7s\tremaining: 9.84s\n",
            "1502:\tlearn: 0.4641229\ttotal: 29.7s\tremaining: 9.82s\n",
            "1503:\tlearn: 0.4640923\ttotal: 29.7s\tremaining: 9.8s\n",
            "1504:\tlearn: 0.4640654\ttotal: 29.7s\tremaining: 9.78s\n",
            "1505:\tlearn: 0.4640436\ttotal: 29.8s\tremaining: 9.76s\n",
            "1506:\tlearn: 0.4640231\ttotal: 29.8s\tremaining: 9.74s\n",
            "1507:\tlearn: 0.4639960\ttotal: 29.8s\tremaining: 9.72s\n",
            "1508:\tlearn: 0.4639660\ttotal: 29.8s\tremaining: 9.7s\n",
            "1509:\tlearn: 0.4639407\ttotal: 29.8s\tremaining: 9.68s\n",
            "1510:\tlearn: 0.4639120\ttotal: 29.9s\tremaining: 9.66s\n",
            "1511:\tlearn: 0.4638713\ttotal: 29.9s\tremaining: 9.64s\n",
            "1512:\tlearn: 0.4638345\ttotal: 29.9s\tremaining: 9.62s\n",
            "1513:\tlearn: 0.4638076\ttotal: 29.9s\tremaining: 9.6s\n",
            "1514:\tlearn: 0.4637845\ttotal: 29.9s\tremaining: 9.58s\n",
            "1515:\tlearn: 0.4637482\ttotal: 30s\tremaining: 9.56s\n",
            "1516:\tlearn: 0.4637166\ttotal: 30s\tremaining: 9.54s\n",
            "1517:\tlearn: 0.4636926\ttotal: 30s\tremaining: 9.52s\n",
            "1518:\tlearn: 0.4636595\ttotal: 30s\tremaining: 9.5s\n",
            "1519:\tlearn: 0.4636406\ttotal: 30s\tremaining: 9.48s\n",
            "1520:\tlearn: 0.4636147\ttotal: 30.1s\tremaining: 9.46s\n",
            "1521:\tlearn: 0.4635904\ttotal: 30.1s\tremaining: 9.45s\n",
            "1522:\tlearn: 0.4635555\ttotal: 30.1s\tremaining: 9.43s\n",
            "1523:\tlearn: 0.4635157\ttotal: 30.1s\tremaining: 9.41s\n",
            "1524:\tlearn: 0.4634672\ttotal: 30.1s\tremaining: 9.39s\n",
            "1525:\tlearn: 0.4634396\ttotal: 30.2s\tremaining: 9.37s\n",
            "1526:\tlearn: 0.4634036\ttotal: 30.2s\tremaining: 9.35s\n",
            "1527:\tlearn: 0.4633542\ttotal: 30.2s\tremaining: 9.33s\n",
            "1528:\tlearn: 0.4633273\ttotal: 30.2s\tremaining: 9.31s\n",
            "1529:\tlearn: 0.4632837\ttotal: 30.2s\tremaining: 9.29s\n",
            "1530:\tlearn: 0.4632513\ttotal: 30.3s\tremaining: 9.27s\n",
            "1531:\tlearn: 0.4632052\ttotal: 30.3s\tremaining: 9.25s\n",
            "1532:\tlearn: 0.4631703\ttotal: 30.3s\tremaining: 9.23s\n",
            "1533:\tlearn: 0.4631362\ttotal: 30.3s\tremaining: 9.21s\n",
            "1534:\tlearn: 0.4630993\ttotal: 30.3s\tremaining: 9.19s\n",
            "1535:\tlearn: 0.4630430\ttotal: 30.4s\tremaining: 9.17s\n",
            "1536:\tlearn: 0.4630092\ttotal: 30.4s\tremaining: 9.15s\n",
            "1537:\tlearn: 0.4629805\ttotal: 30.4s\tremaining: 9.13s\n",
            "1538:\tlearn: 0.4629485\ttotal: 30.4s\tremaining: 9.11s\n",
            "1539:\tlearn: 0.4629280\ttotal: 30.4s\tremaining: 9.09s\n",
            "1540:\tlearn: 0.4628937\ttotal: 30.5s\tremaining: 9.07s\n",
            "1541:\tlearn: 0.4628656\ttotal: 30.5s\tremaining: 9.05s\n",
            "1542:\tlearn: 0.4628395\ttotal: 30.5s\tremaining: 9.03s\n",
            "1543:\tlearn: 0.4628051\ttotal: 30.5s\tremaining: 9.01s\n",
            "1544:\tlearn: 0.4627786\ttotal: 30.5s\tremaining: 8.99s\n",
            "1545:\tlearn: 0.4627458\ttotal: 30.6s\tremaining: 8.97s\n",
            "1546:\tlearn: 0.4627111\ttotal: 30.6s\tremaining: 8.95s\n",
            "1547:\tlearn: 0.4626774\ttotal: 30.6s\tremaining: 8.93s\n",
            "1548:\tlearn: 0.4626414\ttotal: 30.6s\tremaining: 8.91s\n",
            "1549:\tlearn: 0.4626206\ttotal: 30.6s\tremaining: 8.89s\n",
            "1550:\tlearn: 0.4625834\ttotal: 30.7s\tremaining: 8.87s\n",
            "1551:\tlearn: 0.4625435\ttotal: 30.7s\tremaining: 8.85s\n",
            "1552:\tlearn: 0.4625111\ttotal: 30.7s\tremaining: 8.83s\n",
            "1553:\tlearn: 0.4624897\ttotal: 30.7s\tremaining: 8.82s\n",
            "1554:\tlearn: 0.4624422\ttotal: 30.7s\tremaining: 8.8s\n",
            "1555:\tlearn: 0.4624109\ttotal: 30.8s\tremaining: 8.78s\n",
            "1556:\tlearn: 0.4623741\ttotal: 30.8s\tremaining: 8.76s\n",
            "1557:\tlearn: 0.4623328\ttotal: 30.8s\tremaining: 8.74s\n",
            "1558:\tlearn: 0.4623042\ttotal: 30.8s\tremaining: 8.72s\n",
            "1559:\tlearn: 0.4622734\ttotal: 30.8s\tremaining: 8.7s\n",
            "1560:\tlearn: 0.4622434\ttotal: 30.9s\tremaining: 8.68s\n",
            "1561:\tlearn: 0.4622013\ttotal: 30.9s\tremaining: 8.66s\n",
            "1562:\tlearn: 0.4621711\ttotal: 30.9s\tremaining: 8.64s\n",
            "1563:\tlearn: 0.4621414\ttotal: 30.9s\tremaining: 8.62s\n",
            "1564:\tlearn: 0.4621116\ttotal: 30.9s\tremaining: 8.6s\n",
            "1565:\tlearn: 0.4620800\ttotal: 31s\tremaining: 8.58s\n",
            "1566:\tlearn: 0.4620410\ttotal: 31s\tremaining: 8.56s\n",
            "1567:\tlearn: 0.4620099\ttotal: 31s\tremaining: 8.54s\n",
            "1568:\tlearn: 0.4619713\ttotal: 31s\tremaining: 8.52s\n",
            "1569:\tlearn: 0.4619513\ttotal: 31s\tremaining: 8.5s\n",
            "1570:\tlearn: 0.4619229\ttotal: 31.1s\tremaining: 8.48s\n",
            "1571:\tlearn: 0.4618916\ttotal: 31.1s\tremaining: 8.46s\n",
            "1572:\tlearn: 0.4618533\ttotal: 31.1s\tremaining: 8.44s\n",
            "1573:\tlearn: 0.4618094\ttotal: 31.1s\tremaining: 8.42s\n",
            "1574:\tlearn: 0.4617746\ttotal: 31.1s\tremaining: 8.4s\n",
            "1575:\tlearn: 0.4617230\ttotal: 31.2s\tremaining: 8.38s\n",
            "1576:\tlearn: 0.4617015\ttotal: 31.2s\tremaining: 8.36s\n",
            "1577:\tlearn: 0.4616746\ttotal: 31.2s\tremaining: 8.34s\n",
            "1578:\tlearn: 0.4616359\ttotal: 31.2s\tremaining: 8.32s\n",
            "1579:\tlearn: 0.4615993\ttotal: 31.2s\tremaining: 8.31s\n",
            "1580:\tlearn: 0.4615702\ttotal: 31.3s\tremaining: 8.29s\n",
            "1581:\tlearn: 0.4615383\ttotal: 31.3s\tremaining: 8.27s\n",
            "1582:\tlearn: 0.4615100\ttotal: 31.3s\tremaining: 8.24s\n",
            "1583:\tlearn: 0.4614798\ttotal: 31.3s\tremaining: 8.22s\n",
            "1584:\tlearn: 0.4614548\ttotal: 31.3s\tremaining: 8.21s\n",
            "1585:\tlearn: 0.4614213\ttotal: 31.4s\tremaining: 8.18s\n",
            "1586:\tlearn: 0.4613878\ttotal: 31.4s\tremaining: 8.17s\n",
            "1587:\tlearn: 0.4613543\ttotal: 31.4s\tremaining: 8.15s\n",
            "1588:\tlearn: 0.4613147\ttotal: 31.4s\tremaining: 8.13s\n",
            "1589:\tlearn: 0.4612753\ttotal: 31.4s\tremaining: 8.11s\n",
            "1590:\tlearn: 0.4612449\ttotal: 31.5s\tremaining: 8.09s\n",
            "1591:\tlearn: 0.4612284\ttotal: 31.5s\tremaining: 8.06s\n",
            "1592:\tlearn: 0.4611753\ttotal: 31.5s\tremaining: 8.04s\n",
            "1593:\tlearn: 0.4611524\ttotal: 31.5s\tremaining: 8.03s\n",
            "1594:\tlearn: 0.4611234\ttotal: 31.5s\tremaining: 8.01s\n",
            "1595:\tlearn: 0.4610786\ttotal: 31.5s\tremaining: 7.99s\n",
            "1596:\tlearn: 0.4610409\ttotal: 31.6s\tremaining: 7.96s\n",
            "1597:\tlearn: 0.4610064\ttotal: 31.6s\tremaining: 7.95s\n",
            "1598:\tlearn: 0.4609749\ttotal: 31.6s\tremaining: 7.93s\n",
            "1599:\tlearn: 0.4609431\ttotal: 31.6s\tremaining: 7.91s\n",
            "1600:\tlearn: 0.4609181\ttotal: 31.6s\tremaining: 7.89s\n",
            "1601:\tlearn: 0.4608887\ttotal: 31.7s\tremaining: 7.87s\n",
            "1602:\tlearn: 0.4608658\ttotal: 31.7s\tremaining: 7.85s\n",
            "1603:\tlearn: 0.4608325\ttotal: 31.7s\tremaining: 7.83s\n",
            "1604:\tlearn: 0.4608074\ttotal: 31.7s\tremaining: 7.81s\n",
            "1605:\tlearn: 0.4607752\ttotal: 31.7s\tremaining: 7.79s\n",
            "1606:\tlearn: 0.4607189\ttotal: 31.8s\tremaining: 7.76s\n",
            "1607:\tlearn: 0.4606940\ttotal: 31.8s\tremaining: 7.75s\n",
            "1608:\tlearn: 0.4606489\ttotal: 31.8s\tremaining: 7.73s\n",
            "1609:\tlearn: 0.4606211\ttotal: 31.8s\tremaining: 7.71s\n",
            "1610:\tlearn: 0.4606032\ttotal: 31.8s\tremaining: 7.69s\n",
            "1611:\tlearn: 0.4605720\ttotal: 31.9s\tremaining: 7.67s\n",
            "1612:\tlearn: 0.4605374\ttotal: 31.9s\tremaining: 7.65s\n",
            "1613:\tlearn: 0.4605046\ttotal: 31.9s\tremaining: 7.63s\n",
            "1614:\tlearn: 0.4604733\ttotal: 31.9s\tremaining: 7.61s\n",
            "1615:\tlearn: 0.4604337\ttotal: 31.9s\tremaining: 7.59s\n",
            "1616:\tlearn: 0.4604135\ttotal: 31.9s\tremaining: 7.57s\n",
            "1617:\tlearn: 0.4603884\ttotal: 32s\tremaining: 7.55s\n",
            "1618:\tlearn: 0.4603493\ttotal: 32s\tremaining: 7.53s\n",
            "1619:\tlearn: 0.4603118\ttotal: 32s\tremaining: 7.51s\n",
            "1620:\tlearn: 0.4602865\ttotal: 32s\tremaining: 7.49s\n",
            "1621:\tlearn: 0.4602527\ttotal: 32.1s\tremaining: 7.47s\n",
            "1622:\tlearn: 0.4602169\ttotal: 32.1s\tremaining: 7.45s\n",
            "1623:\tlearn: 0.4601686\ttotal: 32.1s\tremaining: 7.43s\n",
            "1624:\tlearn: 0.4601378\ttotal: 32.1s\tremaining: 7.41s\n",
            "1625:\tlearn: 0.4601145\ttotal: 32.1s\tremaining: 7.39s\n",
            "1626:\tlearn: 0.4600771\ttotal: 32.1s\tremaining: 7.37s\n",
            "1627:\tlearn: 0.4600180\ttotal: 32.2s\tremaining: 7.35s\n",
            "1628:\tlearn: 0.4599973\ttotal: 32.2s\tremaining: 7.33s\n",
            "1629:\tlearn: 0.4599842\ttotal: 32.2s\tremaining: 7.31s\n",
            "1630:\tlearn: 0.4599519\ttotal: 32.2s\tremaining: 7.29s\n",
            "1631:\tlearn: 0.4599034\ttotal: 32.3s\tremaining: 7.27s\n",
            "1632:\tlearn: 0.4598603\ttotal: 32.3s\tremaining: 7.25s\n",
            "1633:\tlearn: 0.4598288\ttotal: 32.3s\tremaining: 7.23s\n",
            "1634:\tlearn: 0.4597977\ttotal: 32.3s\tremaining: 7.21s\n",
            "1635:\tlearn: 0.4597546\ttotal: 32.3s\tremaining: 7.19s\n",
            "1636:\tlearn: 0.4597222\ttotal: 32.3s\tremaining: 7.17s\n",
            "1637:\tlearn: 0.4596881\ttotal: 32.4s\tremaining: 7.15s\n",
            "1638:\tlearn: 0.4596515\ttotal: 32.4s\tremaining: 7.13s\n",
            "1639:\tlearn: 0.4596198\ttotal: 32.4s\tremaining: 7.11s\n",
            "1640:\tlearn: 0.4595903\ttotal: 32.4s\tremaining: 7.09s\n",
            "1641:\tlearn: 0.4595687\ttotal: 32.4s\tremaining: 7.07s\n",
            "1642:\tlearn: 0.4595423\ttotal: 32.5s\tremaining: 7.05s\n",
            "1643:\tlearn: 0.4594949\ttotal: 32.5s\tremaining: 7.03s\n",
            "1644:\tlearn: 0.4594484\ttotal: 32.5s\tremaining: 7.01s\n",
            "1645:\tlearn: 0.4594298\ttotal: 32.5s\tremaining: 6.99s\n",
            "1646:\tlearn: 0.4593892\ttotal: 32.5s\tremaining: 6.97s\n",
            "1647:\tlearn: 0.4593594\ttotal: 32.6s\tremaining: 6.95s\n",
            "1648:\tlearn: 0.4593190\ttotal: 32.6s\tremaining: 6.93s\n",
            "1649:\tlearn: 0.4592916\ttotal: 32.6s\tremaining: 6.91s\n",
            "1650:\tlearn: 0.4592607\ttotal: 32.6s\tremaining: 6.89s\n",
            "1651:\tlearn: 0.4592385\ttotal: 32.6s\tremaining: 6.87s\n",
            "1652:\tlearn: 0.4592016\ttotal: 32.7s\tremaining: 6.85s\n",
            "1653:\tlearn: 0.4591815\ttotal: 32.7s\tremaining: 6.83s\n",
            "1654:\tlearn: 0.4591375\ttotal: 32.7s\tremaining: 6.81s\n",
            "1655:\tlearn: 0.4591054\ttotal: 32.7s\tremaining: 6.79s\n",
            "1656:\tlearn: 0.4590579\ttotal: 32.7s\tremaining: 6.77s\n",
            "1657:\tlearn: 0.4590155\ttotal: 32.7s\tremaining: 6.75s\n",
            "1658:\tlearn: 0.4589775\ttotal: 32.8s\tremaining: 6.73s\n",
            "1659:\tlearn: 0.4589556\ttotal: 32.8s\tremaining: 6.71s\n",
            "1660:\tlearn: 0.4589344\ttotal: 32.8s\tremaining: 6.69s\n",
            "1661:\tlearn: 0.4588939\ttotal: 32.8s\tremaining: 6.67s\n",
            "1662:\tlearn: 0.4588694\ttotal: 32.8s\tremaining: 6.65s\n",
            "1663:\tlearn: 0.4588269\ttotal: 32.9s\tremaining: 6.64s\n",
            "1664:\tlearn: 0.4587899\ttotal: 32.9s\tremaining: 6.62s\n",
            "1665:\tlearn: 0.4587660\ttotal: 32.9s\tremaining: 6.6s\n",
            "1666:\tlearn: 0.4587203\ttotal: 32.9s\tremaining: 6.58s\n",
            "1667:\tlearn: 0.4586977\ttotal: 32.9s\tremaining: 6.56s\n",
            "1668:\tlearn: 0.4586739\ttotal: 33s\tremaining: 6.54s\n",
            "1669:\tlearn: 0.4586345\ttotal: 33s\tremaining: 6.52s\n",
            "1670:\tlearn: 0.4586073\ttotal: 33s\tremaining: 6.5s\n",
            "1671:\tlearn: 0.4585821\ttotal: 33s\tremaining: 6.48s\n",
            "1672:\tlearn: 0.4585453\ttotal: 33s\tremaining: 6.46s\n",
            "1673:\tlearn: 0.4585149\ttotal: 33.1s\tremaining: 6.44s\n",
            "1674:\tlearn: 0.4584848\ttotal: 33.1s\tremaining: 6.42s\n",
            "1675:\tlearn: 0.4584369\ttotal: 33.1s\tremaining: 6.4s\n",
            "1676:\tlearn: 0.4584061\ttotal: 33.1s\tremaining: 6.38s\n",
            "1677:\tlearn: 0.4583801\ttotal: 33.1s\tremaining: 6.36s\n",
            "1678:\tlearn: 0.4583558\ttotal: 33.2s\tremaining: 6.34s\n",
            "1679:\tlearn: 0.4583138\ttotal: 33.2s\tremaining: 6.32s\n",
            "1680:\tlearn: 0.4582800\ttotal: 33.2s\tremaining: 6.3s\n",
            "1681:\tlearn: 0.4582447\ttotal: 33.2s\tremaining: 6.28s\n",
            "1682:\tlearn: 0.4582073\ttotal: 33.2s\tremaining: 6.26s\n",
            "1683:\tlearn: 0.4581745\ttotal: 33.3s\tremaining: 6.24s\n",
            "1684:\tlearn: 0.4581356\ttotal: 33.3s\tremaining: 6.22s\n",
            "1685:\tlearn: 0.4581154\ttotal: 33.3s\tremaining: 6.2s\n",
            "1686:\tlearn: 0.4580521\ttotal: 33.3s\tremaining: 6.18s\n",
            "1687:\tlearn: 0.4580322\ttotal: 33.3s\tremaining: 6.16s\n",
            "1688:\tlearn: 0.4580128\ttotal: 33.4s\tremaining: 6.14s\n",
            "1689:\tlearn: 0.4579739\ttotal: 33.4s\tremaining: 6.12s\n",
            "1690:\tlearn: 0.4579414\ttotal: 33.4s\tremaining: 6.1s\n",
            "1691:\tlearn: 0.4579052\ttotal: 33.4s\tremaining: 6.08s\n",
            "1692:\tlearn: 0.4578803\ttotal: 33.4s\tremaining: 6.06s\n",
            "1693:\tlearn: 0.4578363\ttotal: 33.5s\tremaining: 6.04s\n",
            "1694:\tlearn: 0.4577856\ttotal: 33.5s\tremaining: 6.02s\n",
            "1695:\tlearn: 0.4577422\ttotal: 33.5s\tremaining: 6s\n",
            "1696:\tlearn: 0.4577193\ttotal: 33.5s\tremaining: 5.98s\n",
            "1697:\tlearn: 0.4576859\ttotal: 33.5s\tremaining: 5.96s\n",
            "1698:\tlearn: 0.4576493\ttotal: 33.6s\tremaining: 5.94s\n",
            "1699:\tlearn: 0.4576140\ttotal: 33.6s\tremaining: 5.92s\n",
            "1700:\tlearn: 0.4575791\ttotal: 33.6s\tremaining: 5.9s\n",
            "1701:\tlearn: 0.4575071\ttotal: 33.6s\tremaining: 5.88s\n",
            "1702:\tlearn: 0.4574794\ttotal: 33.6s\tremaining: 5.86s\n",
            "1703:\tlearn: 0.4574463\ttotal: 33.6s\tremaining: 5.84s\n",
            "1704:\tlearn: 0.4574111\ttotal: 33.7s\tremaining: 5.82s\n",
            "1705:\tlearn: 0.4573788\ttotal: 33.7s\tremaining: 5.8s\n",
            "1706:\tlearn: 0.4573423\ttotal: 33.7s\tremaining: 5.79s\n",
            "1707:\tlearn: 0.4573123\ttotal: 33.7s\tremaining: 5.77s\n",
            "1708:\tlearn: 0.4572751\ttotal: 33.8s\tremaining: 5.75s\n",
            "1709:\tlearn: 0.4572203\ttotal: 33.8s\tremaining: 5.73s\n",
            "1710:\tlearn: 0.4571857\ttotal: 33.8s\tremaining: 5.71s\n",
            "1711:\tlearn: 0.4571585\ttotal: 33.8s\tremaining: 5.69s\n",
            "1712:\tlearn: 0.4571356\ttotal: 33.8s\tremaining: 5.67s\n",
            "1713:\tlearn: 0.4571000\ttotal: 33.9s\tremaining: 5.65s\n",
            "1714:\tlearn: 0.4570688\ttotal: 33.9s\tremaining: 5.63s\n",
            "1715:\tlearn: 0.4570409\ttotal: 33.9s\tremaining: 5.61s\n",
            "1716:\tlearn: 0.4570143\ttotal: 33.9s\tremaining: 5.59s\n",
            "1717:\tlearn: 0.4569926\ttotal: 33.9s\tremaining: 5.57s\n",
            "1718:\tlearn: 0.4569669\ttotal: 34s\tremaining: 5.55s\n",
            "1719:\tlearn: 0.4569071\ttotal: 34s\tremaining: 5.53s\n",
            "1720:\tlearn: 0.4568821\ttotal: 34s\tremaining: 5.51s\n",
            "1721:\tlearn: 0.4568593\ttotal: 34s\tremaining: 5.49s\n",
            "1722:\tlearn: 0.4568356\ttotal: 34s\tremaining: 5.47s\n",
            "1723:\tlearn: 0.4567963\ttotal: 34.1s\tremaining: 5.45s\n",
            "1724:\tlearn: 0.4567690\ttotal: 34.1s\tremaining: 5.43s\n",
            "1725:\tlearn: 0.4567404\ttotal: 34.1s\tremaining: 5.41s\n",
            "1726:\tlearn: 0.4567232\ttotal: 34.1s\tremaining: 5.39s\n",
            "1727:\tlearn: 0.4566937\ttotal: 34.1s\tremaining: 5.37s\n",
            "1728:\tlearn: 0.4566681\ttotal: 34.2s\tremaining: 5.35s\n",
            "1729:\tlearn: 0.4566370\ttotal: 34.2s\tremaining: 5.33s\n",
            "1730:\tlearn: 0.4566031\ttotal: 34.2s\tremaining: 5.31s\n",
            "1731:\tlearn: 0.4565738\ttotal: 34.2s\tremaining: 5.29s\n",
            "1732:\tlearn: 0.4565191\ttotal: 34.2s\tremaining: 5.27s\n",
            "1733:\tlearn: 0.4564819\ttotal: 34.3s\tremaining: 5.25s\n",
            "1734:\tlearn: 0.4564530\ttotal: 34.3s\tremaining: 5.23s\n",
            "1735:\tlearn: 0.4564123\ttotal: 34.3s\tremaining: 5.21s\n",
            "1736:\tlearn: 0.4563687\ttotal: 34.3s\tremaining: 5.2s\n",
            "1737:\tlearn: 0.4563489\ttotal: 34.3s\tremaining: 5.17s\n",
            "1738:\tlearn: 0.4563168\ttotal: 34.4s\tremaining: 5.16s\n",
            "1739:\tlearn: 0.4562824\ttotal: 34.4s\tremaining: 5.14s\n",
            "1740:\tlearn: 0.4562565\ttotal: 34.4s\tremaining: 5.12s\n",
            "1741:\tlearn: 0.4562241\ttotal: 34.4s\tremaining: 5.1s\n",
            "1742:\tlearn: 0.4561898\ttotal: 34.5s\tremaining: 5.08s\n",
            "1743:\tlearn: 0.4561504\ttotal: 34.5s\tremaining: 5.06s\n",
            "1744:\tlearn: 0.4561293\ttotal: 34.5s\tremaining: 5.04s\n",
            "1745:\tlearn: 0.4561011\ttotal: 34.5s\tremaining: 5.02s\n",
            "1746:\tlearn: 0.4560578\ttotal: 34.5s\tremaining: 5s\n",
            "1747:\tlearn: 0.4560404\ttotal: 34.5s\tremaining: 4.98s\n",
            "1748:\tlearn: 0.4560099\ttotal: 34.6s\tremaining: 4.96s\n",
            "1749:\tlearn: 0.4559727\ttotal: 34.6s\tremaining: 4.94s\n",
            "1750:\tlearn: 0.4559480\ttotal: 34.6s\tremaining: 4.92s\n",
            "1751:\tlearn: 0.4559138\ttotal: 34.6s\tremaining: 4.9s\n",
            "1752:\tlearn: 0.4558840\ttotal: 34.6s\tremaining: 4.88s\n",
            "1753:\tlearn: 0.4558540\ttotal: 34.7s\tremaining: 4.86s\n",
            "1754:\tlearn: 0.4558252\ttotal: 34.7s\tremaining: 4.84s\n",
            "1755:\tlearn: 0.4557893\ttotal: 34.7s\tremaining: 4.82s\n",
            "1756:\tlearn: 0.4557626\ttotal: 34.7s\tremaining: 4.8s\n",
            "1757:\tlearn: 0.4557246\ttotal: 34.7s\tremaining: 4.78s\n",
            "1758:\tlearn: 0.4556828\ttotal: 34.8s\tremaining: 4.76s\n",
            "1759:\tlearn: 0.4556455\ttotal: 34.8s\tremaining: 4.74s\n",
            "1760:\tlearn: 0.4556064\ttotal: 34.8s\tremaining: 4.72s\n",
            "1761:\tlearn: 0.4555807\ttotal: 34.8s\tremaining: 4.7s\n",
            "1762:\tlearn: 0.4555566\ttotal: 34.8s\tremaining: 4.68s\n",
            "1763:\tlearn: 0.4555309\ttotal: 34.9s\tremaining: 4.66s\n",
            "1764:\tlearn: 0.4554926\ttotal: 34.9s\tremaining: 4.64s\n",
            "1765:\tlearn: 0.4554599\ttotal: 34.9s\tremaining: 4.63s\n",
            "1766:\tlearn: 0.4554289\ttotal: 34.9s\tremaining: 4.61s\n",
            "1767:\tlearn: 0.4553951\ttotal: 34.9s\tremaining: 4.58s\n",
            "1768:\tlearn: 0.4553498\ttotal: 35s\tremaining: 4.57s\n",
            "1769:\tlearn: 0.4553196\ttotal: 35s\tremaining: 4.55s\n",
            "1770:\tlearn: 0.4552768\ttotal: 35s\tremaining: 4.53s\n",
            "1771:\tlearn: 0.4552385\ttotal: 35s\tremaining: 4.51s\n",
            "1772:\tlearn: 0.4552006\ttotal: 35.1s\tremaining: 4.49s\n",
            "1773:\tlearn: 0.4551717\ttotal: 35.1s\tremaining: 4.47s\n",
            "1774:\tlearn: 0.4551319\ttotal: 35.1s\tremaining: 4.45s\n",
            "1775:\tlearn: 0.4550874\ttotal: 35.1s\tremaining: 4.43s\n",
            "1776:\tlearn: 0.4550556\ttotal: 35.1s\tremaining: 4.41s\n",
            "1777:\tlearn: 0.4550217\ttotal: 35.2s\tremaining: 4.39s\n",
            "1778:\tlearn: 0.4549898\ttotal: 35.2s\tremaining: 4.37s\n",
            "1779:\tlearn: 0.4549591\ttotal: 35.2s\tremaining: 4.35s\n",
            "1780:\tlearn: 0.4549215\ttotal: 35.2s\tremaining: 4.33s\n",
            "1781:\tlearn: 0.4548800\ttotal: 35.2s\tremaining: 4.31s\n",
            "1782:\tlearn: 0.4548451\ttotal: 35.3s\tremaining: 4.29s\n",
            "1783:\tlearn: 0.4547981\ttotal: 35.3s\tremaining: 4.27s\n",
            "1784:\tlearn: 0.4547569\ttotal: 35.3s\tremaining: 4.25s\n",
            "1785:\tlearn: 0.4547262\ttotal: 35.3s\tremaining: 4.23s\n",
            "1786:\tlearn: 0.4546874\ttotal: 35.3s\tremaining: 4.21s\n",
            "1787:\tlearn: 0.4546573\ttotal: 35.4s\tremaining: 4.19s\n",
            "1788:\tlearn: 0.4546342\ttotal: 35.4s\tremaining: 4.17s\n",
            "1789:\tlearn: 0.4545975\ttotal: 35.4s\tremaining: 4.15s\n",
            "1790:\tlearn: 0.4545618\ttotal: 35.4s\tremaining: 4.13s\n",
            "1791:\tlearn: 0.4545332\ttotal: 35.4s\tremaining: 4.11s\n",
            "1792:\tlearn: 0.4545044\ttotal: 35.5s\tremaining: 4.09s\n",
            "1793:\tlearn: 0.4544816\ttotal: 35.5s\tremaining: 4.08s\n",
            "1794:\tlearn: 0.4544522\ttotal: 35.5s\tremaining: 4.05s\n",
            "1795:\tlearn: 0.4544247\ttotal: 35.5s\tremaining: 4.04s\n",
            "1796:\tlearn: 0.4543855\ttotal: 35.5s\tremaining: 4.01s\n",
            "1797:\tlearn: 0.4543542\ttotal: 35.6s\tremaining: 4s\n",
            "1798:\tlearn: 0.4543254\ttotal: 35.6s\tremaining: 3.98s\n",
            "1799:\tlearn: 0.4542919\ttotal: 35.6s\tremaining: 3.96s\n",
            "1800:\tlearn: 0.4542613\ttotal: 35.6s\tremaining: 3.94s\n",
            "1801:\tlearn: 0.4541945\ttotal: 35.6s\tremaining: 3.92s\n",
            "1802:\tlearn: 0.4541673\ttotal: 35.7s\tremaining: 3.9s\n",
            "1803:\tlearn: 0.4541329\ttotal: 35.7s\tremaining: 3.88s\n",
            "1804:\tlearn: 0.4541081\ttotal: 35.7s\tremaining: 3.86s\n",
            "1805:\tlearn: 0.4540743\ttotal: 35.7s\tremaining: 3.84s\n",
            "1806:\tlearn: 0.4540470\ttotal: 35.8s\tremaining: 3.82s\n",
            "1807:\tlearn: 0.4540209\ttotal: 35.8s\tremaining: 3.8s\n",
            "1808:\tlearn: 0.4539961\ttotal: 35.8s\tremaining: 3.78s\n",
            "1809:\tlearn: 0.4539698\ttotal: 35.8s\tremaining: 3.76s\n",
            "1810:\tlearn: 0.4539442\ttotal: 35.8s\tremaining: 3.74s\n",
            "1811:\tlearn: 0.4539062\ttotal: 35.8s\tremaining: 3.72s\n",
            "1812:\tlearn: 0.4538774\ttotal: 35.9s\tremaining: 3.7s\n",
            "1813:\tlearn: 0.4538385\ttotal: 35.9s\tremaining: 3.68s\n",
            "1814:\tlearn: 0.4538112\ttotal: 35.9s\tremaining: 3.66s\n",
            "1815:\tlearn: 0.4537785\ttotal: 35.9s\tremaining: 3.64s\n",
            "1816:\tlearn: 0.4537598\ttotal: 36s\tremaining: 3.62s\n",
            "1817:\tlearn: 0.4537354\ttotal: 36s\tremaining: 3.6s\n",
            "1818:\tlearn: 0.4536912\ttotal: 36s\tremaining: 3.58s\n",
            "1819:\tlearn: 0.4536666\ttotal: 36s\tremaining: 3.56s\n",
            "1820:\tlearn: 0.4536437\ttotal: 36s\tremaining: 3.54s\n",
            "1821:\tlearn: 0.4536191\ttotal: 36s\tremaining: 3.52s\n",
            "1822:\tlearn: 0.4535936\ttotal: 36.1s\tremaining: 3.5s\n",
            "1823:\tlearn: 0.4535619\ttotal: 36.1s\tremaining: 3.48s\n",
            "1824:\tlearn: 0.4535280\ttotal: 36.1s\tremaining: 3.46s\n",
            "1825:\tlearn: 0.4534746\ttotal: 36.1s\tremaining: 3.44s\n",
            "1826:\tlearn: 0.4534545\ttotal: 36.1s\tremaining: 3.42s\n",
            "1827:\tlearn: 0.4534310\ttotal: 36.2s\tremaining: 3.4s\n",
            "1828:\tlearn: 0.4534145\ttotal: 36.2s\tremaining: 3.38s\n",
            "1829:\tlearn: 0.4533821\ttotal: 36.2s\tremaining: 3.36s\n",
            "1830:\tlearn: 0.4533450\ttotal: 36.2s\tremaining: 3.34s\n",
            "1831:\tlearn: 0.4533256\ttotal: 36.3s\tremaining: 3.32s\n",
            "1832:\tlearn: 0.4532810\ttotal: 36.3s\tremaining: 3.3s\n",
            "1833:\tlearn: 0.4532541\ttotal: 36.3s\tremaining: 3.29s\n",
            "1834:\tlearn: 0.4532304\ttotal: 36.3s\tremaining: 3.27s\n",
            "1835:\tlearn: 0.4531532\ttotal: 36.3s\tremaining: 3.25s\n",
            "1836:\tlearn: 0.4531409\ttotal: 36.4s\tremaining: 3.23s\n",
            "1837:\tlearn: 0.4531132\ttotal: 36.4s\tremaining: 3.21s\n",
            "1838:\tlearn: 0.4530824\ttotal: 36.4s\tremaining: 3.19s\n",
            "1839:\tlearn: 0.4530439\ttotal: 36.4s\tremaining: 3.17s\n",
            "1840:\tlearn: 0.4529968\ttotal: 36.4s\tremaining: 3.15s\n",
            "1841:\tlearn: 0.4529658\ttotal: 36.5s\tremaining: 3.13s\n",
            "1842:\tlearn: 0.4529413\ttotal: 36.5s\tremaining: 3.11s\n",
            "1843:\tlearn: 0.4529190\ttotal: 36.5s\tremaining: 3.09s\n",
            "1844:\tlearn: 0.4529000\ttotal: 36.5s\tremaining: 3.07s\n",
            "1845:\tlearn: 0.4528645\ttotal: 36.5s\tremaining: 3.05s\n",
            "1846:\tlearn: 0.4528225\ttotal: 36.6s\tremaining: 3.03s\n",
            "1847:\tlearn: 0.4527919\ttotal: 36.6s\tremaining: 3.01s\n",
            "1848:\tlearn: 0.4527625\ttotal: 36.6s\tremaining: 2.99s\n",
            "1849:\tlearn: 0.4527186\ttotal: 36.6s\tremaining: 2.97s\n",
            "1850:\tlearn: 0.4526965\ttotal: 36.6s\tremaining: 2.95s\n",
            "1851:\tlearn: 0.4526641\ttotal: 36.7s\tremaining: 2.93s\n",
            "1852:\tlearn: 0.4526218\ttotal: 36.7s\tremaining: 2.91s\n",
            "1853:\tlearn: 0.4526061\ttotal: 36.7s\tremaining: 2.89s\n",
            "1854:\tlearn: 0.4525651\ttotal: 36.7s\tremaining: 2.87s\n",
            "1855:\tlearn: 0.4525433\ttotal: 36.7s\tremaining: 2.85s\n",
            "1856:\tlearn: 0.4525031\ttotal: 36.8s\tremaining: 2.83s\n",
            "1857:\tlearn: 0.4524799\ttotal: 36.8s\tremaining: 2.81s\n",
            "1858:\tlearn: 0.4524545\ttotal: 36.8s\tremaining: 2.79s\n",
            "1859:\tlearn: 0.4524333\ttotal: 36.8s\tremaining: 2.77s\n",
            "1860:\tlearn: 0.4524011\ttotal: 36.8s\tremaining: 2.75s\n",
            "1861:\tlearn: 0.4523774\ttotal: 36.9s\tremaining: 2.73s\n",
            "1862:\tlearn: 0.4523354\ttotal: 36.9s\tremaining: 2.71s\n",
            "1863:\tlearn: 0.4522957\ttotal: 36.9s\tremaining: 2.69s\n",
            "1864:\tlearn: 0.4522526\ttotal: 36.9s\tremaining: 2.67s\n",
            "1865:\tlearn: 0.4522167\ttotal: 36.9s\tremaining: 2.65s\n",
            "1866:\tlearn: 0.4521903\ttotal: 37s\tremaining: 2.63s\n",
            "1867:\tlearn: 0.4521596\ttotal: 37s\tremaining: 2.61s\n",
            "1868:\tlearn: 0.4521306\ttotal: 37s\tremaining: 2.59s\n",
            "1869:\tlearn: 0.4520581\ttotal: 37s\tremaining: 2.57s\n",
            "1870:\tlearn: 0.4520180\ttotal: 37s\tremaining: 2.55s\n",
            "1871:\tlearn: 0.4519806\ttotal: 37.1s\tremaining: 2.53s\n",
            "1872:\tlearn: 0.4519509\ttotal: 37.1s\tremaining: 2.51s\n",
            "1873:\tlearn: 0.4519016\ttotal: 37.1s\tremaining: 2.49s\n",
            "1874:\tlearn: 0.4518843\ttotal: 37.1s\tremaining: 2.47s\n",
            "1875:\tlearn: 0.4518612\ttotal: 37.1s\tremaining: 2.45s\n",
            "1876:\tlearn: 0.4518276\ttotal: 37.2s\tremaining: 2.43s\n",
            "1877:\tlearn: 0.4517884\ttotal: 37.2s\tremaining: 2.42s\n",
            "1878:\tlearn: 0.4517494\ttotal: 37.2s\tremaining: 2.4s\n",
            "1879:\tlearn: 0.4517292\ttotal: 37.2s\tremaining: 2.38s\n",
            "1880:\tlearn: 0.4516958\ttotal: 37.2s\tremaining: 2.36s\n",
            "1881:\tlearn: 0.4516630\ttotal: 37.3s\tremaining: 2.34s\n",
            "1882:\tlearn: 0.4516400\ttotal: 37.3s\tremaining: 2.32s\n",
            "1883:\tlearn: 0.4515932\ttotal: 37.3s\tremaining: 2.3s\n",
            "1884:\tlearn: 0.4515615\ttotal: 37.3s\tremaining: 2.28s\n",
            "1885:\tlearn: 0.4515418\ttotal: 37.3s\tremaining: 2.26s\n",
            "1886:\tlearn: 0.4514872\ttotal: 37.4s\tremaining: 2.24s\n",
            "1887:\tlearn: 0.4514471\ttotal: 37.4s\tremaining: 2.22s\n",
            "1888:\tlearn: 0.4514242\ttotal: 37.4s\tremaining: 2.2s\n",
            "1889:\tlearn: 0.4513930\ttotal: 37.4s\tremaining: 2.18s\n",
            "1890:\tlearn: 0.4513693\ttotal: 37.4s\tremaining: 2.16s\n",
            "1891:\tlearn: 0.4513238\ttotal: 37.5s\tremaining: 2.14s\n",
            "1892:\tlearn: 0.4512870\ttotal: 37.5s\tremaining: 2.12s\n",
            "1893:\tlearn: 0.4512531\ttotal: 37.5s\tremaining: 2.1s\n",
            "1894:\tlearn: 0.4512112\ttotal: 37.5s\tremaining: 2.08s\n",
            "1895:\tlearn: 0.4511773\ttotal: 37.5s\tremaining: 2.06s\n",
            "1896:\tlearn: 0.4511344\ttotal: 37.6s\tremaining: 2.04s\n",
            "1897:\tlearn: 0.4511179\ttotal: 37.6s\tremaining: 2.02s\n",
            "1898:\tlearn: 0.4510816\ttotal: 37.6s\tremaining: 2s\n",
            "1899:\tlearn: 0.4510584\ttotal: 37.6s\tremaining: 1.98s\n",
            "1900:\tlearn: 0.4510247\ttotal: 37.7s\tremaining: 1.96s\n",
            "1901:\tlearn: 0.4509779\ttotal: 37.7s\tremaining: 1.94s\n",
            "1902:\tlearn: 0.4509431\ttotal: 37.7s\tremaining: 1.92s\n",
            "1903:\tlearn: 0.4509177\ttotal: 37.7s\tremaining: 1.9s\n",
            "1904:\tlearn: 0.4509000\ttotal: 37.7s\tremaining: 1.88s\n",
            "1905:\tlearn: 0.4508603\ttotal: 37.7s\tremaining: 1.86s\n",
            "1906:\tlearn: 0.4508235\ttotal: 37.8s\tremaining: 1.84s\n",
            "1907:\tlearn: 0.4507944\ttotal: 37.8s\tremaining: 1.82s\n",
            "1908:\tlearn: 0.4507671\ttotal: 37.8s\tremaining: 1.8s\n",
            "1909:\tlearn: 0.4507186\ttotal: 37.8s\tremaining: 1.78s\n",
            "1910:\tlearn: 0.4506854\ttotal: 37.9s\tremaining: 1.76s\n",
            "1911:\tlearn: 0.4506473\ttotal: 37.9s\tremaining: 1.74s\n",
            "1912:\tlearn: 0.4506175\ttotal: 37.9s\tremaining: 1.72s\n",
            "1913:\tlearn: 0.4505949\ttotal: 37.9s\tremaining: 1.7s\n",
            "1914:\tlearn: 0.4505681\ttotal: 37.9s\tremaining: 1.68s\n",
            "1915:\tlearn: 0.4505179\ttotal: 38s\tremaining: 1.66s\n",
            "1916:\tlearn: 0.4504953\ttotal: 38s\tremaining: 1.64s\n",
            "1917:\tlearn: 0.4504686\ttotal: 38s\tremaining: 1.62s\n",
            "1918:\tlearn: 0.4504412\ttotal: 38s\tremaining: 1.6s\n",
            "1919:\tlearn: 0.4504177\ttotal: 38s\tremaining: 1.58s\n",
            "1920:\tlearn: 0.4503809\ttotal: 38.1s\tremaining: 1.56s\n",
            "1921:\tlearn: 0.4503499\ttotal: 38.1s\tremaining: 1.54s\n",
            "1922:\tlearn: 0.4503140\ttotal: 38.1s\tremaining: 1.52s\n",
            "1923:\tlearn: 0.4502787\ttotal: 38.1s\tremaining: 1.5s\n",
            "1924:\tlearn: 0.4502447\ttotal: 38.1s\tremaining: 1.49s\n",
            "1925:\tlearn: 0.4502011\ttotal: 38.2s\tremaining: 1.47s\n",
            "1926:\tlearn: 0.4501704\ttotal: 38.2s\tremaining: 1.45s\n",
            "1927:\tlearn: 0.4501450\ttotal: 38.2s\tremaining: 1.43s\n",
            "1928:\tlearn: 0.4501075\ttotal: 38.2s\tremaining: 1.41s\n",
            "1929:\tlearn: 0.4500735\ttotal: 38.2s\tremaining: 1.39s\n",
            "1930:\tlearn: 0.4500508\ttotal: 38.3s\tremaining: 1.37s\n",
            "1931:\tlearn: 0.4500096\ttotal: 38.3s\tremaining: 1.35s\n",
            "1932:\tlearn: 0.4499874\ttotal: 38.3s\tremaining: 1.33s\n",
            "1933:\tlearn: 0.4499607\ttotal: 38.3s\tremaining: 1.31s\n",
            "1934:\tlearn: 0.4499177\ttotal: 38.3s\tremaining: 1.29s\n",
            "1935:\tlearn: 0.4498655\ttotal: 38.4s\tremaining: 1.27s\n",
            "1936:\tlearn: 0.4498376\ttotal: 38.4s\tremaining: 1.25s\n",
            "1937:\tlearn: 0.4498176\ttotal: 38.4s\tremaining: 1.23s\n",
            "1938:\tlearn: 0.4498014\ttotal: 38.4s\tremaining: 1.21s\n",
            "1939:\tlearn: 0.4497617\ttotal: 38.4s\tremaining: 1.19s\n",
            "1940:\tlearn: 0.4497361\ttotal: 38.5s\tremaining: 1.17s\n",
            "1941:\tlearn: 0.4497252\ttotal: 38.5s\tremaining: 1.15s\n",
            "1942:\tlearn: 0.4496952\ttotal: 38.5s\tremaining: 1.13s\n",
            "1943:\tlearn: 0.4496575\ttotal: 38.5s\tremaining: 1.11s\n",
            "1944:\tlearn: 0.4496396\ttotal: 38.5s\tremaining: 1.09s\n",
            "1945:\tlearn: 0.4496076\ttotal: 38.6s\tremaining: 1.07s\n",
            "1946:\tlearn: 0.4495797\ttotal: 38.6s\tremaining: 1.05s\n",
            "1947:\tlearn: 0.4495382\ttotal: 38.6s\tremaining: 1.03s\n",
            "1948:\tlearn: 0.4495052\ttotal: 38.6s\tremaining: 1.01s\n",
            "1949:\tlearn: 0.4494791\ttotal: 38.6s\tremaining: 991ms\n",
            "1950:\tlearn: 0.4494355\ttotal: 38.7s\tremaining: 971ms\n",
            "1951:\tlearn: 0.4494073\ttotal: 38.7s\tremaining: 951ms\n",
            "1952:\tlearn: 0.4493685\ttotal: 38.7s\tremaining: 932ms\n",
            "1953:\tlearn: 0.4493461\ttotal: 38.7s\tremaining: 912ms\n",
            "1954:\tlearn: 0.4493175\ttotal: 38.8s\tremaining: 892ms\n",
            "1955:\tlearn: 0.4492948\ttotal: 38.8s\tremaining: 872ms\n",
            "1956:\tlearn: 0.4492630\ttotal: 38.8s\tremaining: 852ms\n",
            "1957:\tlearn: 0.4492232\ttotal: 38.8s\tremaining: 833ms\n",
            "1958:\tlearn: 0.4491944\ttotal: 38.8s\tremaining: 813ms\n",
            "1959:\tlearn: 0.4491688\ttotal: 38.9s\tremaining: 793ms\n",
            "1960:\tlearn: 0.4491454\ttotal: 38.9s\tremaining: 773ms\n",
            "1961:\tlearn: 0.4491216\ttotal: 38.9s\tremaining: 753ms\n",
            "1962:\tlearn: 0.4490980\ttotal: 38.9s\tremaining: 734ms\n",
            "1963:\tlearn: 0.4490606\ttotal: 38.9s\tremaining: 714ms\n",
            "1964:\tlearn: 0.4490427\ttotal: 39s\tremaining: 694ms\n",
            "1965:\tlearn: 0.4490071\ttotal: 39s\tremaining: 674ms\n",
            "1966:\tlearn: 0.4489750\ttotal: 39s\tremaining: 654ms\n",
            "1967:\tlearn: 0.4489364\ttotal: 39s\tremaining: 634ms\n",
            "1968:\tlearn: 0.4489073\ttotal: 39s\tremaining: 615ms\n",
            "1969:\tlearn: 0.4488590\ttotal: 39s\tremaining: 595ms\n",
            "1970:\tlearn: 0.4488425\ttotal: 39.1s\tremaining: 575ms\n",
            "1971:\tlearn: 0.4488160\ttotal: 39.1s\tremaining: 555ms\n",
            "1972:\tlearn: 0.4487852\ttotal: 39.1s\tremaining: 535ms\n",
            "1973:\tlearn: 0.4487511\ttotal: 39.1s\tremaining: 515ms\n",
            "1974:\tlearn: 0.4487186\ttotal: 39.2s\tremaining: 496ms\n",
            "1975:\tlearn: 0.4486728\ttotal: 39.2s\tremaining: 476ms\n",
            "1976:\tlearn: 0.4486308\ttotal: 39.2s\tremaining: 456ms\n",
            "1977:\tlearn: 0.4486004\ttotal: 39.2s\tremaining: 436ms\n",
            "1978:\tlearn: 0.4485736\ttotal: 39.2s\tremaining: 416ms\n",
            "1979:\tlearn: 0.4485456\ttotal: 39.3s\tremaining: 397ms\n",
            "1980:\tlearn: 0.4485167\ttotal: 39.3s\tremaining: 377ms\n",
            "1981:\tlearn: 0.4484958\ttotal: 39.3s\tremaining: 357ms\n",
            "1982:\tlearn: 0.4484783\ttotal: 39.3s\tremaining: 337ms\n",
            "1983:\tlearn: 0.4484401\ttotal: 39.3s\tremaining: 317ms\n",
            "1984:\tlearn: 0.4484146\ttotal: 39.4s\tremaining: 297ms\n",
            "1985:\tlearn: 0.4483974\ttotal: 39.4s\tremaining: 278ms\n",
            "1986:\tlearn: 0.4483748\ttotal: 39.4s\tremaining: 258ms\n",
            "1987:\tlearn: 0.4483367\ttotal: 39.4s\tremaining: 238ms\n",
            "1988:\tlearn: 0.4482957\ttotal: 39.4s\tremaining: 218ms\n",
            "1989:\tlearn: 0.4482657\ttotal: 39.5s\tremaining: 198ms\n",
            "1990:\tlearn: 0.4482300\ttotal: 39.5s\tremaining: 178ms\n",
            "1991:\tlearn: 0.4481950\ttotal: 39.5s\tremaining: 159ms\n",
            "1992:\tlearn: 0.4481703\ttotal: 39.5s\tremaining: 139ms\n",
            "1993:\tlearn: 0.4481356\ttotal: 39.5s\tremaining: 119ms\n",
            "1994:\tlearn: 0.4481078\ttotal: 39.6s\tremaining: 99.2ms\n",
            "1995:\tlearn: 0.4480711\ttotal: 39.6s\tremaining: 79.3ms\n",
            "1996:\tlearn: 0.4480225\ttotal: 39.6s\tremaining: 59.5ms\n",
            "1997:\tlearn: 0.4479954\ttotal: 39.6s\tremaining: 39.7ms\n",
            "1998:\tlearn: 0.4479742\ttotal: 39.6s\tremaining: 19.8ms\n",
            "1999:\tlearn: 0.4479340\ttotal: 39.7s\tremaining: 0us\n",
            "ROC Score for training set : 0.668140347195988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af8hjZonfBa2",
        "outputId": "bba8cd3a-8f7d-4433-a795-ad2269cfd1f1"
      },
      "source": [
        "CBmprdT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.30128616, 0.24019159, 0.27876093, ..., 0.02013416, 0.20897753,\n",
              "       0.17258378])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "qhKnp8L50uGd",
        "outputId": "b98ea821-6452-40f0-aa64-8c14bb345da8"
      },
      "source": [
        "subm.head()"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50883</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50884</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50885</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50886</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50887</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID  Response\n",
              "0  50883         0\n",
              "1  50884         0\n",
              "2  50885         0\n",
              "3  50886         0\n",
              "4  50887         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iwynY6f0_92",
        "outputId": "773855f5-05b7-4596-9250-4b0c6eb84d4d"
      },
      "source": [
        "id = np.array(test['ID'])\r\n",
        "id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([50883, 50884, 50885, ..., 72685, 72686, 72687], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "P2wkNh2n1aDK",
        "outputId": "9508ec17-64e9-4de2-b531-4d51f8183dcd"
      },
      "source": [
        "subDF = pd.DataFrame({'ID' : id,'Response' :lgprdT })\r\n",
        "subDF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50883</td>\n",
              "      <td>0.156747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50884</td>\n",
              "      <td>0.232679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50885</td>\n",
              "      <td>0.249267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50886</td>\n",
              "      <td>0.260792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50887</td>\n",
              "      <td>0.163089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21800</th>\n",
              "      <td>72683</td>\n",
              "      <td>0.245424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21801</th>\n",
              "      <td>72684</td>\n",
              "      <td>0.254321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21802</th>\n",
              "      <td>72685</td>\n",
              "      <td>0.143571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21803</th>\n",
              "      <td>72686</td>\n",
              "      <td>0.253649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21804</th>\n",
              "      <td>72687</td>\n",
              "      <td>0.157322</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21805 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  Response\n",
              "0      50883  0.156747\n",
              "1      50884  0.232679\n",
              "2      50885  0.249267\n",
              "3      50886  0.260792\n",
              "4      50887  0.163089\n",
              "...      ...       ...\n",
              "21800  72683  0.245424\n",
              "21801  72684  0.254321\n",
              "21802  72685  0.143571\n",
              "21803  72686  0.253649\n",
              "21804  72687  0.157322\n",
              "\n",
              "[21805 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqoRblDVD7F7"
      },
      "source": [
        "def _subModelP(modelprediction,modelname) :\r\n",
        "  id = np.array(test['ID'])\r\n",
        "  subDF = pd.DataFrame({'ID' : id,'Response' :modelprediction })\r\n",
        "  subDF.to_csv(modelname,index=False)"
      ],
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESnzyCzI1vOT"
      },
      "source": [
        "subDF.to_csv('LogPred03.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mct-UY--158C"
      },
      "source": [
        "_subModelP(DTmprdT ,'DTreePred01.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b609P2L3FCyp"
      },
      "source": [
        "_subModelP(GNBmprdT,'GNBPred01.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWg4Ou9lGnNZ"
      },
      "source": [
        "_subModelP(RFmprdT,'RFPred01.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZm1FJ6uIW2_"
      },
      "source": [
        "_subModelP(XGBmprdT,'XGBPred02.csv')"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UVfwO14Khie"
      },
      "source": [
        "_subModelP(LGBmprdT,'LGBMPred02.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntDMKMAnUcMJ"
      },
      "source": [
        "_subModelP(CBmprdT,'CBMPred08.csv')"
      ],
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK_rXhm9WU-w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt44Y73LvVRM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZW8XM9YvVX9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPuHFqQrvVcC",
        "outputId": "769f9c67-736b-49de-e8b3-b0f3bbe71bed"
      },
      "source": [
        "# hyper parameter tunning for LightGBM\r\n",
        "\r\n",
        "SEED = 4 \r\n",
        "NFOLDS = 2\r\n",
        "kf = KFold(n_splits= NFOLDS, shuffle=False)\r\n",
        "\r\n",
        "parameters = {\r\n",
        "          'num_leaves': np.arange(100,500,100),\r\n",
        "          'min_child_weight': np.arange(0.01,1,0.01),\r\n",
        "    }\r\n",
        "\r\n",
        "model = lgb.LGBMClassifier()\r\n",
        "\r\n",
        "RSCV = RandomizedSearchCV(model,parameters,scoring='roc_auc',cv=kf.split(X_train),n_iter=30,verbose=50)\r\n",
        "RSCV.fit(X_train,y_train)\r\n",
        "\r\n",
        "parameters = {\r\n",
        "          'feature_fraction': np.arange(0.1,0.4,0.01),\r\n",
        "          'bagging_fraction':np.arange(0.3,0.5,0.01),\r\n",
        "          'min_data_in_leaf': np.arange(100,1500,10),\r\n",
        "    }\r\n",
        "\r\n",
        "RSCV = RandomizedSearchCV(RSCV.best_estimator_,parameters,scoring='roc_auc',cv=kf.split(X_train),n_iter=30,verbose=50)\r\n",
        "RSCV.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 30 candidates, totalling 60 fits\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[CV] num_leaves=400, min_child_weight=0.9 ............................\n",
            "[CV]  num_leaves=400, min_child_weight=0.9, score=0.632, total=   2.4s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n",
            "[CV] num_leaves=400, min_child_weight=0.9 ............................\n",
            "[CV]  num_leaves=400, min_child_weight=0.9, score=0.635, total=   2.3s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.7s remaining:    0.0s\n",
            "[CV] num_leaves=400, min_child_weight=0.54 ...........................\n",
            "[CV]  num_leaves=400, min_child_weight=0.54, score=0.636, total=   2.2s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.9s remaining:    0.0s\n",
            "[CV] num_leaves=400, min_child_weight=0.54 ...........................\n",
            "[CV]  num_leaves=400, min_child_weight=0.54, score=0.633, total=   2.4s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    9.3s remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.26 ...........................\n",
            "[CV]  num_leaves=100, min_child_weight=0.26, score=0.636, total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.1s remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.26 ...........................\n",
            "[CV]  num_leaves=100, min_child_weight=0.26, score=0.643, total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   10.9s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.2 ............................\n",
            "[CV]  num_leaves=200, min_child_weight=0.2, score=0.638, total=   1.3s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   12.3s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.2 ............................\n",
            "[CV]  num_leaves=200, min_child_weight=0.2, score=0.633, total=   1.4s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   13.6s remaining:    0.0s\n",
            "[CV] num_leaves=300, min_child_weight=0.93 ...........................\n",
            "[CV]  num_leaves=300, min_child_weight=0.93, score=0.637, total=   1.8s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   15.4s remaining:    0.0s\n",
            "[CV] num_leaves=300, min_child_weight=0.93 ...........................\n",
            "[CV]  num_leaves=300, min_child_weight=0.93, score=0.637, total=   1.8s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   17.2s remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.52 ...........................\n",
            "[CV]  num_leaves=100, min_child_weight=0.52, score=0.643, total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   18.0s remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.52 ...........................\n",
            "[CV]  num_leaves=100, min_child_weight=0.52, score=0.642, total=   0.9s\n",
            "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   18.9s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.73 ...........................\n",
            "[CV]  num_leaves=200, min_child_weight=0.73, score=0.636, total=   1.4s\n",
            "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   20.3s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.73 ...........................\n",
            "[CV]  num_leaves=200, min_child_weight=0.73, score=0.635, total=   1.3s\n",
            "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   21.6s remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.54 ...........................\n",
            "[CV]  num_leaves=100, min_child_weight=0.54, score=0.638, total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   22.3s remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.54 ...........................\n",
            "[CV]  num_leaves=100, min_child_weight=0.54, score=0.640, total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   23.1s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.36000000000000004 ............\n",
            "[CV]  num_leaves=200, min_child_weight=0.36000000000000004, score=0.637, total=   1.3s\n",
            "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:   24.4s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.36000000000000004 ............\n",
            "[CV]  num_leaves=200, min_child_weight=0.36000000000000004, score=0.636, total=   1.4s\n",
            "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   25.8s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.9400000000000001 .............\n",
            "[CV]  num_leaves=200, min_child_weight=0.9400000000000001, score=0.640, total=   1.4s\n",
            "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   27.2s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.9400000000000001 .............\n",
            "[CV]  num_leaves=200, min_child_weight=0.9400000000000001, score=0.637, total=   1.3s\n",
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   28.5s remaining:    0.0s\n",
            "[CV] num_leaves=300, min_child_weight=0.54 ...........................\n",
            "[CV]  num_leaves=300, min_child_weight=0.54, score=0.638, total=   1.8s\n",
            "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:   30.3s remaining:    0.0s\n",
            "[CV] num_leaves=300, min_child_weight=0.54 ...........................\n",
            "[CV]  num_leaves=300, min_child_weight=0.54, score=0.639, total=   1.9s\n",
            "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:   32.2s remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.18000000000000002 ............\n",
            "[CV]  num_leaves=100, min_child_weight=0.18000000000000002, score=0.636, total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:   33.0s remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.18000000000000002 ............\n",
            "[CV]  num_leaves=100, min_child_weight=0.18000000000000002, score=0.641, total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   33.8s remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.39 ...........................\n",
            "[CV]  num_leaves=100, min_child_weight=0.39, score=0.641, total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   34.7s remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.39 ...........................\n",
            "[CV]  num_leaves=100, min_child_weight=0.39, score=0.642, total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   35.5s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.75 ...........................\n",
            "[CV]  num_leaves=200, min_child_weight=0.75, score=0.636, total=   1.3s\n",
            "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   36.8s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.75 ...........................\n",
            "[CV]  num_leaves=200, min_child_weight=0.75, score=0.638, total=   1.3s\n",
            "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   38.1s remaining:    0.0s\n",
            "[CV] num_leaves=300, min_child_weight=0.7100000000000001 .............\n",
            "[CV]  num_leaves=300, min_child_weight=0.7100000000000001, score=0.635, total=   1.8s\n",
            "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:   40.0s remaining:    0.0s\n",
            "[CV] num_leaves=300, min_child_weight=0.7100000000000001 .............\n",
            "[CV]  num_leaves=300, min_child_weight=0.7100000000000001, score=0.634, total=   1.9s\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   41.9s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.5 ............................\n",
            "[CV]  num_leaves=200, min_child_weight=0.5, score=0.635, total=   1.6s\n",
            "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:   43.4s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.5 ............................\n",
            "[CV]  num_leaves=200, min_child_weight=0.5, score=0.637, total=   1.5s\n",
            "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:   45.0s remaining:    0.0s\n",
            "[CV] num_leaves=300, min_child_weight=0.8400000000000001 .............\n",
            "[CV]  num_leaves=300, min_child_weight=0.8400000000000001, score=0.637, total=   2.1s\n",
            "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:   47.1s remaining:    0.0s\n",
            "[CV] num_leaves=300, min_child_weight=0.8400000000000001 .............\n",
            "[CV]  num_leaves=300, min_child_weight=0.8400000000000001, score=0.638, total=   2.3s\n",
            "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:   49.5s remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.46 ...........................\n",
            "[CV]  num_leaves=100, min_child_weight=0.46, score=0.641, total=   1.0s\n",
            "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:   50.4s remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.46 ...........................\n",
            "[CV]  num_leaves=100, min_child_weight=0.46, score=0.639, total=   0.9s\n",
            "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   51.4s remaining:    0.0s\n",
            "[CV] num_leaves=400, min_child_weight=0.31 ...........................\n",
            "[CV]  num_leaves=400, min_child_weight=0.31, score=0.638, total=   2.5s\n",
            "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:   53.9s remaining:    0.0s\n",
            "[CV] num_leaves=400, min_child_weight=0.31 ...........................\n",
            "[CV]  num_leaves=400, min_child_weight=0.31, score=0.630, total=   2.5s\n",
            "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:   56.4s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.55 ...........................\n",
            "[CV]  num_leaves=200, min_child_weight=0.55, score=0.639, total=   1.3s\n",
            "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:   57.7s remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.55 ...........................\n",
            "[CV]  num_leaves=200, min_child_weight=0.55, score=0.640, total=   1.3s\n",
            "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:   59.0s remaining:    0.0s\n",
            "[CV] num_leaves=300, min_child_weight=0.86 ...........................\n",
            "[CV]  num_leaves=300, min_child_weight=0.86, score=0.638, total=   1.8s\n",
            "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:  1.0min remaining:    0.0s\n",
            "[CV] num_leaves=300, min_child_weight=0.86 ...........................\n",
            "[CV]  num_leaves=300, min_child_weight=0.86, score=0.639, total=   1.9s\n",
            "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:  1.0min remaining:    0.0s\n",
            "[CV] num_leaves=400, min_child_weight=0.8 ............................\n",
            "[CV]  num_leaves=400, min_child_weight=0.8, score=0.635, total=   2.4s\n",
            "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] num_leaves=400, min_child_weight=0.8 ............................\n",
            "[CV]  num_leaves=400, min_child_weight=0.8, score=0.638, total=   2.3s\n",
            "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.63 ...........................\n",
            "[CV]  num_leaves=100, min_child_weight=0.63, score=0.638, total=   0.8s\n",
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] num_leaves=100, min_child_weight=0.63 ...........................\n",
            "[CV]  num_leaves=100, min_child_weight=0.63, score=0.641, total=   0.9s\n",
            "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.15000000000000002 ............\n",
            "[CV]  num_leaves=200, min_child_weight=0.15000000000000002, score=0.635, total=   1.5s\n",
            "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] num_leaves=200, min_child_weight=0.15000000000000002 ............\n",
            "[CV]  num_leaves=200, min_child_weight=0.15000000000000002, score=0.640, total=   1.4s\n",
            "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] num_leaves=400, min_child_weight=0.26 ...........................\n",
            "[CV]  num_leaves=400, min_child_weight=0.26, score=0.633, total=   2.4s\n",
            "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] num_leaves=400, min_child_weight=0.26 ...........................\n",
            "[CV]  num_leaves=400, min_child_weight=0.26, score=0.631, total=   2.5s\n",
            "[CV] num_leaves=400, min_child_weight=0.64 ...........................\n",
            "[CV]  num_leaves=400, min_child_weight=0.64, score=0.636, total=   2.3s\n",
            "[CV] num_leaves=400, min_child_weight=0.64 ...........................\n",
            "[CV]  num_leaves=400, min_child_weight=0.64, score=0.629, total=   2.5s\n",
            "[CV] num_leaves=100, min_child_weight=0.5 ............................\n",
            "[CV]  num_leaves=100, min_child_weight=0.5, score=0.640, total=   0.9s\n",
            "[CV] num_leaves=100, min_child_weight=0.5 ............................\n",
            "[CV]  num_leaves=100, min_child_weight=0.5, score=0.640, total=   0.8s\n",
            "[CV] num_leaves=200, min_child_weight=0.02 ...........................\n",
            "[CV]  num_leaves=200, min_child_weight=0.02, score=0.636, total=   1.3s\n",
            "[CV] num_leaves=200, min_child_weight=0.02 ...........................\n",
            "[CV]  num_leaves=200, min_child_weight=0.02, score=0.640, total=   1.4s\n",
            "[CV] num_leaves=300, min_child_weight=0.36000000000000004 ............\n",
            "[CV]  num_leaves=300, min_child_weight=0.36000000000000004, score=0.639, total=   1.9s\n",
            "[CV] num_leaves=300, min_child_weight=0.36000000000000004 ............\n",
            "[CV]  num_leaves=300, min_child_weight=0.36000000000000004, score=0.638, total=   1.9s\n",
            "[CV] num_leaves=300, min_child_weight=0.72 ...........................\n",
            "[CV]  num_leaves=300, min_child_weight=0.72, score=0.636, total=   1.8s\n",
            "[CV] num_leaves=300, min_child_weight=0.72 ...........................\n",
            "[CV]  num_leaves=300, min_child_weight=0.72, score=0.637, total=   1.8s\n",
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  1.6min finished\n",
            "Fitting 2 folds for each of 30 candidates, totalling 60 fits\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[CV] min_data_in_leaf=1070, feature_fraction=0.30999999999999994, bagging_fraction=0.4200000000000001 \n",
            "[CV]  min_data_in_leaf=1070, feature_fraction=0.30999999999999994, bagging_fraction=0.4200000000000001, score=0.611, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1070, feature_fraction=0.30999999999999994, bagging_fraction=0.4200000000000001 \n",
            "[CV]  min_data_in_leaf=1070, feature_fraction=0.30999999999999994, bagging_fraction=0.4200000000000001, score=0.622, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1290, feature_fraction=0.3699999999999999, bagging_fraction=0.33 \n",
            "[CV]  min_data_in_leaf=1290, feature_fraction=0.3699999999999999, bagging_fraction=0.33, score=0.612, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.2s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1290, feature_fraction=0.3699999999999999, bagging_fraction=0.33 \n",
            "[CV]  min_data_in_leaf=1290, feature_fraction=0.3699999999999999, bagging_fraction=0.33, score=0.618, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.7s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1020, feature_fraction=0.3599999999999999, bagging_fraction=0.32 \n",
            "[CV]  min_data_in_leaf=1020, feature_fraction=0.3599999999999999, bagging_fraction=0.32, score=0.616, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.1s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1020, feature_fraction=0.3599999999999999, bagging_fraction=0.32 \n",
            "[CV]  min_data_in_leaf=1020, feature_fraction=0.3599999999999999, bagging_fraction=0.32, score=0.624, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.5s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1060, feature_fraction=0.20999999999999996, bagging_fraction=0.4000000000000001 \n",
            "[CV]  min_data_in_leaf=1060, feature_fraction=0.20999999999999996, bagging_fraction=0.4000000000000001, score=0.599, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    2.9s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1060, feature_fraction=0.20999999999999996, bagging_fraction=0.4000000000000001 \n",
            "[CV]  min_data_in_leaf=1060, feature_fraction=0.20999999999999996, bagging_fraction=0.4000000000000001, score=0.607, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    3.3s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=580, feature_fraction=0.3199999999999999, bagging_fraction=0.4400000000000001 \n",
            "[CV]  min_data_in_leaf=580, feature_fraction=0.3199999999999999, bagging_fraction=0.4400000000000001, score=0.622, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    3.8s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=580, feature_fraction=0.3199999999999999, bagging_fraction=0.4400000000000001 \n",
            "[CV]  min_data_in_leaf=580, feature_fraction=0.3199999999999999, bagging_fraction=0.4400000000000001, score=0.628, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    4.3s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1020, feature_fraction=0.12, bagging_fraction=0.38000000000000006 \n",
            "[CV]  min_data_in_leaf=1020, feature_fraction=0.12, bagging_fraction=0.38000000000000006, score=0.586, total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    4.6s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1020, feature_fraction=0.12, bagging_fraction=0.38000000000000006 \n",
            "[CV]  min_data_in_leaf=1020, feature_fraction=0.12, bagging_fraction=0.38000000000000006, score=0.591, total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    4.9s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=930, feature_fraction=0.2699999999999999, bagging_fraction=0.38000000000000006 \n",
            "[CV]  min_data_in_leaf=930, feature_fraction=0.2699999999999999, bagging_fraction=0.38000000000000006, score=0.607, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    5.4s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=930, feature_fraction=0.2699999999999999, bagging_fraction=0.38000000000000006 \n",
            "[CV]  min_data_in_leaf=930, feature_fraction=0.2699999999999999, bagging_fraction=0.38000000000000006, score=0.616, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    5.8s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1280, feature_fraction=0.21999999999999995, bagging_fraction=0.4400000000000001 \n",
            "[CV]  min_data_in_leaf=1280, feature_fraction=0.21999999999999995, bagging_fraction=0.4400000000000001, score=0.604, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    6.2s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1280, feature_fraction=0.21999999999999995, bagging_fraction=0.4400000000000001 \n",
            "[CV]  min_data_in_leaf=1280, feature_fraction=0.21999999999999995, bagging_fraction=0.4400000000000001, score=0.610, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    6.6s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1430, feature_fraction=0.24999999999999992, bagging_fraction=0.36000000000000004 \n",
            "[CV]  min_data_in_leaf=1430, feature_fraction=0.24999999999999992, bagging_fraction=0.36000000000000004, score=0.601, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    6.9s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1430, feature_fraction=0.24999999999999992, bagging_fraction=0.36000000000000004 \n",
            "[CV]  min_data_in_leaf=1430, feature_fraction=0.24999999999999992, bagging_fraction=0.36000000000000004, score=0.605, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    7.3s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1190, feature_fraction=0.17999999999999997, bagging_fraction=0.4200000000000001 \n",
            "[CV]  min_data_in_leaf=1190, feature_fraction=0.17999999999999997, bagging_fraction=0.4200000000000001, score=0.600, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    7.7s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1190, feature_fraction=0.17999999999999997, bagging_fraction=0.4200000000000001 \n",
            "[CV]  min_data_in_leaf=1190, feature_fraction=0.17999999999999997, bagging_fraction=0.4200000000000001, score=0.606, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    8.1s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=240, feature_fraction=0.13, bagging_fraction=0.35000000000000003 \n",
            "[CV]  min_data_in_leaf=240, feature_fraction=0.13, bagging_fraction=0.35000000000000003, score=0.584, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    8.5s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=240, feature_fraction=0.13, bagging_fraction=0.35000000000000003 \n",
            "[CV]  min_data_in_leaf=240, feature_fraction=0.13, bagging_fraction=0.35000000000000003, score=0.583, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    8.9s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=480, feature_fraction=0.30999999999999994, bagging_fraction=0.49000000000000016 \n",
            "[CV]  min_data_in_leaf=480, feature_fraction=0.30999999999999994, bagging_fraction=0.49000000000000016, score=0.626, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    9.4s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=480, feature_fraction=0.30999999999999994, bagging_fraction=0.49000000000000016 \n",
            "[CV]  min_data_in_leaf=480, feature_fraction=0.30999999999999994, bagging_fraction=0.49000000000000016, score=0.630, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   10.0s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1350, feature_fraction=0.3799999999999999, bagging_fraction=0.4000000000000001 \n",
            "[CV]  min_data_in_leaf=1350, feature_fraction=0.3799999999999999, bagging_fraction=0.4000000000000001, score=0.611, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   10.4s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1350, feature_fraction=0.3799999999999999, bagging_fraction=0.4000000000000001 \n",
            "[CV]  min_data_in_leaf=1350, feature_fraction=0.3799999999999999, bagging_fraction=0.4000000000000001, score=0.615, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   10.7s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1400, feature_fraction=0.30999999999999994, bagging_fraction=0.39000000000000007 \n",
            "[CV]  min_data_in_leaf=1400, feature_fraction=0.30999999999999994, bagging_fraction=0.39000000000000007, score=0.605, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   11.1s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1400, feature_fraction=0.30999999999999994, bagging_fraction=0.39000000000000007 \n",
            "[CV]  min_data_in_leaf=1400, feature_fraction=0.30999999999999994, bagging_fraction=0.39000000000000007, score=0.611, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   11.5s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=370, feature_fraction=0.20999999999999996, bagging_fraction=0.4400000000000001 \n",
            "[CV]  min_data_in_leaf=370, feature_fraction=0.20999999999999996, bagging_fraction=0.4400000000000001, score=0.613, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:   12.0s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=370, feature_fraction=0.20999999999999996, bagging_fraction=0.4400000000000001 \n",
            "[CV]  min_data_in_leaf=370, feature_fraction=0.20999999999999996, bagging_fraction=0.4400000000000001, score=0.616, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   12.4s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=430, feature_fraction=0.3999999999999998, bagging_fraction=0.3 \n",
            "[CV]  min_data_in_leaf=430, feature_fraction=0.3999999999999998, bagging_fraction=0.3, score=0.629, total=   0.6s\n",
            "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:   13.0s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=430, feature_fraction=0.3999999999999998, bagging_fraction=0.3 \n",
            "[CV]  min_data_in_leaf=430, feature_fraction=0.3999999999999998, bagging_fraction=0.3, score=0.635, total=   0.6s\n",
            "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:   13.6s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1160, feature_fraction=0.16999999999999998, bagging_fraction=0.32 \n",
            "[CV]  min_data_in_leaf=1160, feature_fraction=0.16999999999999998, bagging_fraction=0.32, score=0.600, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:   13.9s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1160, feature_fraction=0.16999999999999998, bagging_fraction=0.32 \n",
            "[CV]  min_data_in_leaf=1160, feature_fraction=0.16999999999999998, bagging_fraction=0.32, score=0.607, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:   14.3s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1150, feature_fraction=0.2599999999999999, bagging_fraction=0.38000000000000006 \n",
            "[CV]  min_data_in_leaf=1150, feature_fraction=0.2599999999999999, bagging_fraction=0.38000000000000006, score=0.604, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:   14.8s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1150, feature_fraction=0.2599999999999999, bagging_fraction=0.38000000000000006 \n",
            "[CV]  min_data_in_leaf=1150, feature_fraction=0.2599999999999999, bagging_fraction=0.38000000000000006, score=0.615, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   15.2s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1400, feature_fraction=0.30999999999999994, bagging_fraction=0.35000000000000003 \n",
            "[CV]  min_data_in_leaf=1400, feature_fraction=0.30999999999999994, bagging_fraction=0.35000000000000003, score=0.605, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:   15.6s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1400, feature_fraction=0.30999999999999994, bagging_fraction=0.35000000000000003 \n",
            "[CV]  min_data_in_leaf=1400, feature_fraction=0.30999999999999994, bagging_fraction=0.35000000000000003, score=0.611, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:   16.0s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=680, feature_fraction=0.13, bagging_fraction=0.32 \n",
            "[CV]  min_data_in_leaf=680, feature_fraction=0.13, bagging_fraction=0.32, score=0.584, total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:   16.3s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=680, feature_fraction=0.13, bagging_fraction=0.32 \n",
            "[CV]  min_data_in_leaf=680, feature_fraction=0.13, bagging_fraction=0.32, score=0.587, total=   0.3s\n",
            "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:   16.7s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=420, feature_fraction=0.2899999999999999, bagging_fraction=0.4500000000000001 \n",
            "[CV]  min_data_in_leaf=420, feature_fraction=0.2899999999999999, bagging_fraction=0.4500000000000001, score=0.625, total=   0.6s\n",
            "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:   17.2s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=420, feature_fraction=0.2899999999999999, bagging_fraction=0.4500000000000001 \n",
            "[CV]  min_data_in_leaf=420, feature_fraction=0.2899999999999999, bagging_fraction=0.4500000000000001, score=0.630, total=   0.6s\n",
            "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:   17.8s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1350, feature_fraction=0.3199999999999999, bagging_fraction=0.37000000000000005 \n",
            "[CV]  min_data_in_leaf=1350, feature_fraction=0.3199999999999999, bagging_fraction=0.37000000000000005, score=0.610, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:   18.3s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1350, feature_fraction=0.3199999999999999, bagging_fraction=0.37000000000000005 \n",
            "[CV]  min_data_in_leaf=1350, feature_fraction=0.3199999999999999, bagging_fraction=0.37000000000000005, score=0.612, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:   18.7s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=920, feature_fraction=0.3199999999999999, bagging_fraction=0.4500000000000001 \n",
            "[CV]  min_data_in_leaf=920, feature_fraction=0.3199999999999999, bagging_fraction=0.4500000000000001, score=0.616, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   19.1s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=920, feature_fraction=0.3199999999999999, bagging_fraction=0.4500000000000001 \n",
            "[CV]  min_data_in_leaf=920, feature_fraction=0.3199999999999999, bagging_fraction=0.4500000000000001, score=0.622, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:   19.6s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1060, feature_fraction=0.22999999999999995, bagging_fraction=0.31 \n",
            "[CV]  min_data_in_leaf=1060, feature_fraction=0.22999999999999995, bagging_fraction=0.31, score=0.604, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:   20.0s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=1060, feature_fraction=0.22999999999999995, bagging_fraction=0.31 \n",
            "[CV]  min_data_in_leaf=1060, feature_fraction=0.22999999999999995, bagging_fraction=0.31, score=0.615, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:   20.5s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=810, feature_fraction=0.24999999999999992, bagging_fraction=0.33 \n",
            "[CV]  min_data_in_leaf=810, feature_fraction=0.24999999999999992, bagging_fraction=0.33, score=0.609, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:   20.9s remaining:    0.0s\n",
            "[CV] min_data_in_leaf=810, feature_fraction=0.24999999999999992, bagging_fraction=0.33 \n",
            "[CV]  min_data_in_leaf=810, feature_fraction=0.24999999999999992, bagging_fraction=0.33, score=0.616, total=   0.5s\n",
            "[CV] min_data_in_leaf=1190, feature_fraction=0.3799999999999999, bagging_fraction=0.35000000000000003 \n",
            "[CV]  min_data_in_leaf=1190, feature_fraction=0.3799999999999999, bagging_fraction=0.35000000000000003, score=0.613, total=   0.4s\n",
            "[CV] min_data_in_leaf=1190, feature_fraction=0.3799999999999999, bagging_fraction=0.35000000000000003 \n",
            "[CV]  min_data_in_leaf=1190, feature_fraction=0.3799999999999999, bagging_fraction=0.35000000000000003, score=0.623, total=   0.4s\n",
            "[CV] min_data_in_leaf=1070, feature_fraction=0.32999999999999985, bagging_fraction=0.4000000000000001 \n",
            "[CV]  min_data_in_leaf=1070, feature_fraction=0.32999999999999985, bagging_fraction=0.4000000000000001, score=0.611, total=   0.5s\n",
            "[CV] min_data_in_leaf=1070, feature_fraction=0.32999999999999985, bagging_fraction=0.4000000000000001 \n",
            "[CV]  min_data_in_leaf=1070, feature_fraction=0.32999999999999985, bagging_fraction=0.4000000000000001, score=0.622, total=   0.5s\n",
            "[CV] min_data_in_leaf=1140, feature_fraction=0.15999999999999998, bagging_fraction=0.4100000000000001 \n",
            "[CV]  min_data_in_leaf=1140, feature_fraction=0.15999999999999998, bagging_fraction=0.4100000000000001, score=0.600, total=   0.4s\n",
            "[CV] min_data_in_leaf=1140, feature_fraction=0.15999999999999998, bagging_fraction=0.4100000000000001 \n",
            "[CV]  min_data_in_leaf=1140, feature_fraction=0.15999999999999998, bagging_fraction=0.4100000000000001, score=0.606, total=   0.4s\n",
            "[CV] min_data_in_leaf=200, feature_fraction=0.3999999999999998, bagging_fraction=0.38000000000000006 \n",
            "[CV]  min_data_in_leaf=200, feature_fraction=0.3999999999999998, bagging_fraction=0.38000000000000006, score=0.637, total=   0.8s\n",
            "[CV] min_data_in_leaf=200, feature_fraction=0.3999999999999998, bagging_fraction=0.38000000000000006 \n",
            "[CV]  min_data_in_leaf=200, feature_fraction=0.3999999999999998, bagging_fraction=0.38000000000000006, score=0.639, total=   0.8s\n",
            "[CV] min_data_in_leaf=1270, feature_fraction=0.15999999999999998, bagging_fraction=0.48000000000000015 \n",
            "[CV]  min_data_in_leaf=1270, feature_fraction=0.15999999999999998, bagging_fraction=0.48000000000000015, score=0.599, total=   0.4s\n",
            "[CV] min_data_in_leaf=1270, feature_fraction=0.15999999999999998, bagging_fraction=0.48000000000000015 \n",
            "[CV]  min_data_in_leaf=1270, feature_fraction=0.15999999999999998, bagging_fraction=0.48000000000000015, score=0.607, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   26.3s finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x7f1bdd136d50>,\n",
              "                   error_score=nan,\n",
              "                   estimator=LGBMClassifier(boosting_type='gbdt',\n",
              "                                            class_weight=None,\n",
              "                                            colsample_bytree=1.0,\n",
              "                                            importance_type='split',\n",
              "                                            learning_rate=0.1, max_depth=-1,\n",
              "                                            min_child_samples=20,\n",
              "                                            min_child_weight=0.52,\n",
              "                                            min_split_gain=0.0,\n",
              "                                            n_estimators=100, n_jobs=-1,\n",
              "                                            num_leaves=100, objective=None,\n",
              "                                            ran...\n",
              "        980,  990, 1000, 1010, 1020, 1030, 1040, 1050, 1060, 1070, 1080,\n",
              "       1090, 1100, 1110, 1120, 1130, 1140, 1150, 1160, 1170, 1180, 1190,\n",
              "       1200, 1210, 1220, 1230, 1240, 1250, 1260, 1270, 1280, 1290, 1300,\n",
              "       1310, 1320, 1330, 1340, 1350, 1360, 1370, 1380, 1390, 1400, 1410,\n",
              "       1420, 1430, 1440, 1450, 1460, 1470, 1480, 1490])},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='roc_auc', verbose=50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjEX8G4fvVfi"
      },
      "source": [
        "LGBmprdT = RSCV.predict_proba(X_test)[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7ImS7XZ0uyr",
        "outputId": "d5df9fa6-e7f4-4295-fe43-2edb168ec4b7"
      },
      "source": [
        "# Hyperparameter tunning for LGBM using randomizedsearch\r\n",
        "\r\n",
        "rs_params = {\r\n",
        "\r\n",
        "        'bagging_fraction': [0.5,0.6,0.7,0.8,0.9],\r\n",
        "        'learning_rate'   : [0.1,0.01,0.3,0.03,0.5,0.05,0.9],\r\n",
        "        'bagging_frequency': [5,6,7,8,9],\r\n",
        "        'subsample'        : [0.2,0.3,0,4],\r\n",
        "        'feature_fraction': [0.5,0.6,0,7,0.8,0.9],\r\n",
        "        'max_depth': [2,6,8,10,15],\r\n",
        "        'min_data_in_leaf': [10,30,50,70,90,120],\r\n",
        "        'num_leaves': [15, 31, 63, 127,500,1000,2000],\r\n",
        "        'metric'    : ['auc_roc']\r\n",
        "\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Initialize a RandomizedSearchCV object using 5-fold CV-\r\n",
        "rs_cv = RandomizedSearchCV(estimator=lgb.LGBMClassifier(type= 'GPU',subsample_for_bin=200000,\r\n",
        "    min_child_samples =20,\r\n",
        "    min_child_weight = 0.001,\r\n",
        "    min_split_gain = 0.0,\r\n",
        "    colsample_bytree = 1.0,\r\n",
        "    reg_alpha = 0.0,\r\n",
        "    reg_lambda = 0.0,njobs=-1), param_distributions=rs_params, cv = 10, n_iter= 100,verbose=True)\r\n",
        "\r\n",
        "# Train on training data-\r\n",
        "rs_cv.fit(X_train, y_train,verbose=False)\r\n",
        "print(\"BEST PARAMETERS: \" + str(rs_cv.best_params_))\r\n",
        "print(\"BEST CV SCORE: \" + str(rs_cv.best_score_))\r\n",
        "\r\n",
        "pred = rs_cv.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction <=1.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 303 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "lightgbm.basic.LightGBMError: Check failed: feature_fraction >0.0 at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 302 .\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  5.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BEST PARAMETERS: {'subsample': 0.2, 'num_leaves': 31, 'min_data_in_leaf': 30, 'metric': 'auc_roc', 'max_depth': 10, 'learning_rate': 0.1, 'feature_fraction': 0.9, 'bagging_frequency': 9, 'bagging_fraction': 0.7}\n",
            "BEST CV SCORE: 0.760645681160471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snUF6T0V4mid"
      },
      "source": [
        "LGBmprdT = pred[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X5u7nObhJN-",
        "outputId": "2a412275-2193-43b5-92c6-cc3688bab835"
      },
      "source": [
        "LGBmprdT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.22257679, 0.26712223, 0.2768633 , ..., 0.00700645, 0.2422085 ,\n",
              "       0.13940995])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ff6g1QqGPC4"
      },
      "source": [
        "_subModelP(LGBmprdT,'LGBMPred03.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "NP3MmCHIGecy",
        "outputId": "24a8b661-9ba6-4f5a-af4a-e55def879b5c"
      },
      "source": [
        "# Model Blending LGBM /XGB / CATBOOST simple AVG\r\n",
        "\r\n",
        "df1 = pd.DataFrame({'XGB' : XGBmprdT})\r\n",
        "df2 = pd.DataFrame({'LGB' : LGBmprdT})\r\n",
        "df3 = pd.DataFrame({'CB'  : CBmprdT})          \r\n",
        "\r\n",
        "df = pd.concat([df1,df2,df3],axis=1)\r\n",
        "\r\n",
        "#df['FinalP'] = (df.XGB + df.LGB + df.CB) / 3\r\n",
        "\r\n",
        "df['FinalP'] = (df.LGB + df.CB) /2\r\n",
        "\r\n",
        "df"
      ],
      "execution_count": 397,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>XGB</th>\n",
              "      <th>LGB</th>\n",
              "      <th>CB</th>\n",
              "      <th>FinalP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013616</td>\n",
              "      <td>0.070058</td>\n",
              "      <td>0.248393</td>\n",
              "      <td>0.159226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.354282</td>\n",
              "      <td>0.301469</td>\n",
              "      <td>0.193089</td>\n",
              "      <td>0.247279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.320279</td>\n",
              "      <td>0.188668</td>\n",
              "      <td>0.232929</td>\n",
              "      <td>0.210798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.206981</td>\n",
              "      <td>0.348133</td>\n",
              "      <td>0.247608</td>\n",
              "      <td>0.297871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.008384</td>\n",
              "      <td>0.181622</td>\n",
              "      <td>0.178879</td>\n",
              "      <td>0.180250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21800</th>\n",
              "      <td>0.151095</td>\n",
              "      <td>0.298114</td>\n",
              "      <td>0.208410</td>\n",
              "      <td>0.253262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21801</th>\n",
              "      <td>0.071749</td>\n",
              "      <td>0.254196</td>\n",
              "      <td>0.237576</td>\n",
              "      <td>0.245886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21802</th>\n",
              "      <td>0.000688</td>\n",
              "      <td>0.001554</td>\n",
              "      <td>0.030537</td>\n",
              "      <td>0.016045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21803</th>\n",
              "      <td>0.186505</td>\n",
              "      <td>0.196095</td>\n",
              "      <td>0.195283</td>\n",
              "      <td>0.195689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21804</th>\n",
              "      <td>0.029607</td>\n",
              "      <td>0.050924</td>\n",
              "      <td>0.145299</td>\n",
              "      <td>0.098111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21805 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            XGB       LGB        CB    FinalP\n",
              "0      0.013616  0.070058  0.248393  0.159226\n",
              "1      0.354282  0.301469  0.193089  0.247279\n",
              "2      0.320279  0.188668  0.232929  0.210798\n",
              "3      0.206981  0.348133  0.247608  0.297871\n",
              "4      0.008384  0.181622  0.178879  0.180250\n",
              "...         ...       ...       ...       ...\n",
              "21800  0.151095  0.298114  0.208410  0.253262\n",
              "21801  0.071749  0.254196  0.237576  0.245886\n",
              "21802  0.000688  0.001554  0.030537  0.016045\n",
              "21803  0.186505  0.196095  0.195283  0.195689\n",
              "21804  0.029607  0.050924  0.145299  0.098111\n",
              "\n",
              "[21805 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 397
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "EZm8AaNlXOpl",
        "outputId": "aa036399-694a-47f4-9f11-d45aa5233e98"
      },
      "source": [
        "# Model Blending LGBM /XGB / CATBOOST Weighted AVG\r\n",
        "\r\n",
        "df1 = pd.DataFrame({'XGB' : XGBmprdT})\r\n",
        "df2 = pd.DataFrame({'LGB' : LGBmprdT})\r\n",
        "df3 = pd.DataFrame({'CB'  : CBmprdT})          \r\n",
        "\r\n",
        "df = pd.concat([df1,df2,df3],axis=1)\r\n",
        "\r\n",
        "df['FinalP'] = (2* df.XGB + df.LGB + 2* df.CB) / 5\r\n",
        "\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>XGB</th>\n",
              "      <th>LGB</th>\n",
              "      <th>CB</th>\n",
              "      <th>FinalP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.053797</td>\n",
              "      <td>0.081356</td>\n",
              "      <td>0.301286</td>\n",
              "      <td>0.158304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.078403</td>\n",
              "      <td>0.269415</td>\n",
              "      <td>0.240192</td>\n",
              "      <td>0.181321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.191077</td>\n",
              "      <td>0.328643</td>\n",
              "      <td>0.278761</td>\n",
              "      <td>0.253664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.250380</td>\n",
              "      <td>0.158678</td>\n",
              "      <td>0.223630</td>\n",
              "      <td>0.221340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.040310</td>\n",
              "      <td>0.117353</td>\n",
              "      <td>0.274096</td>\n",
              "      <td>0.149233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21800</th>\n",
              "      <td>0.048434</td>\n",
              "      <td>0.186074</td>\n",
              "      <td>0.210653</td>\n",
              "      <td>0.140849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21801</th>\n",
              "      <td>0.156738</td>\n",
              "      <td>0.124498</td>\n",
              "      <td>0.231980</td>\n",
              "      <td>0.180387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21802</th>\n",
              "      <td>0.003428</td>\n",
              "      <td>0.004359</td>\n",
              "      <td>0.020134</td>\n",
              "      <td>0.010297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21803</th>\n",
              "      <td>0.120674</td>\n",
              "      <td>0.197380</td>\n",
              "      <td>0.208978</td>\n",
              "      <td>0.171336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21804</th>\n",
              "      <td>0.055816</td>\n",
              "      <td>0.042723</td>\n",
              "      <td>0.172584</td>\n",
              "      <td>0.099904</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21805 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            XGB       LGB        CB    FinalP\n",
              "0      0.053797  0.081356  0.301286  0.158304\n",
              "1      0.078403  0.269415  0.240192  0.181321\n",
              "2      0.191077  0.328643  0.278761  0.253664\n",
              "3      0.250380  0.158678  0.223630  0.221340\n",
              "4      0.040310  0.117353  0.274096  0.149233\n",
              "...         ...       ...       ...       ...\n",
              "21800  0.048434  0.186074  0.210653  0.140849\n",
              "21801  0.156738  0.124498  0.231980  0.180387\n",
              "21802  0.003428  0.004359  0.020134  0.010297\n",
              "21803  0.120674  0.197380  0.208978  0.171336\n",
              "21804  0.055816  0.042723  0.172584  0.099904\n",
              "\n",
              "[21805 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "qBG0RJsi3_DY",
        "outputId": "0f6fcf8c-a177-4f0f-cc65-90b8c335df6f"
      },
      "source": [
        "# Model Blending LGBM /XGB / CATBOOST RANK AVG\r\n",
        "\r\n",
        "df1 = pd.DataFrame({'XGB' : XGBmprdT})\r\n",
        "df2 = pd.DataFrame({'LGB' : LGBmprdT})\r\n",
        "df3 = pd.DataFrame({'CB'  : CBmprdT})     \r\n",
        "\r\n",
        "# Rank of 1 for least model pred and 3 for best model pred\r\n",
        "\r\n",
        "r1_Weight ,r2_Weight , r3_Weight  = 1/3 , 1/3 , 2/3\r\n",
        "\r\n",
        "df = pd.concat([df1,df2,df3],axis=1)\r\n",
        "\r\n",
        "df['FinalP'] = (r1_Weight * df.XGB + r2_Weight * df.LGB + r3_Weight * df.CB) \r\n",
        "\r\n",
        "df"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>XGB</th>\n",
              "      <th>LGB</th>\n",
              "      <th>CB</th>\n",
              "      <th>FinalP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013616</td>\n",
              "      <td>0.048032</td>\n",
              "      <td>0.268901</td>\n",
              "      <td>0.199817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.354282</td>\n",
              "      <td>0.142861</td>\n",
              "      <td>0.191563</td>\n",
              "      <td>0.293423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.320279</td>\n",
              "      <td>0.351823</td>\n",
              "      <td>0.250134</td>\n",
              "      <td>0.390790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.206981</td>\n",
              "      <td>0.241989</td>\n",
              "      <td>0.235848</td>\n",
              "      <td>0.306889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.008384</td>\n",
              "      <td>0.122111</td>\n",
              "      <td>0.210349</td>\n",
              "      <td>0.183731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21800</th>\n",
              "      <td>0.151095</td>\n",
              "      <td>0.174334</td>\n",
              "      <td>0.234685</td>\n",
              "      <td>0.264933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21801</th>\n",
              "      <td>0.071749</td>\n",
              "      <td>0.137278</td>\n",
              "      <td>0.227372</td>\n",
              "      <td>0.221257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21802</th>\n",
              "      <td>0.000688</td>\n",
              "      <td>0.003253</td>\n",
              "      <td>0.029957</td>\n",
              "      <td>0.021285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21803</th>\n",
              "      <td>0.186505</td>\n",
              "      <td>0.444215</td>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.338266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21804</th>\n",
              "      <td>0.029607</td>\n",
              "      <td>0.028490</td>\n",
              "      <td>0.142712</td>\n",
              "      <td>0.114507</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21805 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            XGB       LGB        CB    FinalP\n",
              "0      0.013616  0.048032  0.268901  0.199817\n",
              "1      0.354282  0.142861  0.191563  0.293423\n",
              "2      0.320279  0.351823  0.250134  0.390790\n",
              "3      0.206981  0.241989  0.235848  0.306889\n",
              "4      0.008384  0.122111  0.210349  0.183731\n",
              "...         ...       ...       ...       ...\n",
              "21800  0.151095  0.174334  0.234685  0.264933\n",
              "21801  0.071749  0.137278  0.227372  0.221257\n",
              "21802  0.000688  0.003253  0.029957  0.021285\n",
              "21803  0.186505  0.444215  0.192039  0.338266\n",
              "21804  0.029607  0.028490  0.142712  0.114507\n",
              "\n",
              "[21805 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "gUfFTtjbfjIe",
        "outputId": "3f5e18fa-6749-45aa-9e8e-e84eed5a2a69"
      },
      "source": [
        "# Model Blending LGBM /XGB / CATBOOST simple AVG\r\n",
        "\r\n",
        "df1 = pd.DataFrame({'XGB' : XGBmprd})\r\n",
        "df2 = pd.DataFrame({'LGB' : LGBmprd})\r\n",
        "df3 = pd.DataFrame({'CB'  : CBmprd})          \r\n",
        "\r\n",
        "df = pd.concat([df1,df2,df3],axis=1)\r\n",
        "\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>XGB</th>\n",
              "      <th>LGB</th>\n",
              "      <th>CB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.559456</td>\n",
              "      <td>0.299432</td>\n",
              "      <td>0.391467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.008518</td>\n",
              "      <td>0.070852</td>\n",
              "      <td>0.294144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.379374</td>\n",
              "      <td>0.192002</td>\n",
              "      <td>0.233264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.549848</td>\n",
              "      <td>0.217681</td>\n",
              "      <td>0.289944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.885626</td>\n",
              "      <td>0.687662</td>\n",
              "      <td>0.359679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15260</th>\n",
              "      <td>0.003032</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.010704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15261</th>\n",
              "      <td>0.078518</td>\n",
              "      <td>0.239246</td>\n",
              "      <td>0.277175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15262</th>\n",
              "      <td>0.005031</td>\n",
              "      <td>0.118514</td>\n",
              "      <td>0.232573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15263</th>\n",
              "      <td>0.011684</td>\n",
              "      <td>0.022522</td>\n",
              "      <td>0.068598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15264</th>\n",
              "      <td>0.004912</td>\n",
              "      <td>0.140254</td>\n",
              "      <td>0.275925</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15265 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            XGB       LGB        CB\n",
              "0      0.559456  0.299432  0.391467\n",
              "1      0.008518  0.070852  0.294144\n",
              "2      0.379374  0.192002  0.233264\n",
              "3      0.549848  0.217681  0.289944\n",
              "4      0.885626  0.687662  0.359679\n",
              "...         ...       ...       ...\n",
              "15260  0.003032  0.000084  0.010704\n",
              "15261  0.078518  0.239246  0.277175\n",
              "15262  0.005031  0.118514  0.232573\n",
              "15263  0.011684  0.022522  0.068598\n",
              "15264  0.004912  0.140254  0.275925\n",
              "\n",
              "[15265 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 431
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5kqlP25chfY",
        "outputId": "32948868-ec82-42b3-e211-b839c579f16b"
      },
      "source": [
        "# Build another model on top of blended models XGB,CB,LGB\r\n",
        "\r\n",
        "X = np.array(df[['XGB','LGB','CB']])\r\n",
        "lrclf = LogisticRegression(max_iter=1000)\r\n",
        "lrclf.fit(X,y_val)\r\n",
        "lrclf.predict_proba(X)[:,1]\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.453275  , 0.2541234 , 0.25465617, ..., 0.20197737, 0.10545116,\n",
              "       0.2367807 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 439
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS-oF962h5RA",
        "outputId": "8c0cae86-4203-4de6-dae2-e736e66ba9d9"
      },
      "source": [
        "X = np.array(df[['XGB','LGB','CB']])\r\n",
        "cbclf = CatBoostClassifier(n_estimators=2000)\r\n",
        "cbclf.fit(X,y_val)\r\n",
        "CBmprdT = cbclf.predict_proba(X_test)[:,1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.017471\n",
            "0:\tlearn: 0.6856333\ttotal: 8.74ms\tremaining: 17.5s\n",
            "1:\tlearn: 0.6786111\ttotal: 17.6ms\tremaining: 17.6s\n",
            "2:\tlearn: 0.6717704\ttotal: 29.8ms\tremaining: 19.8s\n",
            "3:\tlearn: 0.6653952\ttotal: 38.5ms\tremaining: 19.2s\n",
            "4:\tlearn: 0.6590775\ttotal: 48.5ms\tremaining: 19.4s\n",
            "5:\tlearn: 0.6532745\ttotal: 57.4ms\tremaining: 19.1s\n",
            "6:\tlearn: 0.6477706\ttotal: 67.4ms\tremaining: 19.2s\n",
            "7:\tlearn: 0.6425530\ttotal: 75ms\tremaining: 18.7s\n",
            "8:\tlearn: 0.6372990\ttotal: 83.8ms\tremaining: 18.5s\n",
            "9:\tlearn: 0.6319773\ttotal: 93.6ms\tremaining: 18.6s\n",
            "10:\tlearn: 0.6274748\ttotal: 102ms\tremaining: 18.4s\n",
            "11:\tlearn: 0.6231392\ttotal: 110ms\tremaining: 18.3s\n",
            "12:\tlearn: 0.6186955\ttotal: 121ms\tremaining: 18.5s\n",
            "13:\tlearn: 0.6146871\ttotal: 131ms\tremaining: 18.5s\n",
            "14:\tlearn: 0.6107073\ttotal: 140ms\tremaining: 18.5s\n",
            "15:\tlearn: 0.6068923\ttotal: 152ms\tremaining: 18.9s\n",
            "16:\tlearn: 0.6032842\ttotal: 161ms\tremaining: 18.8s\n",
            "17:\tlearn: 0.5995334\ttotal: 171ms\tremaining: 18.8s\n",
            "18:\tlearn: 0.5961662\ttotal: 179ms\tremaining: 18.7s\n",
            "19:\tlearn: 0.5927880\ttotal: 189ms\tremaining: 18.7s\n",
            "20:\tlearn: 0.5896605\ttotal: 201ms\tremaining: 18.9s\n",
            "21:\tlearn: 0.5866589\ttotal: 212ms\tremaining: 19s\n",
            "22:\tlearn: 0.5834760\ttotal: 222ms\tremaining: 19.1s\n",
            "23:\tlearn: 0.5807327\ttotal: 231ms\tremaining: 19.1s\n",
            "24:\tlearn: 0.5778763\ttotal: 241ms\tremaining: 19s\n",
            "25:\tlearn: 0.5753012\ttotal: 250ms\tremaining: 19s\n",
            "26:\tlearn: 0.5729619\ttotal: 262ms\tremaining: 19.2s\n",
            "27:\tlearn: 0.5702835\ttotal: 272ms\tremaining: 19.2s\n",
            "28:\tlearn: 0.5678672\ttotal: 283ms\tremaining: 19.3s\n",
            "29:\tlearn: 0.5654631\ttotal: 294ms\tremaining: 19.3s\n",
            "30:\tlearn: 0.5634017\ttotal: 302ms\tremaining: 19.2s\n",
            "31:\tlearn: 0.5611979\ttotal: 312ms\tremaining: 19.2s\n",
            "32:\tlearn: 0.5592031\ttotal: 322ms\tremaining: 19.2s\n",
            "33:\tlearn: 0.5573984\ttotal: 331ms\tremaining: 19.2s\n",
            "34:\tlearn: 0.5558573\ttotal: 339ms\tremaining: 19s\n",
            "35:\tlearn: 0.5541257\ttotal: 349ms\tremaining: 19.1s\n",
            "36:\tlearn: 0.5523716\ttotal: 360ms\tremaining: 19.1s\n",
            "37:\tlearn: 0.5507579\ttotal: 371ms\tremaining: 19.1s\n",
            "38:\tlearn: 0.5492149\ttotal: 380ms\tremaining: 19.1s\n",
            "39:\tlearn: 0.5478150\ttotal: 401ms\tremaining: 19.6s\n",
            "40:\tlearn: 0.5464383\ttotal: 410ms\tremaining: 19.6s\n",
            "41:\tlearn: 0.5451073\ttotal: 419ms\tremaining: 19.5s\n",
            "42:\tlearn: 0.5437634\ttotal: 428ms\tremaining: 19.5s\n",
            "43:\tlearn: 0.5425053\ttotal: 438ms\tremaining: 19.5s\n",
            "44:\tlearn: 0.5413773\ttotal: 447ms\tremaining: 19.4s\n",
            "45:\tlearn: 0.5402358\ttotal: 456ms\tremaining: 19.4s\n",
            "46:\tlearn: 0.5391232\ttotal: 465ms\tremaining: 19.3s\n",
            "47:\tlearn: 0.5380806\ttotal: 475ms\tremaining: 19.3s\n",
            "48:\tlearn: 0.5370647\ttotal: 482ms\tremaining: 19.2s\n",
            "49:\tlearn: 0.5360450\ttotal: 492ms\tremaining: 19.2s\n",
            "50:\tlearn: 0.5351019\ttotal: 501ms\tremaining: 19.1s\n",
            "51:\tlearn: 0.5341977\ttotal: 510ms\tremaining: 19.1s\n",
            "52:\tlearn: 0.5332903\ttotal: 520ms\tremaining: 19.1s\n",
            "53:\tlearn: 0.5324497\ttotal: 529ms\tremaining: 19.1s\n",
            "54:\tlearn: 0.5315084\ttotal: 539ms\tremaining: 19s\n",
            "55:\tlearn: 0.5307221\ttotal: 548ms\tremaining: 19s\n",
            "56:\tlearn: 0.5299292\ttotal: 557ms\tremaining: 19s\n",
            "57:\tlearn: 0.5292245\ttotal: 566ms\tremaining: 18.9s\n",
            "58:\tlearn: 0.5285411\ttotal: 577ms\tremaining: 19s\n",
            "59:\tlearn: 0.5277823\ttotal: 586ms\tremaining: 19s\n",
            "60:\tlearn: 0.5270542\ttotal: 595ms\tremaining: 18.9s\n",
            "61:\tlearn: 0.5264120\ttotal: 608ms\tremaining: 19s\n",
            "62:\tlearn: 0.5258161\ttotal: 619ms\tremaining: 19s\n",
            "63:\tlearn: 0.5251947\ttotal: 628ms\tremaining: 19s\n",
            "64:\tlearn: 0.5246181\ttotal: 635ms\tremaining: 18.9s\n",
            "65:\tlearn: 0.5239965\ttotal: 644ms\tremaining: 18.9s\n",
            "66:\tlearn: 0.5234189\ttotal: 653ms\tremaining: 18.8s\n",
            "67:\tlearn: 0.5227945\ttotal: 662ms\tremaining: 18.8s\n",
            "68:\tlearn: 0.5222901\ttotal: 671ms\tremaining: 18.8s\n",
            "69:\tlearn: 0.5217987\ttotal: 681ms\tremaining: 18.8s\n",
            "70:\tlearn: 0.5213381\ttotal: 691ms\tremaining: 18.8s\n",
            "71:\tlearn: 0.5208994\ttotal: 701ms\tremaining: 18.8s\n",
            "72:\tlearn: 0.5203930\ttotal: 713ms\tremaining: 18.8s\n",
            "73:\tlearn: 0.5199477\ttotal: 724ms\tremaining: 18.9s\n",
            "74:\tlearn: 0.5195535\ttotal: 733ms\tremaining: 18.8s\n",
            "75:\tlearn: 0.5191123\ttotal: 742ms\tremaining: 18.8s\n",
            "76:\tlearn: 0.5187551\ttotal: 751ms\tremaining: 18.7s\n",
            "77:\tlearn: 0.5183693\ttotal: 762ms\tremaining: 18.8s\n",
            "78:\tlearn: 0.5180424\ttotal: 775ms\tremaining: 18.9s\n",
            "79:\tlearn: 0.5177121\ttotal: 784ms\tremaining: 18.8s\n",
            "80:\tlearn: 0.5174083\ttotal: 793ms\tremaining: 18.8s\n",
            "81:\tlearn: 0.5171086\ttotal: 810ms\tremaining: 18.9s\n",
            "82:\tlearn: 0.5167955\ttotal: 820ms\tremaining: 18.9s\n",
            "83:\tlearn: 0.5163802\ttotal: 829ms\tremaining: 18.9s\n",
            "84:\tlearn: 0.5160737\ttotal: 839ms\tremaining: 18.9s\n",
            "85:\tlearn: 0.5156990\ttotal: 848ms\tremaining: 18.9s\n",
            "86:\tlearn: 0.5153789\ttotal: 860ms\tremaining: 18.9s\n",
            "87:\tlearn: 0.5150742\ttotal: 869ms\tremaining: 18.9s\n",
            "88:\tlearn: 0.5148321\ttotal: 877ms\tremaining: 18.8s\n",
            "89:\tlearn: 0.5145733\ttotal: 889ms\tremaining: 18.9s\n",
            "90:\tlearn: 0.5143511\ttotal: 899ms\tremaining: 18.9s\n",
            "91:\tlearn: 0.5140810\ttotal: 909ms\tremaining: 18.8s\n",
            "92:\tlearn: 0.5138626\ttotal: 918ms\tremaining: 18.8s\n",
            "93:\tlearn: 0.5136410\ttotal: 926ms\tremaining: 18.8s\n",
            "94:\tlearn: 0.5134219\ttotal: 935ms\tremaining: 18.7s\n",
            "95:\tlearn: 0.5132041\ttotal: 944ms\tremaining: 18.7s\n",
            "96:\tlearn: 0.5130204\ttotal: 952ms\tremaining: 18.7s\n",
            "97:\tlearn: 0.5127918\ttotal: 961ms\tremaining: 18.7s\n",
            "98:\tlearn: 0.5126160\ttotal: 970ms\tremaining: 18.6s\n",
            "99:\tlearn: 0.5124423\ttotal: 978ms\tremaining: 18.6s\n",
            "100:\tlearn: 0.5122926\ttotal: 987ms\tremaining: 18.6s\n",
            "101:\tlearn: 0.5121003\ttotal: 995ms\tremaining: 18.5s\n",
            "102:\tlearn: 0.5119580\ttotal: 1s\tremaining: 18.5s\n",
            "103:\tlearn: 0.5117660\ttotal: 1.02s\tremaining: 18.5s\n",
            "104:\tlearn: 0.5116111\ttotal: 1.03s\tremaining: 18.5s\n",
            "105:\tlearn: 0.5114547\ttotal: 1.03s\tremaining: 18.5s\n",
            "106:\tlearn: 0.5113372\ttotal: 1.04s\tremaining: 18.5s\n",
            "107:\tlearn: 0.5111720\ttotal: 1.05s\tremaining: 18.5s\n",
            "108:\tlearn: 0.5110399\ttotal: 1.06s\tremaining: 18.5s\n",
            "109:\tlearn: 0.5109087\ttotal: 1.07s\tremaining: 18.4s\n",
            "110:\tlearn: 0.5107762\ttotal: 1.08s\tremaining: 18.4s\n",
            "111:\tlearn: 0.5106307\ttotal: 1.09s\tremaining: 18.4s\n",
            "112:\tlearn: 0.5105096\ttotal: 1.1s\tremaining: 18.4s\n",
            "113:\tlearn: 0.5103929\ttotal: 1.11s\tremaining: 18.4s\n",
            "114:\tlearn: 0.5102866\ttotal: 1.12s\tremaining: 18.4s\n",
            "115:\tlearn: 0.5101766\ttotal: 1.13s\tremaining: 18.4s\n",
            "116:\tlearn: 0.5100597\ttotal: 1.14s\tremaining: 18.4s\n",
            "117:\tlearn: 0.5099426\ttotal: 1.15s\tremaining: 18.4s\n",
            "118:\tlearn: 0.5098437\ttotal: 1.16s\tremaining: 18.4s\n",
            "119:\tlearn: 0.5097397\ttotal: 1.17s\tremaining: 18.4s\n",
            "120:\tlearn: 0.5096086\ttotal: 1.19s\tremaining: 18.5s\n",
            "121:\tlearn: 0.5095096\ttotal: 1.2s\tremaining: 18.5s\n",
            "122:\tlearn: 0.5094060\ttotal: 1.21s\tremaining: 18.5s\n",
            "123:\tlearn: 0.5092883\ttotal: 1.22s\tremaining: 18.5s\n",
            "124:\tlearn: 0.5091878\ttotal: 1.23s\tremaining: 18.5s\n",
            "125:\tlearn: 0.5090507\ttotal: 1.24s\tremaining: 18.5s\n",
            "126:\tlearn: 0.5089479\ttotal: 1.25s\tremaining: 18.5s\n",
            "127:\tlearn: 0.5088737\ttotal: 1.26s\tremaining: 18.4s\n",
            "128:\tlearn: 0.5087940\ttotal: 1.27s\tremaining: 18.4s\n",
            "129:\tlearn: 0.5087077\ttotal: 1.28s\tremaining: 18.4s\n",
            "130:\tlearn: 0.5086341\ttotal: 1.29s\tremaining: 18.4s\n",
            "131:\tlearn: 0.5085486\ttotal: 1.3s\tremaining: 18.4s\n",
            "132:\tlearn: 0.5084780\ttotal: 1.31s\tremaining: 18.4s\n",
            "133:\tlearn: 0.5084146\ttotal: 1.32s\tremaining: 18.4s\n",
            "134:\tlearn: 0.5083269\ttotal: 1.33s\tremaining: 18.4s\n",
            "135:\tlearn: 0.5082528\ttotal: 1.34s\tremaining: 18.4s\n",
            "136:\tlearn: 0.5081845\ttotal: 1.35s\tremaining: 18.4s\n",
            "137:\tlearn: 0.5081023\ttotal: 1.36s\tremaining: 18.4s\n",
            "138:\tlearn: 0.5080418\ttotal: 1.38s\tremaining: 18.4s\n",
            "139:\tlearn: 0.5079761\ttotal: 1.39s\tremaining: 18.4s\n",
            "140:\tlearn: 0.5079124\ttotal: 1.4s\tremaining: 18.4s\n",
            "141:\tlearn: 0.5078610\ttotal: 1.4s\tremaining: 18.4s\n",
            "142:\tlearn: 0.5077506\ttotal: 1.42s\tremaining: 18.4s\n",
            "143:\tlearn: 0.5076916\ttotal: 1.43s\tremaining: 18.4s\n",
            "144:\tlearn: 0.5076275\ttotal: 1.44s\tremaining: 18.4s\n",
            "145:\tlearn: 0.5075859\ttotal: 1.45s\tremaining: 18.4s\n",
            "146:\tlearn: 0.5074994\ttotal: 1.46s\tremaining: 18.4s\n",
            "147:\tlearn: 0.5074257\ttotal: 1.47s\tremaining: 18.3s\n",
            "148:\tlearn: 0.5073626\ttotal: 1.47s\tremaining: 18.3s\n",
            "149:\tlearn: 0.5073064\ttotal: 1.48s\tremaining: 18.3s\n",
            "150:\tlearn: 0.5072546\ttotal: 1.49s\tremaining: 18.3s\n",
            "151:\tlearn: 0.5071978\ttotal: 1.5s\tremaining: 18.2s\n",
            "152:\tlearn: 0.5071501\ttotal: 1.51s\tremaining: 18.2s\n",
            "153:\tlearn: 0.5070902\ttotal: 1.52s\tremaining: 18.2s\n",
            "154:\tlearn: 0.5070406\ttotal: 1.52s\tremaining: 18.2s\n",
            "155:\tlearn: 0.5070029\ttotal: 1.53s\tremaining: 18.1s\n",
            "156:\tlearn: 0.5069600\ttotal: 1.54s\tremaining: 18.1s\n",
            "157:\tlearn: 0.5069172\ttotal: 1.55s\tremaining: 18.1s\n",
            "158:\tlearn: 0.5068604\ttotal: 1.56s\tremaining: 18.1s\n",
            "159:\tlearn: 0.5068052\ttotal: 1.58s\tremaining: 18.1s\n",
            "160:\tlearn: 0.5067526\ttotal: 1.59s\tremaining: 18.2s\n",
            "161:\tlearn: 0.5067031\ttotal: 1.6s\tremaining: 18.2s\n",
            "162:\tlearn: 0.5066626\ttotal: 1.62s\tremaining: 18.3s\n",
            "163:\tlearn: 0.5066127\ttotal: 1.63s\tremaining: 18.3s\n",
            "164:\tlearn: 0.5065624\ttotal: 1.65s\tremaining: 18.3s\n",
            "165:\tlearn: 0.5065278\ttotal: 1.65s\tremaining: 18.3s\n",
            "166:\tlearn: 0.5064693\ttotal: 1.67s\tremaining: 18.3s\n",
            "167:\tlearn: 0.5064432\ttotal: 1.67s\tremaining: 18.3s\n",
            "168:\tlearn: 0.5064007\ttotal: 1.68s\tremaining: 18.2s\n",
            "169:\tlearn: 0.5063443\ttotal: 1.69s\tremaining: 18.2s\n",
            "170:\tlearn: 0.5063125\ttotal: 1.7s\tremaining: 18.2s\n",
            "171:\tlearn: 0.5062591\ttotal: 1.71s\tremaining: 18.2s\n",
            "172:\tlearn: 0.5062232\ttotal: 1.72s\tremaining: 18.2s\n",
            "173:\tlearn: 0.5061989\ttotal: 1.73s\tremaining: 18.2s\n",
            "174:\tlearn: 0.5061506\ttotal: 1.74s\tremaining: 18.1s\n",
            "175:\tlearn: 0.5060884\ttotal: 1.75s\tremaining: 18.1s\n",
            "176:\tlearn: 0.5060543\ttotal: 1.76s\tremaining: 18.1s\n",
            "177:\tlearn: 0.5060136\ttotal: 1.77s\tremaining: 18.1s\n",
            "178:\tlearn: 0.5059633\ttotal: 1.78s\tremaining: 18.1s\n",
            "179:\tlearn: 0.5059393\ttotal: 1.79s\tremaining: 18.1s\n",
            "180:\tlearn: 0.5058920\ttotal: 1.8s\tremaining: 18.1s\n",
            "181:\tlearn: 0.5058563\ttotal: 1.81s\tremaining: 18.1s\n",
            "182:\tlearn: 0.5058141\ttotal: 1.82s\tremaining: 18.1s\n",
            "183:\tlearn: 0.5057688\ttotal: 1.84s\tremaining: 18.1s\n",
            "184:\tlearn: 0.5057409\ttotal: 1.85s\tremaining: 18.2s\n",
            "185:\tlearn: 0.5056813\ttotal: 1.87s\tremaining: 18.2s\n",
            "186:\tlearn: 0.5056481\ttotal: 1.88s\tremaining: 18.2s\n",
            "187:\tlearn: 0.5056024\ttotal: 1.88s\tremaining: 18.2s\n",
            "188:\tlearn: 0.5055679\ttotal: 1.89s\tremaining: 18.2s\n",
            "189:\tlearn: 0.5055289\ttotal: 1.9s\tremaining: 18.1s\n",
            "190:\tlearn: 0.5054894\ttotal: 1.91s\tremaining: 18.1s\n",
            "191:\tlearn: 0.5054544\ttotal: 1.92s\tremaining: 18.1s\n",
            "192:\tlearn: 0.5054186\ttotal: 1.93s\tremaining: 18.1s\n",
            "193:\tlearn: 0.5053864\ttotal: 1.94s\tremaining: 18.1s\n",
            "194:\tlearn: 0.5053520\ttotal: 1.95s\tremaining: 18.1s\n",
            "195:\tlearn: 0.5053141\ttotal: 1.96s\tremaining: 18s\n",
            "196:\tlearn: 0.5052859\ttotal: 1.97s\tremaining: 18s\n",
            "197:\tlearn: 0.5052623\ttotal: 1.98s\tremaining: 18s\n",
            "198:\tlearn: 0.5052323\ttotal: 1.99s\tremaining: 18s\n",
            "199:\tlearn: 0.5051989\ttotal: 2s\tremaining: 18s\n",
            "200:\tlearn: 0.5051697\ttotal: 2.01s\tremaining: 18s\n",
            "201:\tlearn: 0.5051459\ttotal: 2.02s\tremaining: 17.9s\n",
            "202:\tlearn: 0.5051079\ttotal: 2.03s\tremaining: 18s\n",
            "203:\tlearn: 0.5050828\ttotal: 2.04s\tremaining: 18s\n",
            "204:\tlearn: 0.5050575\ttotal: 2.05s\tremaining: 18s\n",
            "205:\tlearn: 0.5050303\ttotal: 2.06s\tremaining: 17.9s\n",
            "206:\tlearn: 0.5049987\ttotal: 2.07s\tremaining: 17.9s\n",
            "207:\tlearn: 0.5049477\ttotal: 2.08s\tremaining: 17.9s\n",
            "208:\tlearn: 0.5049199\ttotal: 2.09s\tremaining: 17.9s\n",
            "209:\tlearn: 0.5049006\ttotal: 2.1s\tremaining: 17.9s\n",
            "210:\tlearn: 0.5048759\ttotal: 2.1s\tremaining: 17.9s\n",
            "211:\tlearn: 0.5048364\ttotal: 2.11s\tremaining: 17.8s\n",
            "212:\tlearn: 0.5047962\ttotal: 2.12s\tremaining: 17.8s\n",
            "213:\tlearn: 0.5047752\ttotal: 2.13s\tremaining: 17.8s\n",
            "214:\tlearn: 0.5047350\ttotal: 2.14s\tremaining: 17.8s\n",
            "215:\tlearn: 0.5046890\ttotal: 2.15s\tremaining: 17.7s\n",
            "216:\tlearn: 0.5046492\ttotal: 2.16s\tremaining: 17.7s\n",
            "217:\tlearn: 0.5046244\ttotal: 2.17s\tremaining: 17.7s\n",
            "218:\tlearn: 0.5045986\ttotal: 2.17s\tremaining: 17.7s\n",
            "219:\tlearn: 0.5045727\ttotal: 2.18s\tremaining: 17.7s\n",
            "220:\tlearn: 0.5045490\ttotal: 2.19s\tremaining: 17.7s\n",
            "221:\tlearn: 0.5045227\ttotal: 2.2s\tremaining: 17.6s\n",
            "222:\tlearn: 0.5045003\ttotal: 2.21s\tremaining: 17.6s\n",
            "223:\tlearn: 0.5044672\ttotal: 2.22s\tremaining: 17.6s\n",
            "224:\tlearn: 0.5044324\ttotal: 2.23s\tremaining: 17.6s\n",
            "225:\tlearn: 0.5043960\ttotal: 2.24s\tremaining: 17.6s\n",
            "226:\tlearn: 0.5043678\ttotal: 2.25s\tremaining: 17.6s\n",
            "227:\tlearn: 0.5043468\ttotal: 2.26s\tremaining: 17.6s\n",
            "228:\tlearn: 0.5043155\ttotal: 2.27s\tremaining: 17.6s\n",
            "229:\tlearn: 0.5042897\ttotal: 2.28s\tremaining: 17.5s\n",
            "230:\tlearn: 0.5042551\ttotal: 2.29s\tremaining: 17.5s\n",
            "231:\tlearn: 0.5042258\ttotal: 2.3s\tremaining: 17.5s\n",
            "232:\tlearn: 0.5041758\ttotal: 2.31s\tremaining: 17.5s\n",
            "233:\tlearn: 0.5041426\ttotal: 2.32s\tremaining: 17.5s\n",
            "234:\tlearn: 0.5040976\ttotal: 2.33s\tremaining: 17.5s\n",
            "235:\tlearn: 0.5040605\ttotal: 2.34s\tremaining: 17.5s\n",
            "236:\tlearn: 0.5040305\ttotal: 2.35s\tremaining: 17.5s\n",
            "237:\tlearn: 0.5040015\ttotal: 2.36s\tremaining: 17.5s\n",
            "238:\tlearn: 0.5039652\ttotal: 2.37s\tremaining: 17.5s\n",
            "239:\tlearn: 0.5039418\ttotal: 2.38s\tremaining: 17.5s\n",
            "240:\tlearn: 0.5039130\ttotal: 2.39s\tremaining: 17.4s\n",
            "241:\tlearn: 0.5038901\ttotal: 2.4s\tremaining: 17.4s\n",
            "242:\tlearn: 0.5038529\ttotal: 2.41s\tremaining: 17.4s\n",
            "243:\tlearn: 0.5038306\ttotal: 2.42s\tremaining: 17.4s\n",
            "244:\tlearn: 0.5038011\ttotal: 2.42s\tremaining: 17.4s\n",
            "245:\tlearn: 0.5037754\ttotal: 2.44s\tremaining: 17.4s\n",
            "246:\tlearn: 0.5037406\ttotal: 2.44s\tremaining: 17.4s\n",
            "247:\tlearn: 0.5037150\ttotal: 2.45s\tremaining: 17.3s\n",
            "248:\tlearn: 0.5036842\ttotal: 2.47s\tremaining: 17.4s\n",
            "249:\tlearn: 0.5036624\ttotal: 2.48s\tremaining: 17.4s\n",
            "250:\tlearn: 0.5036436\ttotal: 2.49s\tremaining: 17.3s\n",
            "251:\tlearn: 0.5036232\ttotal: 2.5s\tremaining: 17.3s\n",
            "252:\tlearn: 0.5035826\ttotal: 2.51s\tremaining: 17.3s\n",
            "253:\tlearn: 0.5035550\ttotal: 2.52s\tremaining: 17.3s\n",
            "254:\tlearn: 0.5035237\ttotal: 2.52s\tremaining: 17.3s\n",
            "255:\tlearn: 0.5034968\ttotal: 2.53s\tremaining: 17.3s\n",
            "256:\tlearn: 0.5034657\ttotal: 2.55s\tremaining: 17.3s\n",
            "257:\tlearn: 0.5034300\ttotal: 2.56s\tremaining: 17.3s\n",
            "258:\tlearn: 0.5034114\ttotal: 2.56s\tremaining: 17.2s\n",
            "259:\tlearn: 0.5033843\ttotal: 2.57s\tremaining: 17.2s\n",
            "260:\tlearn: 0.5033513\ttotal: 2.58s\tremaining: 17.2s\n",
            "261:\tlearn: 0.5033245\ttotal: 2.59s\tremaining: 17.2s\n",
            "262:\tlearn: 0.5032963\ttotal: 2.6s\tremaining: 17.2s\n",
            "263:\tlearn: 0.5032682\ttotal: 2.61s\tremaining: 17.2s\n",
            "264:\tlearn: 0.5032416\ttotal: 2.62s\tremaining: 17.2s\n",
            "265:\tlearn: 0.5032226\ttotal: 2.63s\tremaining: 17.1s\n",
            "266:\tlearn: 0.5031969\ttotal: 2.64s\tremaining: 17.2s\n",
            "267:\tlearn: 0.5031564\ttotal: 2.65s\tremaining: 17.1s\n",
            "268:\tlearn: 0.5031308\ttotal: 2.66s\tremaining: 17.1s\n",
            "269:\tlearn: 0.5030912\ttotal: 2.67s\tremaining: 17.1s\n",
            "270:\tlearn: 0.5030715\ttotal: 2.68s\tremaining: 17.1s\n",
            "271:\tlearn: 0.5030357\ttotal: 2.69s\tremaining: 17.1s\n",
            "272:\tlearn: 0.5030132\ttotal: 2.7s\tremaining: 17.1s\n",
            "273:\tlearn: 0.5029902\ttotal: 2.71s\tremaining: 17.1s\n",
            "274:\tlearn: 0.5029548\ttotal: 2.72s\tremaining: 17s\n",
            "275:\tlearn: 0.5029248\ttotal: 2.73s\tremaining: 17s\n",
            "276:\tlearn: 0.5028940\ttotal: 2.73s\tremaining: 17s\n",
            "277:\tlearn: 0.5028740\ttotal: 2.74s\tremaining: 17s\n",
            "278:\tlearn: 0.5028470\ttotal: 2.75s\tremaining: 17s\n",
            "279:\tlearn: 0.5028274\ttotal: 2.76s\tremaining: 17s\n",
            "280:\tlearn: 0.5028000\ttotal: 2.77s\tremaining: 16.9s\n",
            "281:\tlearn: 0.5027558\ttotal: 2.78s\tremaining: 16.9s\n",
            "282:\tlearn: 0.5027362\ttotal: 2.79s\tremaining: 16.9s\n",
            "283:\tlearn: 0.5027107\ttotal: 2.8s\tremaining: 16.9s\n",
            "284:\tlearn: 0.5026824\ttotal: 2.81s\tremaining: 16.9s\n",
            "285:\tlearn: 0.5026483\ttotal: 2.81s\tremaining: 16.9s\n",
            "286:\tlearn: 0.5026190\ttotal: 2.82s\tremaining: 16.8s\n",
            "287:\tlearn: 0.5026005\ttotal: 2.83s\tremaining: 16.8s\n",
            "288:\tlearn: 0.5025495\ttotal: 2.85s\tremaining: 16.8s\n",
            "289:\tlearn: 0.5025119\ttotal: 2.85s\tremaining: 16.8s\n",
            "290:\tlearn: 0.5024864\ttotal: 2.87s\tremaining: 16.8s\n",
            "291:\tlearn: 0.5024535\ttotal: 2.87s\tremaining: 16.8s\n",
            "292:\tlearn: 0.5024145\ttotal: 2.88s\tremaining: 16.8s\n",
            "293:\tlearn: 0.5023878\ttotal: 2.89s\tremaining: 16.8s\n",
            "294:\tlearn: 0.5023700\ttotal: 2.9s\tremaining: 16.8s\n",
            "295:\tlearn: 0.5023405\ttotal: 2.91s\tremaining: 16.8s\n",
            "296:\tlearn: 0.5023131\ttotal: 2.93s\tremaining: 16.8s\n",
            "297:\tlearn: 0.5022928\ttotal: 2.94s\tremaining: 16.8s\n",
            "298:\tlearn: 0.5022510\ttotal: 2.95s\tremaining: 16.8s\n",
            "299:\tlearn: 0.5022151\ttotal: 2.96s\tremaining: 16.8s\n",
            "300:\tlearn: 0.5021883\ttotal: 2.96s\tremaining: 16.7s\n",
            "301:\tlearn: 0.5021670\ttotal: 2.98s\tremaining: 16.7s\n",
            "302:\tlearn: 0.5021416\ttotal: 2.99s\tremaining: 16.7s\n",
            "303:\tlearn: 0.5021177\ttotal: 3s\tremaining: 16.7s\n",
            "304:\tlearn: 0.5020945\ttotal: 3s\tremaining: 16.7s\n",
            "305:\tlearn: 0.5020755\ttotal: 3.01s\tremaining: 16.7s\n",
            "306:\tlearn: 0.5020546\ttotal: 3.02s\tremaining: 16.7s\n",
            "307:\tlearn: 0.5020171\ttotal: 3.03s\tremaining: 16.7s\n",
            "308:\tlearn: 0.5019902\ttotal: 3.05s\tremaining: 16.7s\n",
            "309:\tlearn: 0.5019712\ttotal: 3.06s\tremaining: 16.7s\n",
            "310:\tlearn: 0.5019529\ttotal: 3.07s\tremaining: 16.7s\n",
            "311:\tlearn: 0.5019253\ttotal: 3.08s\tremaining: 16.6s\n",
            "312:\tlearn: 0.5018933\ttotal: 3.08s\tremaining: 16.6s\n",
            "313:\tlearn: 0.5018718\ttotal: 3.09s\tremaining: 16.6s\n",
            "314:\tlearn: 0.5018333\ttotal: 3.1s\tremaining: 16.6s\n",
            "315:\tlearn: 0.5018029\ttotal: 3.11s\tremaining: 16.6s\n",
            "316:\tlearn: 0.5017924\ttotal: 3.12s\tremaining: 16.6s\n",
            "317:\tlearn: 0.5017777\ttotal: 3.13s\tremaining: 16.6s\n",
            "318:\tlearn: 0.5017461\ttotal: 3.14s\tremaining: 16.6s\n",
            "319:\tlearn: 0.5017102\ttotal: 3.15s\tremaining: 16.5s\n",
            "320:\tlearn: 0.5016898\ttotal: 3.16s\tremaining: 16.5s\n",
            "321:\tlearn: 0.5016681\ttotal: 3.17s\tremaining: 16.5s\n",
            "322:\tlearn: 0.5016367\ttotal: 3.18s\tremaining: 16.5s\n",
            "323:\tlearn: 0.5016229\ttotal: 3.19s\tremaining: 16.5s\n",
            "324:\tlearn: 0.5015956\ttotal: 3.2s\tremaining: 16.5s\n",
            "325:\tlearn: 0.5015678\ttotal: 3.21s\tremaining: 16.5s\n",
            "326:\tlearn: 0.5015248\ttotal: 3.21s\tremaining: 16.5s\n",
            "327:\tlearn: 0.5014955\ttotal: 3.22s\tremaining: 16.4s\n",
            "328:\tlearn: 0.5014710\ttotal: 3.23s\tremaining: 16.4s\n",
            "329:\tlearn: 0.5014485\ttotal: 3.25s\tremaining: 16.4s\n",
            "330:\tlearn: 0.5014346\ttotal: 3.25s\tremaining: 16.4s\n",
            "331:\tlearn: 0.5014248\ttotal: 3.26s\tremaining: 16.4s\n",
            "332:\tlearn: 0.5013998\ttotal: 3.27s\tremaining: 16.4s\n",
            "333:\tlearn: 0.5013663\ttotal: 3.28s\tremaining: 16.4s\n",
            "334:\tlearn: 0.5013457\ttotal: 3.29s\tremaining: 16.3s\n",
            "335:\tlearn: 0.5013207\ttotal: 3.3s\tremaining: 16.3s\n",
            "336:\tlearn: 0.5012922\ttotal: 3.31s\tremaining: 16.3s\n",
            "337:\tlearn: 0.5012746\ttotal: 3.32s\tremaining: 16.3s\n",
            "338:\tlearn: 0.5012437\ttotal: 3.33s\tremaining: 16.3s\n",
            "339:\tlearn: 0.5012262\ttotal: 3.34s\tremaining: 16.3s\n",
            "340:\tlearn: 0.5011899\ttotal: 3.35s\tremaining: 16.3s\n",
            "341:\tlearn: 0.5011546\ttotal: 3.36s\tremaining: 16.3s\n",
            "342:\tlearn: 0.5011373\ttotal: 3.37s\tremaining: 16.3s\n",
            "343:\tlearn: 0.5011199\ttotal: 3.38s\tremaining: 16.3s\n",
            "344:\tlearn: 0.5010839\ttotal: 3.39s\tremaining: 16.3s\n",
            "345:\tlearn: 0.5010627\ttotal: 3.4s\tremaining: 16.2s\n",
            "346:\tlearn: 0.5010310\ttotal: 3.4s\tremaining: 16.2s\n",
            "347:\tlearn: 0.5010110\ttotal: 3.41s\tremaining: 16.2s\n",
            "348:\tlearn: 0.5009927\ttotal: 3.42s\tremaining: 16.2s\n",
            "349:\tlearn: 0.5009613\ttotal: 3.43s\tremaining: 16.2s\n",
            "350:\tlearn: 0.5009451\ttotal: 3.44s\tremaining: 16.2s\n",
            "351:\tlearn: 0.5009060\ttotal: 3.45s\tremaining: 16.2s\n",
            "352:\tlearn: 0.5008718\ttotal: 3.46s\tremaining: 16.2s\n",
            "353:\tlearn: 0.5008527\ttotal: 3.47s\tremaining: 16.1s\n",
            "354:\tlearn: 0.5008349\ttotal: 3.48s\tremaining: 16.1s\n",
            "355:\tlearn: 0.5008078\ttotal: 3.49s\tremaining: 16.1s\n",
            "356:\tlearn: 0.5007802\ttotal: 3.5s\tremaining: 16.1s\n",
            "357:\tlearn: 0.5007602\ttotal: 3.51s\tremaining: 16.1s\n",
            "358:\tlearn: 0.5007273\ttotal: 3.52s\tremaining: 16.1s\n",
            "359:\tlearn: 0.5007010\ttotal: 3.53s\tremaining: 16.1s\n",
            "360:\tlearn: 0.5006799\ttotal: 3.54s\tremaining: 16.1s\n",
            "361:\tlearn: 0.5006445\ttotal: 3.55s\tremaining: 16.1s\n",
            "362:\tlearn: 0.5006161\ttotal: 3.56s\tremaining: 16s\n",
            "363:\tlearn: 0.5005984\ttotal: 3.57s\tremaining: 16s\n",
            "364:\tlearn: 0.5005732\ttotal: 3.58s\tremaining: 16s\n",
            "365:\tlearn: 0.5005356\ttotal: 3.58s\tremaining: 16s\n",
            "366:\tlearn: 0.5005195\ttotal: 3.59s\tremaining: 16s\n",
            "367:\tlearn: 0.5005012\ttotal: 3.6s\tremaining: 16s\n",
            "368:\tlearn: 0.5004762\ttotal: 3.61s\tremaining: 16s\n",
            "369:\tlearn: 0.5004511\ttotal: 3.62s\tremaining: 16s\n",
            "370:\tlearn: 0.5004342\ttotal: 3.63s\tremaining: 15.9s\n",
            "371:\tlearn: 0.5004087\ttotal: 3.65s\tremaining: 16s\n",
            "372:\tlearn: 0.5003831\ttotal: 3.66s\tremaining: 15.9s\n",
            "373:\tlearn: 0.5003684\ttotal: 3.67s\tremaining: 15.9s\n",
            "374:\tlearn: 0.5003496\ttotal: 3.67s\tremaining: 15.9s\n",
            "375:\tlearn: 0.5003300\ttotal: 3.68s\tremaining: 15.9s\n",
            "376:\tlearn: 0.5003103\ttotal: 3.69s\tremaining: 15.9s\n",
            "377:\tlearn: 0.5002809\ttotal: 3.7s\tremaining: 15.9s\n",
            "378:\tlearn: 0.5002577\ttotal: 3.71s\tremaining: 15.9s\n",
            "379:\tlearn: 0.5002247\ttotal: 3.72s\tremaining: 15.9s\n",
            "380:\tlearn: 0.5001881\ttotal: 3.73s\tremaining: 15.8s\n",
            "381:\tlearn: 0.5001717\ttotal: 3.74s\tremaining: 15.8s\n",
            "382:\tlearn: 0.5001417\ttotal: 3.75s\tremaining: 15.8s\n",
            "383:\tlearn: 0.5001162\ttotal: 3.75s\tremaining: 15.8s\n",
            "384:\tlearn: 0.5000979\ttotal: 3.76s\tremaining: 15.8s\n",
            "385:\tlearn: 0.5000717\ttotal: 3.77s\tremaining: 15.8s\n",
            "386:\tlearn: 0.5000491\ttotal: 3.78s\tremaining: 15.8s\n",
            "387:\tlearn: 0.5000241\ttotal: 3.79s\tremaining: 15.7s\n",
            "388:\tlearn: 0.5000030\ttotal: 3.8s\tremaining: 15.7s\n",
            "389:\tlearn: 0.4999902\ttotal: 3.81s\tremaining: 15.7s\n",
            "390:\tlearn: 0.4999830\ttotal: 3.82s\tremaining: 15.7s\n",
            "391:\tlearn: 0.4999668\ttotal: 3.83s\tremaining: 15.7s\n",
            "392:\tlearn: 0.4999522\ttotal: 3.83s\tremaining: 15.7s\n",
            "393:\tlearn: 0.4999284\ttotal: 3.85s\tremaining: 15.7s\n",
            "394:\tlearn: 0.4999097\ttotal: 3.86s\tremaining: 15.7s\n",
            "395:\tlearn: 0.4998804\ttotal: 3.87s\tremaining: 15.7s\n",
            "396:\tlearn: 0.4998600\ttotal: 3.88s\tremaining: 15.7s\n",
            "397:\tlearn: 0.4998394\ttotal: 3.89s\tremaining: 15.6s\n",
            "398:\tlearn: 0.4998259\ttotal: 3.9s\tremaining: 15.6s\n",
            "399:\tlearn: 0.4998055\ttotal: 3.91s\tremaining: 15.6s\n",
            "400:\tlearn: 0.4997910\ttotal: 3.92s\tremaining: 15.6s\n",
            "401:\tlearn: 0.4997684\ttotal: 3.92s\tremaining: 15.6s\n",
            "402:\tlearn: 0.4997501\ttotal: 3.93s\tremaining: 15.6s\n",
            "403:\tlearn: 0.4997280\ttotal: 3.94s\tremaining: 15.6s\n",
            "404:\tlearn: 0.4996834\ttotal: 3.95s\tremaining: 15.6s\n",
            "405:\tlearn: 0.4996640\ttotal: 3.96s\tremaining: 15.5s\n",
            "406:\tlearn: 0.4996334\ttotal: 3.97s\tremaining: 15.5s\n",
            "407:\tlearn: 0.4996048\ttotal: 3.98s\tremaining: 15.5s\n",
            "408:\tlearn: 0.4995787\ttotal: 4s\tremaining: 15.5s\n",
            "409:\tlearn: 0.4995664\ttotal: 4s\tremaining: 15.5s\n",
            "410:\tlearn: 0.4995524\ttotal: 4.01s\tremaining: 15.5s\n",
            "411:\tlearn: 0.4995334\ttotal: 4.02s\tremaining: 15.5s\n",
            "412:\tlearn: 0.4995159\ttotal: 4.03s\tremaining: 15.5s\n",
            "413:\tlearn: 0.4994905\ttotal: 4.04s\tremaining: 15.5s\n",
            "414:\tlearn: 0.4994676\ttotal: 4.06s\tremaining: 15.5s\n",
            "415:\tlearn: 0.4994456\ttotal: 4.07s\tremaining: 15.5s\n",
            "416:\tlearn: 0.4994228\ttotal: 4.08s\tremaining: 15.5s\n",
            "417:\tlearn: 0.4993955\ttotal: 4.08s\tremaining: 15.5s\n",
            "418:\tlearn: 0.4993611\ttotal: 4.09s\tremaining: 15.4s\n",
            "419:\tlearn: 0.4993443\ttotal: 4.1s\tremaining: 15.4s\n",
            "420:\tlearn: 0.4993222\ttotal: 4.12s\tremaining: 15.4s\n",
            "421:\tlearn: 0.4993009\ttotal: 4.13s\tremaining: 15.4s\n",
            "422:\tlearn: 0.4992837\ttotal: 4.14s\tremaining: 15.4s\n",
            "423:\tlearn: 0.4992599\ttotal: 4.15s\tremaining: 15.4s\n",
            "424:\tlearn: 0.4992353\ttotal: 4.16s\tremaining: 15.4s\n",
            "425:\tlearn: 0.4992142\ttotal: 4.17s\tremaining: 15.4s\n",
            "426:\tlearn: 0.4991994\ttotal: 4.18s\tremaining: 15.4s\n",
            "427:\tlearn: 0.4991808\ttotal: 4.18s\tremaining: 15.4s\n",
            "428:\tlearn: 0.4991502\ttotal: 4.2s\tremaining: 15.4s\n",
            "429:\tlearn: 0.4991338\ttotal: 4.21s\tremaining: 15.4s\n",
            "430:\tlearn: 0.4991202\ttotal: 4.22s\tremaining: 15.3s\n",
            "431:\tlearn: 0.4991064\ttotal: 4.22s\tremaining: 15.3s\n",
            "432:\tlearn: 0.4990823\ttotal: 4.23s\tremaining: 15.3s\n",
            "433:\tlearn: 0.4990596\ttotal: 4.24s\tremaining: 15.3s\n",
            "434:\tlearn: 0.4990322\ttotal: 4.25s\tremaining: 15.3s\n",
            "435:\tlearn: 0.4990062\ttotal: 4.27s\tremaining: 15.3s\n",
            "436:\tlearn: 0.4989836\ttotal: 4.28s\tremaining: 15.3s\n",
            "437:\tlearn: 0.4989688\ttotal: 4.29s\tremaining: 15.3s\n",
            "438:\tlearn: 0.4989507\ttotal: 4.3s\tremaining: 15.3s\n",
            "439:\tlearn: 0.4989314\ttotal: 4.32s\tremaining: 15.3s\n",
            "440:\tlearn: 0.4989122\ttotal: 4.33s\tremaining: 15.3s\n",
            "441:\tlearn: 0.4989038\ttotal: 4.34s\tremaining: 15.3s\n",
            "442:\tlearn: 0.4988808\ttotal: 4.35s\tremaining: 15.3s\n",
            "443:\tlearn: 0.4988640\ttotal: 4.36s\tremaining: 15.3s\n",
            "444:\tlearn: 0.4988463\ttotal: 4.37s\tremaining: 15.3s\n",
            "445:\tlearn: 0.4988216\ttotal: 4.38s\tremaining: 15.3s\n",
            "446:\tlearn: 0.4988024\ttotal: 4.38s\tremaining: 15.2s\n",
            "447:\tlearn: 0.4987804\ttotal: 4.4s\tremaining: 15.2s\n",
            "448:\tlearn: 0.4987683\ttotal: 4.41s\tremaining: 15.2s\n",
            "449:\tlearn: 0.4987473\ttotal: 4.42s\tremaining: 15.2s\n",
            "450:\tlearn: 0.4987271\ttotal: 4.43s\tremaining: 15.2s\n",
            "451:\tlearn: 0.4987011\ttotal: 4.44s\tremaining: 15.2s\n",
            "452:\tlearn: 0.4986800\ttotal: 4.45s\tremaining: 15.2s\n",
            "453:\tlearn: 0.4986562\ttotal: 4.46s\tremaining: 15.2s\n",
            "454:\tlearn: 0.4986354\ttotal: 4.47s\tremaining: 15.2s\n",
            "455:\tlearn: 0.4986053\ttotal: 4.48s\tremaining: 15.2s\n",
            "456:\tlearn: 0.4985847\ttotal: 4.49s\tremaining: 15.2s\n",
            "457:\tlearn: 0.4985661\ttotal: 4.5s\tremaining: 15.1s\n",
            "458:\tlearn: 0.4985480\ttotal: 4.51s\tremaining: 15.1s\n",
            "459:\tlearn: 0.4985166\ttotal: 4.51s\tremaining: 15.1s\n",
            "460:\tlearn: 0.4984934\ttotal: 4.52s\tremaining: 15.1s\n",
            "461:\tlearn: 0.4984712\ttotal: 4.53s\tremaining: 15.1s\n",
            "462:\tlearn: 0.4984547\ttotal: 4.54s\tremaining: 15.1s\n",
            "463:\tlearn: 0.4984378\ttotal: 4.55s\tremaining: 15.1s\n",
            "464:\tlearn: 0.4984131\ttotal: 4.56s\tremaining: 15.1s\n",
            "465:\tlearn: 0.4983917\ttotal: 4.57s\tremaining: 15.1s\n",
            "466:\tlearn: 0.4983679\ttotal: 4.58s\tremaining: 15s\n",
            "467:\tlearn: 0.4983426\ttotal: 4.59s\tremaining: 15s\n",
            "468:\tlearn: 0.4983241\ttotal: 4.6s\tremaining: 15s\n",
            "469:\tlearn: 0.4983021\ttotal: 4.61s\tremaining: 15s\n",
            "470:\tlearn: 0.4982933\ttotal: 4.62s\tremaining: 15s\n",
            "471:\tlearn: 0.4982761\ttotal: 4.63s\tremaining: 15s\n",
            "472:\tlearn: 0.4982532\ttotal: 4.64s\tremaining: 15s\n",
            "473:\tlearn: 0.4982287\ttotal: 4.65s\tremaining: 15s\n",
            "474:\tlearn: 0.4982076\ttotal: 4.67s\tremaining: 15s\n",
            "475:\tlearn: 0.4981866\ttotal: 4.67s\tremaining: 15s\n",
            "476:\tlearn: 0.4981721\ttotal: 4.68s\tremaining: 15s\n",
            "477:\tlearn: 0.4981538\ttotal: 4.7s\tremaining: 15s\n",
            "478:\tlearn: 0.4981369\ttotal: 4.71s\tremaining: 14.9s\n",
            "479:\tlearn: 0.4981196\ttotal: 4.72s\tremaining: 14.9s\n",
            "480:\tlearn: 0.4980983\ttotal: 4.73s\tremaining: 14.9s\n",
            "481:\tlearn: 0.4980779\ttotal: 4.74s\tremaining: 14.9s\n",
            "482:\tlearn: 0.4980488\ttotal: 4.74s\tremaining: 14.9s\n",
            "483:\tlearn: 0.4980263\ttotal: 4.76s\tremaining: 14.9s\n",
            "484:\tlearn: 0.4980027\ttotal: 4.77s\tremaining: 14.9s\n",
            "485:\tlearn: 0.4979927\ttotal: 4.78s\tremaining: 14.9s\n",
            "486:\tlearn: 0.4979713\ttotal: 4.78s\tremaining: 14.9s\n",
            "487:\tlearn: 0.4979564\ttotal: 4.79s\tremaining: 14.8s\n",
            "488:\tlearn: 0.4979197\ttotal: 4.8s\tremaining: 14.8s\n",
            "489:\tlearn: 0.4979041\ttotal: 4.81s\tremaining: 14.8s\n",
            "490:\tlearn: 0.4978816\ttotal: 4.82s\tremaining: 14.8s\n",
            "491:\tlearn: 0.4978447\ttotal: 4.83s\tremaining: 14.8s\n",
            "492:\tlearn: 0.4978155\ttotal: 4.84s\tremaining: 14.8s\n",
            "493:\tlearn: 0.4977945\ttotal: 4.86s\tremaining: 14.8s\n",
            "494:\tlearn: 0.4977597\ttotal: 4.87s\tremaining: 14.8s\n",
            "495:\tlearn: 0.4977403\ttotal: 4.88s\tremaining: 14.8s\n",
            "496:\tlearn: 0.4977212\ttotal: 4.89s\tremaining: 14.8s\n",
            "497:\tlearn: 0.4976956\ttotal: 4.89s\tremaining: 14.8s\n",
            "498:\tlearn: 0.4976724\ttotal: 4.9s\tremaining: 14.8s\n",
            "499:\tlearn: 0.4976531\ttotal: 4.91s\tremaining: 14.7s\n",
            "500:\tlearn: 0.4976300\ttotal: 4.92s\tremaining: 14.7s\n",
            "501:\tlearn: 0.4975930\ttotal: 4.93s\tremaining: 14.7s\n",
            "502:\tlearn: 0.4975715\ttotal: 4.94s\tremaining: 14.7s\n",
            "503:\tlearn: 0.4975525\ttotal: 4.95s\tremaining: 14.7s\n",
            "504:\tlearn: 0.4975330\ttotal: 4.96s\tremaining: 14.7s\n",
            "505:\tlearn: 0.4975087\ttotal: 4.97s\tremaining: 14.7s\n",
            "506:\tlearn: 0.4974879\ttotal: 4.98s\tremaining: 14.7s\n",
            "507:\tlearn: 0.4974748\ttotal: 4.99s\tremaining: 14.6s\n",
            "508:\tlearn: 0.4974545\ttotal: 5s\tremaining: 14.6s\n",
            "509:\tlearn: 0.4974308\ttotal: 5s\tremaining: 14.6s\n",
            "510:\tlearn: 0.4974102\ttotal: 5.02s\tremaining: 14.6s\n",
            "511:\tlearn: 0.4973655\ttotal: 5.03s\tremaining: 14.6s\n",
            "512:\tlearn: 0.4973480\ttotal: 5.04s\tremaining: 14.6s\n",
            "513:\tlearn: 0.4973237\ttotal: 5.05s\tremaining: 14.6s\n",
            "514:\tlearn: 0.4972915\ttotal: 5.05s\tremaining: 14.6s\n",
            "515:\tlearn: 0.4972701\ttotal: 5.07s\tremaining: 14.6s\n",
            "516:\tlearn: 0.4972433\ttotal: 5.08s\tremaining: 14.6s\n",
            "517:\tlearn: 0.4972228\ttotal: 5.09s\tremaining: 14.6s\n",
            "518:\tlearn: 0.4971917\ttotal: 5.1s\tremaining: 14.5s\n",
            "519:\tlearn: 0.4971750\ttotal: 5.11s\tremaining: 14.5s\n",
            "520:\tlearn: 0.4971490\ttotal: 5.12s\tremaining: 14.5s\n",
            "521:\tlearn: 0.4971316\ttotal: 5.13s\tremaining: 14.5s\n",
            "522:\tlearn: 0.4971152\ttotal: 5.14s\tremaining: 14.5s\n",
            "523:\tlearn: 0.4970886\ttotal: 5.15s\tremaining: 14.5s\n",
            "524:\tlearn: 0.4970698\ttotal: 5.16s\tremaining: 14.5s\n",
            "525:\tlearn: 0.4970294\ttotal: 5.17s\tremaining: 14.5s\n",
            "526:\tlearn: 0.4970140\ttotal: 5.18s\tremaining: 14.5s\n",
            "527:\tlearn: 0.4969766\ttotal: 5.19s\tremaining: 14.5s\n",
            "528:\tlearn: 0.4969513\ttotal: 5.2s\tremaining: 14.5s\n",
            "529:\tlearn: 0.4969114\ttotal: 5.21s\tremaining: 14.4s\n",
            "530:\tlearn: 0.4968885\ttotal: 5.22s\tremaining: 14.4s\n",
            "531:\tlearn: 0.4968587\ttotal: 5.23s\tremaining: 14.4s\n",
            "532:\tlearn: 0.4968460\ttotal: 5.24s\tremaining: 14.4s\n",
            "533:\tlearn: 0.4968216\ttotal: 5.25s\tremaining: 14.4s\n",
            "534:\tlearn: 0.4967941\ttotal: 5.26s\tremaining: 14.4s\n",
            "535:\tlearn: 0.4967595\ttotal: 5.28s\tremaining: 14.4s\n",
            "536:\tlearn: 0.4967325\ttotal: 5.3s\tremaining: 14.4s\n",
            "537:\tlearn: 0.4967063\ttotal: 5.31s\tremaining: 14.4s\n",
            "538:\tlearn: 0.4966834\ttotal: 5.32s\tremaining: 14.4s\n",
            "539:\tlearn: 0.4966635\ttotal: 5.33s\tremaining: 14.4s\n",
            "540:\tlearn: 0.4966311\ttotal: 5.34s\tremaining: 14.4s\n",
            "541:\tlearn: 0.4966021\ttotal: 5.35s\tremaining: 14.4s\n",
            "542:\tlearn: 0.4965635\ttotal: 5.36s\tremaining: 14.4s\n",
            "543:\tlearn: 0.4965340\ttotal: 5.37s\tremaining: 14.4s\n",
            "544:\tlearn: 0.4965064\ttotal: 5.38s\tremaining: 14.4s\n",
            "545:\tlearn: 0.4964814\ttotal: 5.39s\tremaining: 14.3s\n",
            "546:\tlearn: 0.4964808\ttotal: 5.39s\tremaining: 14.3s\n",
            "547:\tlearn: 0.4964655\ttotal: 5.4s\tremaining: 14.3s\n",
            "548:\tlearn: 0.4964429\ttotal: 5.41s\tremaining: 14.3s\n",
            "549:\tlearn: 0.4964265\ttotal: 5.42s\tremaining: 14.3s\n",
            "550:\tlearn: 0.4964098\ttotal: 5.43s\tremaining: 14.3s\n",
            "551:\tlearn: 0.4963840\ttotal: 5.44s\tremaining: 14.3s\n",
            "552:\tlearn: 0.4963519\ttotal: 5.45s\tremaining: 14.3s\n",
            "553:\tlearn: 0.4963145\ttotal: 5.46s\tremaining: 14.2s\n",
            "554:\tlearn: 0.4962772\ttotal: 5.47s\tremaining: 14.2s\n",
            "555:\tlearn: 0.4962334\ttotal: 5.48s\tremaining: 14.2s\n",
            "556:\tlearn: 0.4961985\ttotal: 5.49s\tremaining: 14.2s\n",
            "557:\tlearn: 0.4961720\ttotal: 5.5s\tremaining: 14.2s\n",
            "558:\tlearn: 0.4961470\ttotal: 5.51s\tremaining: 14.2s\n",
            "559:\tlearn: 0.4961170\ttotal: 5.53s\tremaining: 14.2s\n",
            "560:\tlearn: 0.4960735\ttotal: 5.54s\tremaining: 14.2s\n",
            "561:\tlearn: 0.4960500\ttotal: 5.54s\tremaining: 14.2s\n",
            "562:\tlearn: 0.4960118\ttotal: 5.55s\tremaining: 14.2s\n",
            "563:\tlearn: 0.4959947\ttotal: 5.56s\tremaining: 14.2s\n",
            "564:\tlearn: 0.4959620\ttotal: 5.57s\tremaining: 14.2s\n",
            "565:\tlearn: 0.4959324\ttotal: 5.58s\tremaining: 14.1s\n",
            "566:\tlearn: 0.4959061\ttotal: 5.59s\tremaining: 14.1s\n",
            "567:\tlearn: 0.4958752\ttotal: 5.6s\tremaining: 14.1s\n",
            "568:\tlearn: 0.4958491\ttotal: 5.61s\tremaining: 14.1s\n",
            "569:\tlearn: 0.4958242\ttotal: 5.62s\tremaining: 14.1s\n",
            "570:\tlearn: 0.4958043\ttotal: 5.63s\tremaining: 14.1s\n",
            "571:\tlearn: 0.4957682\ttotal: 5.64s\tremaining: 14.1s\n",
            "572:\tlearn: 0.4957365\ttotal: 5.64s\tremaining: 14.1s\n",
            "573:\tlearn: 0.4957061\ttotal: 5.65s\tremaining: 14s\n",
            "574:\tlearn: 0.4956779\ttotal: 5.66s\tremaining: 14s\n",
            "575:\tlearn: 0.4956586\ttotal: 5.67s\tremaining: 14s\n",
            "576:\tlearn: 0.4956286\ttotal: 5.69s\tremaining: 14s\n",
            "577:\tlearn: 0.4955928\ttotal: 5.7s\tremaining: 14s\n",
            "578:\tlearn: 0.4955612\ttotal: 5.71s\tremaining: 14s\n",
            "579:\tlearn: 0.4955294\ttotal: 5.72s\tremaining: 14s\n",
            "580:\tlearn: 0.4954989\ttotal: 5.73s\tremaining: 14s\n",
            "581:\tlearn: 0.4954647\ttotal: 5.74s\tremaining: 14s\n",
            "582:\tlearn: 0.4954491\ttotal: 5.75s\tremaining: 14s\n",
            "583:\tlearn: 0.4954332\ttotal: 5.76s\tremaining: 14s\n",
            "584:\tlearn: 0.4954013\ttotal: 5.77s\tremaining: 13.9s\n",
            "585:\tlearn: 0.4953902\ttotal: 5.77s\tremaining: 13.9s\n",
            "586:\tlearn: 0.4953543\ttotal: 5.78s\tremaining: 13.9s\n",
            "587:\tlearn: 0.4953363\ttotal: 5.79s\tremaining: 13.9s\n",
            "588:\tlearn: 0.4952928\ttotal: 5.8s\tremaining: 13.9s\n",
            "589:\tlearn: 0.4952696\ttotal: 5.81s\tremaining: 13.9s\n",
            "590:\tlearn: 0.4952498\ttotal: 5.82s\tremaining: 13.9s\n",
            "591:\tlearn: 0.4952242\ttotal: 5.83s\tremaining: 13.9s\n",
            "592:\tlearn: 0.4951926\ttotal: 5.84s\tremaining: 13.9s\n",
            "593:\tlearn: 0.4951501\ttotal: 5.85s\tremaining: 13.8s\n",
            "594:\tlearn: 0.4951243\ttotal: 5.86s\tremaining: 13.8s\n",
            "595:\tlearn: 0.4950965\ttotal: 5.87s\tremaining: 13.8s\n",
            "596:\tlearn: 0.4950704\ttotal: 5.88s\tremaining: 13.8s\n",
            "597:\tlearn: 0.4950368\ttotal: 5.89s\tremaining: 13.8s\n",
            "598:\tlearn: 0.4949997\ttotal: 5.91s\tremaining: 13.8s\n",
            "599:\tlearn: 0.4949724\ttotal: 5.92s\tremaining: 13.8s\n",
            "600:\tlearn: 0.4949270\ttotal: 5.93s\tremaining: 13.8s\n",
            "601:\tlearn: 0.4948979\ttotal: 5.94s\tremaining: 13.8s\n",
            "602:\tlearn: 0.4948707\ttotal: 5.96s\tremaining: 13.8s\n",
            "603:\tlearn: 0.4948447\ttotal: 5.97s\tremaining: 13.8s\n",
            "604:\tlearn: 0.4948141\ttotal: 5.98s\tremaining: 13.8s\n",
            "605:\tlearn: 0.4947768\ttotal: 5.99s\tremaining: 13.8s\n",
            "606:\tlearn: 0.4947386\ttotal: 6s\tremaining: 13.8s\n",
            "607:\tlearn: 0.4947066\ttotal: 6.01s\tremaining: 13.8s\n",
            "608:\tlearn: 0.4946718\ttotal: 6.02s\tremaining: 13.7s\n",
            "609:\tlearn: 0.4946294\ttotal: 6.03s\tremaining: 13.7s\n",
            "610:\tlearn: 0.4946030\ttotal: 6.04s\tremaining: 13.7s\n",
            "611:\tlearn: 0.4945760\ttotal: 6.04s\tremaining: 13.7s\n",
            "612:\tlearn: 0.4945335\ttotal: 6.05s\tremaining: 13.7s\n",
            "613:\tlearn: 0.4945037\ttotal: 6.06s\tremaining: 13.7s\n",
            "614:\tlearn: 0.4944821\ttotal: 6.08s\tremaining: 13.7s\n",
            "615:\tlearn: 0.4944559\ttotal: 6.09s\tremaining: 13.7s\n",
            "616:\tlearn: 0.4944319\ttotal: 6.1s\tremaining: 13.7s\n",
            "617:\tlearn: 0.4943911\ttotal: 6.11s\tremaining: 13.7s\n",
            "618:\tlearn: 0.4943553\ttotal: 6.12s\tremaining: 13.7s\n",
            "619:\tlearn: 0.4943018\ttotal: 6.13s\tremaining: 13.7s\n",
            "620:\tlearn: 0.4942735\ttotal: 6.14s\tremaining: 13.6s\n",
            "621:\tlearn: 0.4942330\ttotal: 6.16s\tremaining: 13.6s\n",
            "622:\tlearn: 0.4941968\ttotal: 6.17s\tremaining: 13.6s\n",
            "623:\tlearn: 0.4941823\ttotal: 6.18s\tremaining: 13.6s\n",
            "624:\tlearn: 0.4941507\ttotal: 6.19s\tremaining: 13.6s\n",
            "625:\tlearn: 0.4941099\ttotal: 6.2s\tremaining: 13.6s\n",
            "626:\tlearn: 0.4940724\ttotal: 6.21s\tremaining: 13.6s\n",
            "627:\tlearn: 0.4940366\ttotal: 6.22s\tremaining: 13.6s\n",
            "628:\tlearn: 0.4939883\ttotal: 6.22s\tremaining: 13.6s\n",
            "629:\tlearn: 0.4939628\ttotal: 6.23s\tremaining: 13.6s\n",
            "630:\tlearn: 0.4939376\ttotal: 6.24s\tremaining: 13.5s\n",
            "631:\tlearn: 0.4939051\ttotal: 6.26s\tremaining: 13.5s\n",
            "632:\tlearn: 0.4938570\ttotal: 6.26s\tremaining: 13.5s\n",
            "633:\tlearn: 0.4938290\ttotal: 6.28s\tremaining: 13.5s\n",
            "634:\tlearn: 0.4937924\ttotal: 6.29s\tremaining: 13.5s\n",
            "635:\tlearn: 0.4937593\ttotal: 6.31s\tremaining: 13.5s\n",
            "636:\tlearn: 0.4937270\ttotal: 6.32s\tremaining: 13.5s\n",
            "637:\tlearn: 0.4936994\ttotal: 6.33s\tremaining: 13.5s\n",
            "638:\tlearn: 0.4936533\ttotal: 6.34s\tremaining: 13.5s\n",
            "639:\tlearn: 0.4936330\ttotal: 6.35s\tremaining: 13.5s\n",
            "640:\tlearn: 0.4936081\ttotal: 6.36s\tremaining: 13.5s\n",
            "641:\tlearn: 0.4935650\ttotal: 6.37s\tremaining: 13.5s\n",
            "642:\tlearn: 0.4935079\ttotal: 6.38s\tremaining: 13.5s\n",
            "643:\tlearn: 0.4934798\ttotal: 6.39s\tremaining: 13.5s\n",
            "644:\tlearn: 0.4934373\ttotal: 6.4s\tremaining: 13.5s\n",
            "645:\tlearn: 0.4933976\ttotal: 6.41s\tremaining: 13.4s\n",
            "646:\tlearn: 0.4933705\ttotal: 6.42s\tremaining: 13.4s\n",
            "647:\tlearn: 0.4933220\ttotal: 6.43s\tremaining: 13.4s\n",
            "648:\tlearn: 0.4932980\ttotal: 6.44s\tremaining: 13.4s\n",
            "649:\tlearn: 0.4932598\ttotal: 6.45s\tremaining: 13.4s\n",
            "650:\tlearn: 0.4932281\ttotal: 6.46s\tremaining: 13.4s\n",
            "651:\tlearn: 0.4931762\ttotal: 6.49s\tremaining: 13.4s\n",
            "652:\tlearn: 0.4931355\ttotal: 6.5s\tremaining: 13.4s\n",
            "653:\tlearn: 0.4930998\ttotal: 6.51s\tremaining: 13.4s\n",
            "654:\tlearn: 0.4930745\ttotal: 6.52s\tremaining: 13.4s\n",
            "655:\tlearn: 0.4930382\ttotal: 6.54s\tremaining: 13.4s\n",
            "656:\tlearn: 0.4930011\ttotal: 6.54s\tremaining: 13.4s\n",
            "657:\tlearn: 0.4929533\ttotal: 6.56s\tremaining: 13.4s\n",
            "658:\tlearn: 0.4929176\ttotal: 6.57s\tremaining: 13.4s\n",
            "659:\tlearn: 0.4928670\ttotal: 6.58s\tremaining: 13.4s\n",
            "660:\tlearn: 0.4928257\ttotal: 6.59s\tremaining: 13.3s\n",
            "661:\tlearn: 0.4928054\ttotal: 6.6s\tremaining: 13.3s\n",
            "662:\tlearn: 0.4927760\ttotal: 6.61s\tremaining: 13.3s\n",
            "663:\tlearn: 0.4927451\ttotal: 6.62s\tremaining: 13.3s\n",
            "664:\tlearn: 0.4927035\ttotal: 6.63s\tremaining: 13.3s\n",
            "665:\tlearn: 0.4926709\ttotal: 6.63s\tremaining: 13.3s\n",
            "666:\tlearn: 0.4926219\ttotal: 6.64s\tremaining: 13.3s\n",
            "667:\tlearn: 0.4925738\ttotal: 6.66s\tremaining: 13.3s\n",
            "668:\tlearn: 0.4925324\ttotal: 6.67s\tremaining: 13.3s\n",
            "669:\tlearn: 0.4924979\ttotal: 6.67s\tremaining: 13.3s\n",
            "670:\tlearn: 0.4924584\ttotal: 6.68s\tremaining: 13.2s\n",
            "671:\tlearn: 0.4924346\ttotal: 6.69s\tremaining: 13.2s\n",
            "672:\tlearn: 0.4923804\ttotal: 6.7s\tremaining: 13.2s\n",
            "673:\tlearn: 0.4923421\ttotal: 6.72s\tremaining: 13.2s\n",
            "674:\tlearn: 0.4923164\ttotal: 6.73s\tremaining: 13.2s\n",
            "675:\tlearn: 0.4922877\ttotal: 6.74s\tremaining: 13.2s\n",
            "676:\tlearn: 0.4922413\ttotal: 6.75s\tremaining: 13.2s\n",
            "677:\tlearn: 0.4922094\ttotal: 6.76s\tremaining: 13.2s\n",
            "678:\tlearn: 0.4921791\ttotal: 6.76s\tremaining: 13.2s\n",
            "679:\tlearn: 0.4921486\ttotal: 6.78s\tremaining: 13.2s\n",
            "680:\tlearn: 0.4921087\ttotal: 6.79s\tremaining: 13.1s\n",
            "681:\tlearn: 0.4920736\ttotal: 6.8s\tremaining: 13.1s\n",
            "682:\tlearn: 0.4920509\ttotal: 6.81s\tremaining: 13.1s\n",
            "683:\tlearn: 0.4920125\ttotal: 6.82s\tremaining: 13.1s\n",
            "684:\tlearn: 0.4919697\ttotal: 6.83s\tremaining: 13.1s\n",
            "685:\tlearn: 0.4919375\ttotal: 6.84s\tremaining: 13.1s\n",
            "686:\tlearn: 0.4918937\ttotal: 6.85s\tremaining: 13.1s\n",
            "687:\tlearn: 0.4918679\ttotal: 6.86s\tremaining: 13.1s\n",
            "688:\tlearn: 0.4918265\ttotal: 6.87s\tremaining: 13.1s\n",
            "689:\tlearn: 0.4917896\ttotal: 6.87s\tremaining: 13.1s\n",
            "690:\tlearn: 0.4917476\ttotal: 6.88s\tremaining: 13s\n",
            "691:\tlearn: 0.4916983\ttotal: 6.89s\tremaining: 13s\n",
            "692:\tlearn: 0.4916637\ttotal: 6.9s\tremaining: 13s\n",
            "693:\tlearn: 0.4916221\ttotal: 6.91s\tremaining: 13s\n",
            "694:\tlearn: 0.4915997\ttotal: 6.93s\tremaining: 13s\n",
            "695:\tlearn: 0.4915576\ttotal: 6.93s\tremaining: 13s\n",
            "696:\tlearn: 0.4915202\ttotal: 6.94s\tremaining: 13s\n",
            "697:\tlearn: 0.4915012\ttotal: 6.95s\tremaining: 13s\n",
            "698:\tlearn: 0.4914768\ttotal: 6.96s\tremaining: 13s\n",
            "699:\tlearn: 0.4914407\ttotal: 6.97s\tremaining: 12.9s\n",
            "700:\tlearn: 0.4914067\ttotal: 6.98s\tremaining: 12.9s\n",
            "701:\tlearn: 0.4913600\ttotal: 6.99s\tremaining: 12.9s\n",
            "702:\tlearn: 0.4913074\ttotal: 7s\tremaining: 12.9s\n",
            "703:\tlearn: 0.4912566\ttotal: 7.01s\tremaining: 12.9s\n",
            "704:\tlearn: 0.4912192\ttotal: 7.03s\tremaining: 12.9s\n",
            "705:\tlearn: 0.4911792\ttotal: 7.04s\tremaining: 12.9s\n",
            "706:\tlearn: 0.4911450\ttotal: 7.05s\tremaining: 12.9s\n",
            "707:\tlearn: 0.4911087\ttotal: 7.06s\tremaining: 12.9s\n",
            "708:\tlearn: 0.4910825\ttotal: 7.07s\tremaining: 12.9s\n",
            "709:\tlearn: 0.4910570\ttotal: 7.09s\tremaining: 12.9s\n",
            "710:\tlearn: 0.4910176\ttotal: 7.09s\tremaining: 12.9s\n",
            "711:\tlearn: 0.4909754\ttotal: 7.1s\tremaining: 12.9s\n",
            "712:\tlearn: 0.4909349\ttotal: 7.11s\tremaining: 12.8s\n",
            "713:\tlearn: 0.4909080\ttotal: 7.13s\tremaining: 12.8s\n",
            "714:\tlearn: 0.4908711\ttotal: 7.14s\tremaining: 12.8s\n",
            "715:\tlearn: 0.4908304\ttotal: 7.15s\tremaining: 12.8s\n",
            "716:\tlearn: 0.4907883\ttotal: 7.16s\tremaining: 12.8s\n",
            "717:\tlearn: 0.4907415\ttotal: 7.17s\tremaining: 12.8s\n",
            "718:\tlearn: 0.4907173\ttotal: 7.18s\tremaining: 12.8s\n",
            "719:\tlearn: 0.4906810\ttotal: 7.19s\tremaining: 12.8s\n",
            "720:\tlearn: 0.4906502\ttotal: 7.2s\tremaining: 12.8s\n",
            "721:\tlearn: 0.4906150\ttotal: 7.21s\tremaining: 12.8s\n",
            "722:\tlearn: 0.4905700\ttotal: 7.21s\tremaining: 12.7s\n",
            "723:\tlearn: 0.4905274\ttotal: 7.22s\tremaining: 12.7s\n",
            "724:\tlearn: 0.4904869\ttotal: 7.23s\tremaining: 12.7s\n",
            "725:\tlearn: 0.4904619\ttotal: 7.24s\tremaining: 12.7s\n",
            "726:\tlearn: 0.4904257\ttotal: 7.25s\tremaining: 12.7s\n",
            "727:\tlearn: 0.4903888\ttotal: 7.27s\tremaining: 12.7s\n",
            "728:\tlearn: 0.4903573\ttotal: 7.28s\tremaining: 12.7s\n",
            "729:\tlearn: 0.4903169\ttotal: 7.29s\tremaining: 12.7s\n",
            "730:\tlearn: 0.4902716\ttotal: 7.3s\tremaining: 12.7s\n",
            "731:\tlearn: 0.4902223\ttotal: 7.31s\tremaining: 12.7s\n",
            "732:\tlearn: 0.4901871\ttotal: 7.31s\tremaining: 12.6s\n",
            "733:\tlearn: 0.4901519\ttotal: 7.32s\tremaining: 12.6s\n",
            "734:\tlearn: 0.4900979\ttotal: 7.34s\tremaining: 12.6s\n",
            "735:\tlearn: 0.4900484\ttotal: 7.35s\tremaining: 12.6s\n",
            "736:\tlearn: 0.4899978\ttotal: 7.36s\tremaining: 12.6s\n",
            "737:\tlearn: 0.4899616\ttotal: 7.37s\tremaining: 12.6s\n",
            "738:\tlearn: 0.4899224\ttotal: 7.38s\tremaining: 12.6s\n",
            "739:\tlearn: 0.4898901\ttotal: 7.38s\tremaining: 12.6s\n",
            "740:\tlearn: 0.4898510\ttotal: 7.39s\tremaining: 12.6s\n",
            "741:\tlearn: 0.4898261\ttotal: 7.41s\tremaining: 12.6s\n",
            "742:\tlearn: 0.4897919\ttotal: 7.42s\tremaining: 12.5s\n",
            "743:\tlearn: 0.4897595\ttotal: 7.42s\tremaining: 12.5s\n",
            "744:\tlearn: 0.4897352\ttotal: 7.43s\tremaining: 12.5s\n",
            "745:\tlearn: 0.4896974\ttotal: 7.44s\tremaining: 12.5s\n",
            "746:\tlearn: 0.4896647\ttotal: 7.45s\tremaining: 12.5s\n",
            "747:\tlearn: 0.4896170\ttotal: 7.46s\tremaining: 12.5s\n",
            "748:\tlearn: 0.4895731\ttotal: 7.47s\tremaining: 12.5s\n",
            "749:\tlearn: 0.4895269\ttotal: 7.48s\tremaining: 12.5s\n",
            "750:\tlearn: 0.4894865\ttotal: 7.49s\tremaining: 12.5s\n",
            "751:\tlearn: 0.4894538\ttotal: 7.5s\tremaining: 12.4s\n",
            "752:\tlearn: 0.4894183\ttotal: 7.51s\tremaining: 12.4s\n",
            "753:\tlearn: 0.4893857\ttotal: 7.52s\tremaining: 12.4s\n",
            "754:\tlearn: 0.4893434\ttotal: 7.53s\tremaining: 12.4s\n",
            "755:\tlearn: 0.4893060\ttotal: 7.54s\tremaining: 12.4s\n",
            "756:\tlearn: 0.4892690\ttotal: 7.55s\tremaining: 12.4s\n",
            "757:\tlearn: 0.4892363\ttotal: 7.56s\tremaining: 12.4s\n",
            "758:\tlearn: 0.4891994\ttotal: 7.57s\tremaining: 12.4s\n",
            "759:\tlearn: 0.4891637\ttotal: 7.58s\tremaining: 12.4s\n",
            "760:\tlearn: 0.4891295\ttotal: 7.59s\tremaining: 12.4s\n",
            "761:\tlearn: 0.4890786\ttotal: 7.6s\tremaining: 12.3s\n",
            "762:\tlearn: 0.4890292\ttotal: 7.61s\tremaining: 12.3s\n",
            "763:\tlearn: 0.4889813\ttotal: 7.62s\tremaining: 12.3s\n",
            "764:\tlearn: 0.4889476\ttotal: 7.63s\tremaining: 12.3s\n",
            "765:\tlearn: 0.4888986\ttotal: 7.64s\tremaining: 12.3s\n",
            "766:\tlearn: 0.4888696\ttotal: 7.65s\tremaining: 12.3s\n",
            "767:\tlearn: 0.4888250\ttotal: 7.66s\tremaining: 12.3s\n",
            "768:\tlearn: 0.4887902\ttotal: 7.66s\tremaining: 12.3s\n",
            "769:\tlearn: 0.4887506\ttotal: 7.67s\tremaining: 12.3s\n",
            "770:\tlearn: 0.4887238\ttotal: 7.68s\tremaining: 12.2s\n",
            "771:\tlearn: 0.4886839\ttotal: 7.69s\tremaining: 12.2s\n",
            "772:\tlearn: 0.4886412\ttotal: 7.7s\tremaining: 12.2s\n",
            "773:\tlearn: 0.4885878\ttotal: 7.71s\tremaining: 12.2s\n",
            "774:\tlearn: 0.4885581\ttotal: 7.72s\tremaining: 12.2s\n",
            "775:\tlearn: 0.4885246\ttotal: 7.73s\tremaining: 12.2s\n",
            "776:\tlearn: 0.4884933\ttotal: 7.75s\tremaining: 12.2s\n",
            "777:\tlearn: 0.4884533\ttotal: 7.75s\tremaining: 12.2s\n",
            "778:\tlearn: 0.4884001\ttotal: 7.77s\tremaining: 12.2s\n",
            "779:\tlearn: 0.4883651\ttotal: 7.77s\tremaining: 12.2s\n",
            "780:\tlearn: 0.4883291\ttotal: 7.78s\tremaining: 12.1s\n",
            "781:\tlearn: 0.4882985\ttotal: 7.8s\tremaining: 12.1s\n",
            "782:\tlearn: 0.4882656\ttotal: 7.81s\tremaining: 12.1s\n",
            "783:\tlearn: 0.4882282\ttotal: 7.82s\tremaining: 12.1s\n",
            "784:\tlearn: 0.4882050\ttotal: 7.83s\tremaining: 12.1s\n",
            "785:\tlearn: 0.4881627\ttotal: 7.84s\tremaining: 12.1s\n",
            "786:\tlearn: 0.4881171\ttotal: 7.85s\tremaining: 12.1s\n",
            "787:\tlearn: 0.4880787\ttotal: 7.86s\tremaining: 12.1s\n",
            "788:\tlearn: 0.4880409\ttotal: 7.87s\tremaining: 12.1s\n",
            "789:\tlearn: 0.4880170\ttotal: 7.88s\tremaining: 12.1s\n",
            "790:\tlearn: 0.4879738\ttotal: 7.89s\tremaining: 12.1s\n",
            "791:\tlearn: 0.4879329\ttotal: 7.9s\tremaining: 12s\n",
            "792:\tlearn: 0.4878852\ttotal: 7.91s\tremaining: 12s\n",
            "793:\tlearn: 0.4878444\ttotal: 7.92s\tremaining: 12s\n",
            "794:\tlearn: 0.4878213\ttotal: 7.93s\tremaining: 12s\n",
            "795:\tlearn: 0.4877809\ttotal: 7.93s\tremaining: 12s\n",
            "796:\tlearn: 0.4877458\ttotal: 7.95s\tremaining: 12s\n",
            "797:\tlearn: 0.4877153\ttotal: 7.96s\tremaining: 12s\n",
            "798:\tlearn: 0.4876880\ttotal: 7.97s\tremaining: 12s\n",
            "799:\tlearn: 0.4876661\ttotal: 7.98s\tremaining: 12s\n",
            "800:\tlearn: 0.4876357\ttotal: 7.99s\tremaining: 12s\n",
            "801:\tlearn: 0.4875970\ttotal: 8s\tremaining: 11.9s\n",
            "802:\tlearn: 0.4875611\ttotal: 8.01s\tremaining: 11.9s\n",
            "803:\tlearn: 0.4875272\ttotal: 8.02s\tremaining: 11.9s\n",
            "804:\tlearn: 0.4875050\ttotal: 8.03s\tremaining: 11.9s\n",
            "805:\tlearn: 0.4874384\ttotal: 8.04s\tremaining: 11.9s\n",
            "806:\tlearn: 0.4873951\ttotal: 8.05s\tremaining: 11.9s\n",
            "807:\tlearn: 0.4873637\ttotal: 8.06s\tremaining: 11.9s\n",
            "808:\tlearn: 0.4873441\ttotal: 8.07s\tremaining: 11.9s\n",
            "809:\tlearn: 0.4873222\ttotal: 8.08s\tremaining: 11.9s\n",
            "810:\tlearn: 0.4872926\ttotal: 8.09s\tremaining: 11.9s\n",
            "811:\tlearn: 0.4872605\ttotal: 8.09s\tremaining: 11.8s\n",
            "812:\tlearn: 0.4872316\ttotal: 8.1s\tremaining: 11.8s\n",
            "813:\tlearn: 0.4871931\ttotal: 8.11s\tremaining: 11.8s\n",
            "814:\tlearn: 0.4871606\ttotal: 8.12s\tremaining: 11.8s\n",
            "815:\tlearn: 0.4871280\ttotal: 8.13s\tremaining: 11.8s\n",
            "816:\tlearn: 0.4870911\ttotal: 8.14s\tremaining: 11.8s\n",
            "817:\tlearn: 0.4870589\ttotal: 8.16s\tremaining: 11.8s\n",
            "818:\tlearn: 0.4870249\ttotal: 8.17s\tremaining: 11.8s\n",
            "819:\tlearn: 0.4869946\ttotal: 8.18s\tremaining: 11.8s\n",
            "820:\tlearn: 0.4869664\ttotal: 8.19s\tremaining: 11.8s\n",
            "821:\tlearn: 0.4869263\ttotal: 8.2s\tremaining: 11.7s\n",
            "822:\tlearn: 0.4868802\ttotal: 8.21s\tremaining: 11.7s\n",
            "823:\tlearn: 0.4868553\ttotal: 8.21s\tremaining: 11.7s\n",
            "824:\tlearn: 0.4868137\ttotal: 8.22s\tremaining: 11.7s\n",
            "825:\tlearn: 0.4867778\ttotal: 8.24s\tremaining: 11.7s\n",
            "826:\tlearn: 0.4867545\ttotal: 8.26s\tremaining: 11.7s\n",
            "827:\tlearn: 0.4867189\ttotal: 8.27s\tremaining: 11.7s\n",
            "828:\tlearn: 0.4866979\ttotal: 8.28s\tremaining: 11.7s\n",
            "829:\tlearn: 0.4866482\ttotal: 8.29s\tremaining: 11.7s\n",
            "830:\tlearn: 0.4866190\ttotal: 8.29s\tremaining: 11.7s\n",
            "831:\tlearn: 0.4865861\ttotal: 8.3s\tremaining: 11.7s\n",
            "832:\tlearn: 0.4865455\ttotal: 8.31s\tremaining: 11.6s\n",
            "833:\tlearn: 0.4865102\ttotal: 8.32s\tremaining: 11.6s\n",
            "834:\tlearn: 0.4864803\ttotal: 8.33s\tremaining: 11.6s\n",
            "835:\tlearn: 0.4864512\ttotal: 8.34s\tremaining: 11.6s\n",
            "836:\tlearn: 0.4864238\ttotal: 8.35s\tremaining: 11.6s\n",
            "837:\tlearn: 0.4863958\ttotal: 8.36s\tremaining: 11.6s\n",
            "838:\tlearn: 0.4863630\ttotal: 8.37s\tremaining: 11.6s\n",
            "839:\tlearn: 0.4863292\ttotal: 8.38s\tremaining: 11.6s\n",
            "840:\tlearn: 0.4862876\ttotal: 8.39s\tremaining: 11.6s\n",
            "841:\tlearn: 0.4862550\ttotal: 8.4s\tremaining: 11.6s\n",
            "842:\tlearn: 0.4862326\ttotal: 8.41s\tremaining: 11.5s\n",
            "843:\tlearn: 0.4861983\ttotal: 8.42s\tremaining: 11.5s\n",
            "844:\tlearn: 0.4861586\ttotal: 8.43s\tremaining: 11.5s\n",
            "845:\tlearn: 0.4861421\ttotal: 8.44s\tremaining: 11.5s\n",
            "846:\tlearn: 0.4861028\ttotal: 8.45s\tremaining: 11.5s\n",
            "847:\tlearn: 0.4860627\ttotal: 8.46s\tremaining: 11.5s\n",
            "848:\tlearn: 0.4860294\ttotal: 8.47s\tremaining: 11.5s\n",
            "849:\tlearn: 0.4859919\ttotal: 8.48s\tremaining: 11.5s\n",
            "850:\tlearn: 0.4859473\ttotal: 8.49s\tremaining: 11.5s\n",
            "851:\tlearn: 0.4859087\ttotal: 8.5s\tremaining: 11.5s\n",
            "852:\tlearn: 0.4858739\ttotal: 8.51s\tremaining: 11.4s\n",
            "853:\tlearn: 0.4858311\ttotal: 8.52s\tremaining: 11.4s\n",
            "854:\tlearn: 0.4857969\ttotal: 8.53s\tremaining: 11.4s\n",
            "855:\tlearn: 0.4857747\ttotal: 8.54s\tremaining: 11.4s\n",
            "856:\tlearn: 0.4857312\ttotal: 8.54s\tremaining: 11.4s\n",
            "857:\tlearn: 0.4856908\ttotal: 8.55s\tremaining: 11.4s\n",
            "858:\tlearn: 0.4856606\ttotal: 8.57s\tremaining: 11.4s\n",
            "859:\tlearn: 0.4856257\ttotal: 8.58s\tremaining: 11.4s\n",
            "860:\tlearn: 0.4855817\ttotal: 8.59s\tremaining: 11.4s\n",
            "861:\tlearn: 0.4855444\ttotal: 8.6s\tremaining: 11.3s\n",
            "862:\tlearn: 0.4855142\ttotal: 8.6s\tremaining: 11.3s\n",
            "863:\tlearn: 0.4854909\ttotal: 8.61s\tremaining: 11.3s\n",
            "864:\tlearn: 0.4854568\ttotal: 8.62s\tremaining: 11.3s\n",
            "865:\tlearn: 0.4854262\ttotal: 8.64s\tremaining: 11.3s\n",
            "866:\tlearn: 0.4853880\ttotal: 8.65s\tremaining: 11.3s\n",
            "867:\tlearn: 0.4853491\ttotal: 8.66s\tremaining: 11.3s\n",
            "868:\tlearn: 0.4853175\ttotal: 8.67s\tremaining: 11.3s\n",
            "869:\tlearn: 0.4852975\ttotal: 8.68s\tremaining: 11.3s\n",
            "870:\tlearn: 0.4852355\ttotal: 8.69s\tremaining: 11.3s\n",
            "871:\tlearn: 0.4852063\ttotal: 8.7s\tremaining: 11.3s\n",
            "872:\tlearn: 0.4851709\ttotal: 8.71s\tremaining: 11.2s\n",
            "873:\tlearn: 0.4851487\ttotal: 8.71s\tremaining: 11.2s\n",
            "874:\tlearn: 0.4851128\ttotal: 8.72s\tremaining: 11.2s\n",
            "875:\tlearn: 0.4850704\ttotal: 8.74s\tremaining: 11.2s\n",
            "876:\tlearn: 0.4850294\ttotal: 8.74s\tremaining: 11.2s\n",
            "877:\tlearn: 0.4849984\ttotal: 8.75s\tremaining: 11.2s\n",
            "878:\tlearn: 0.4849586\ttotal: 8.76s\tremaining: 11.2s\n",
            "879:\tlearn: 0.4849273\ttotal: 8.77s\tremaining: 11.2s\n",
            "880:\tlearn: 0.4848777\ttotal: 8.78s\tremaining: 11.2s\n",
            "881:\tlearn: 0.4848425\ttotal: 8.79s\tremaining: 11.1s\n",
            "882:\tlearn: 0.4848224\ttotal: 8.8s\tremaining: 11.1s\n",
            "883:\tlearn: 0.4847870\ttotal: 8.81s\tremaining: 11.1s\n",
            "884:\tlearn: 0.4847664\ttotal: 8.82s\tremaining: 11.1s\n",
            "885:\tlearn: 0.4847346\ttotal: 8.83s\tremaining: 11.1s\n",
            "886:\tlearn: 0.4846985\ttotal: 8.84s\tremaining: 11.1s\n",
            "887:\tlearn: 0.4846634\ttotal: 8.85s\tremaining: 11.1s\n",
            "888:\tlearn: 0.4846140\ttotal: 8.86s\tremaining: 11.1s\n",
            "889:\tlearn: 0.4845916\ttotal: 8.87s\tremaining: 11.1s\n",
            "890:\tlearn: 0.4845635\ttotal: 8.88s\tremaining: 11s\n",
            "891:\tlearn: 0.4845316\ttotal: 8.89s\tremaining: 11s\n",
            "892:\tlearn: 0.4844969\ttotal: 8.89s\tremaining: 11s\n",
            "893:\tlearn: 0.4844679\ttotal: 8.9s\tremaining: 11s\n",
            "894:\tlearn: 0.4844300\ttotal: 8.91s\tremaining: 11s\n",
            "895:\tlearn: 0.4843993\ttotal: 8.93s\tremaining: 11s\n",
            "896:\tlearn: 0.4843691\ttotal: 8.93s\tremaining: 11s\n",
            "897:\tlearn: 0.4843347\ttotal: 8.94s\tremaining: 11s\n",
            "898:\tlearn: 0.4843066\ttotal: 8.95s\tremaining: 11s\n",
            "899:\tlearn: 0.4842773\ttotal: 8.96s\tremaining: 11s\n",
            "900:\tlearn: 0.4842481\ttotal: 8.97s\tremaining: 10.9s\n",
            "901:\tlearn: 0.4842157\ttotal: 8.99s\tremaining: 10.9s\n",
            "902:\tlearn: 0.4841933\ttotal: 9s\tremaining: 10.9s\n",
            "903:\tlearn: 0.4841564\ttotal: 9.01s\tremaining: 10.9s\n",
            "904:\tlearn: 0.4841334\ttotal: 9.02s\tremaining: 10.9s\n",
            "905:\tlearn: 0.4840942\ttotal: 9.03s\tremaining: 10.9s\n",
            "906:\tlearn: 0.4840553\ttotal: 9.04s\tremaining: 10.9s\n",
            "907:\tlearn: 0.4840180\ttotal: 9.05s\tremaining: 10.9s\n",
            "908:\tlearn: 0.4839779\ttotal: 9.06s\tremaining: 10.9s\n",
            "909:\tlearn: 0.4839438\ttotal: 9.07s\tremaining: 10.9s\n",
            "910:\tlearn: 0.4839005\ttotal: 9.08s\tremaining: 10.8s\n",
            "911:\tlearn: 0.4838661\ttotal: 9.09s\tremaining: 10.8s\n",
            "912:\tlearn: 0.4838297\ttotal: 9.09s\tremaining: 10.8s\n",
            "913:\tlearn: 0.4838014\ttotal: 9.1s\tremaining: 10.8s\n",
            "914:\tlearn: 0.4837697\ttotal: 9.11s\tremaining: 10.8s\n",
            "915:\tlearn: 0.4837325\ttotal: 9.12s\tremaining: 10.8s\n",
            "916:\tlearn: 0.4837053\ttotal: 9.13s\tremaining: 10.8s\n",
            "917:\tlearn: 0.4836628\ttotal: 9.14s\tremaining: 10.8s\n",
            "918:\tlearn: 0.4836247\ttotal: 9.15s\tremaining: 10.8s\n",
            "919:\tlearn: 0.4835791\ttotal: 9.16s\tremaining: 10.8s\n",
            "920:\tlearn: 0.4835473\ttotal: 9.17s\tremaining: 10.7s\n",
            "921:\tlearn: 0.4835112\ttotal: 9.18s\tremaining: 10.7s\n",
            "922:\tlearn: 0.4834749\ttotal: 9.19s\tremaining: 10.7s\n",
            "923:\tlearn: 0.4834564\ttotal: 9.21s\tremaining: 10.7s\n",
            "924:\tlearn: 0.4834083\ttotal: 9.21s\tremaining: 10.7s\n",
            "925:\tlearn: 0.4833760\ttotal: 9.23s\tremaining: 10.7s\n",
            "926:\tlearn: 0.4833552\ttotal: 9.24s\tremaining: 10.7s\n",
            "927:\tlearn: 0.4833166\ttotal: 9.26s\tremaining: 10.7s\n",
            "928:\tlearn: 0.4832827\ttotal: 9.27s\tremaining: 10.7s\n",
            "929:\tlearn: 0.4832475\ttotal: 9.28s\tremaining: 10.7s\n",
            "930:\tlearn: 0.4832122\ttotal: 9.29s\tremaining: 10.7s\n",
            "931:\tlearn: 0.4831828\ttotal: 9.29s\tremaining: 10.7s\n",
            "932:\tlearn: 0.4831569\ttotal: 9.3s\tremaining: 10.6s\n",
            "933:\tlearn: 0.4831290\ttotal: 9.31s\tremaining: 10.6s\n",
            "934:\tlearn: 0.4831007\ttotal: 9.32s\tremaining: 10.6s\n",
            "935:\tlearn: 0.4830774\ttotal: 9.33s\tremaining: 10.6s\n",
            "936:\tlearn: 0.4830467\ttotal: 9.34s\tremaining: 10.6s\n",
            "937:\tlearn: 0.4830228\ttotal: 9.35s\tremaining: 10.6s\n",
            "938:\tlearn: 0.4829807\ttotal: 9.36s\tremaining: 10.6s\n",
            "939:\tlearn: 0.4829623\ttotal: 9.38s\tremaining: 10.6s\n",
            "940:\tlearn: 0.4829254\ttotal: 9.39s\tremaining: 10.6s\n",
            "941:\tlearn: 0.4828901\ttotal: 9.4s\tremaining: 10.6s\n",
            "942:\tlearn: 0.4828556\ttotal: 9.4s\tremaining: 10.5s\n",
            "943:\tlearn: 0.4828109\ttotal: 9.42s\tremaining: 10.5s\n",
            "944:\tlearn: 0.4827813\ttotal: 9.43s\tremaining: 10.5s\n",
            "945:\tlearn: 0.4827473\ttotal: 9.44s\tremaining: 10.5s\n",
            "946:\tlearn: 0.4827228\ttotal: 9.45s\tremaining: 10.5s\n",
            "947:\tlearn: 0.4826858\ttotal: 9.46s\tremaining: 10.5s\n",
            "948:\tlearn: 0.4826409\ttotal: 9.47s\tremaining: 10.5s\n",
            "949:\tlearn: 0.4826090\ttotal: 9.48s\tremaining: 10.5s\n",
            "950:\tlearn: 0.4825739\ttotal: 9.49s\tremaining: 10.5s\n",
            "951:\tlearn: 0.4825454\ttotal: 9.5s\tremaining: 10.5s\n",
            "952:\tlearn: 0.4825097\ttotal: 9.51s\tremaining: 10.4s\n",
            "953:\tlearn: 0.4824654\ttotal: 9.52s\tremaining: 10.4s\n",
            "954:\tlearn: 0.4824288\ttotal: 9.53s\tremaining: 10.4s\n",
            "955:\tlearn: 0.4824050\ttotal: 9.54s\tremaining: 10.4s\n",
            "956:\tlearn: 0.4823880\ttotal: 9.55s\tremaining: 10.4s\n",
            "957:\tlearn: 0.4823688\ttotal: 9.55s\tremaining: 10.4s\n",
            "958:\tlearn: 0.4823391\ttotal: 9.56s\tremaining: 10.4s\n",
            "959:\tlearn: 0.4823116\ttotal: 9.58s\tremaining: 10.4s\n",
            "960:\tlearn: 0.4822794\ttotal: 9.59s\tremaining: 10.4s\n",
            "961:\tlearn: 0.4822452\ttotal: 9.6s\tremaining: 10.4s\n",
            "962:\tlearn: 0.4822359\ttotal: 9.61s\tremaining: 10.3s\n",
            "963:\tlearn: 0.4822010\ttotal: 9.62s\tremaining: 10.3s\n",
            "964:\tlearn: 0.4821629\ttotal: 9.63s\tremaining: 10.3s\n",
            "965:\tlearn: 0.4821187\ttotal: 9.64s\tremaining: 10.3s\n",
            "966:\tlearn: 0.4820822\ttotal: 9.66s\tremaining: 10.3s\n",
            "967:\tlearn: 0.4820703\ttotal: 9.66s\tremaining: 10.3s\n",
            "968:\tlearn: 0.4820303\ttotal: 9.68s\tremaining: 10.3s\n",
            "969:\tlearn: 0.4820004\ttotal: 9.69s\tremaining: 10.3s\n",
            "970:\tlearn: 0.4819668\ttotal: 9.7s\tremaining: 10.3s\n",
            "971:\tlearn: 0.4819375\ttotal: 9.71s\tremaining: 10.3s\n",
            "972:\tlearn: 0.4819181\ttotal: 9.71s\tremaining: 10.3s\n",
            "973:\tlearn: 0.4818953\ttotal: 9.72s\tremaining: 10.2s\n",
            "974:\tlearn: 0.4818686\ttotal: 9.73s\tremaining: 10.2s\n",
            "975:\tlearn: 0.4818288\ttotal: 9.74s\tremaining: 10.2s\n",
            "976:\tlearn: 0.4818090\ttotal: 9.76s\tremaining: 10.2s\n",
            "977:\tlearn: 0.4817768\ttotal: 9.77s\tremaining: 10.2s\n",
            "978:\tlearn: 0.4817528\ttotal: 9.78s\tremaining: 10.2s\n",
            "979:\tlearn: 0.4817330\ttotal: 9.79s\tremaining: 10.2s\n",
            "980:\tlearn: 0.4817050\ttotal: 9.8s\tremaining: 10.2s\n",
            "981:\tlearn: 0.4816538\ttotal: 9.81s\tremaining: 10.2s\n",
            "982:\tlearn: 0.4816182\ttotal: 9.82s\tremaining: 10.2s\n",
            "983:\tlearn: 0.4815875\ttotal: 9.83s\tremaining: 10.2s\n",
            "984:\tlearn: 0.4815635\ttotal: 9.84s\tremaining: 10.1s\n",
            "985:\tlearn: 0.4815285\ttotal: 9.85s\tremaining: 10.1s\n",
            "986:\tlearn: 0.4814897\ttotal: 9.86s\tremaining: 10.1s\n",
            "987:\tlearn: 0.4814479\ttotal: 9.87s\tremaining: 10.1s\n",
            "988:\tlearn: 0.4814094\ttotal: 9.88s\tremaining: 10.1s\n",
            "989:\tlearn: 0.4813903\ttotal: 9.89s\tremaining: 10.1s\n",
            "990:\tlearn: 0.4813648\ttotal: 9.9s\tremaining: 10.1s\n",
            "991:\tlearn: 0.4813296\ttotal: 9.91s\tremaining: 10.1s\n",
            "992:\tlearn: 0.4813008\ttotal: 9.92s\tremaining: 10.1s\n",
            "993:\tlearn: 0.4812763\ttotal: 9.93s\tremaining: 10s\n",
            "994:\tlearn: 0.4812442\ttotal: 9.94s\tremaining: 10s\n",
            "995:\tlearn: 0.4811999\ttotal: 9.95s\tremaining: 10s\n",
            "996:\tlearn: 0.4811702\ttotal: 9.96s\tremaining: 10s\n",
            "997:\tlearn: 0.4811330\ttotal: 9.97s\tremaining: 10s\n",
            "998:\tlearn: 0.4811028\ttotal: 9.98s\tremaining: 10s\n",
            "999:\tlearn: 0.4810714\ttotal: 9.99s\tremaining: 9.99s\n",
            "1000:\tlearn: 0.4810365\ttotal: 10s\tremaining: 9.98s\n",
            "1001:\tlearn: 0.4810128\ttotal: 10s\tremaining: 9.97s\n",
            "1002:\tlearn: 0.4809861\ttotal: 10s\tremaining: 9.96s\n",
            "1003:\tlearn: 0.4809520\ttotal: 10s\tremaining: 9.95s\n",
            "1004:\tlearn: 0.4809214\ttotal: 10s\tremaining: 9.94s\n",
            "1005:\tlearn: 0.4808937\ttotal: 10.1s\tremaining: 9.94s\n",
            "1006:\tlearn: 0.4808508\ttotal: 10.1s\tremaining: 9.93s\n",
            "1007:\tlearn: 0.4808167\ttotal: 10.1s\tremaining: 9.91s\n",
            "1008:\tlearn: 0.4807858\ttotal: 10.1s\tremaining: 9.9s\n",
            "1009:\tlearn: 0.4807723\ttotal: 10.1s\tremaining: 9.9s\n",
            "1010:\tlearn: 0.4807451\ttotal: 10.1s\tremaining: 9.89s\n",
            "1011:\tlearn: 0.4807173\ttotal: 10.1s\tremaining: 9.88s\n",
            "1012:\tlearn: 0.4806755\ttotal: 10.1s\tremaining: 9.87s\n",
            "1013:\tlearn: 0.4806412\ttotal: 10.1s\tremaining: 9.86s\n",
            "1014:\tlearn: 0.4806026\ttotal: 10.1s\tremaining: 9.85s\n",
            "1015:\tlearn: 0.4805745\ttotal: 10.2s\tremaining: 9.84s\n",
            "1016:\tlearn: 0.4805230\ttotal: 10.2s\tremaining: 9.82s\n",
            "1017:\tlearn: 0.4804918\ttotal: 10.2s\tremaining: 9.82s\n",
            "1018:\tlearn: 0.4804515\ttotal: 10.2s\tremaining: 9.82s\n",
            "1019:\tlearn: 0.4804291\ttotal: 10.2s\tremaining: 9.81s\n",
            "1020:\tlearn: 0.4803963\ttotal: 10.2s\tremaining: 9.8s\n",
            "1021:\tlearn: 0.4803595\ttotal: 10.2s\tremaining: 9.79s\n",
            "1022:\tlearn: 0.4803273\ttotal: 10.2s\tremaining: 9.78s\n",
            "1023:\tlearn: 0.4802949\ttotal: 10.3s\tremaining: 9.77s\n",
            "1024:\tlearn: 0.4802599\ttotal: 10.3s\tremaining: 9.76s\n",
            "1025:\tlearn: 0.4802296\ttotal: 10.3s\tremaining: 9.75s\n",
            "1026:\tlearn: 0.4802037\ttotal: 10.3s\tremaining: 9.74s\n",
            "1027:\tlearn: 0.4801707\ttotal: 10.3s\tremaining: 9.73s\n",
            "1028:\tlearn: 0.4801397\ttotal: 10.3s\tremaining: 9.72s\n",
            "1029:\tlearn: 0.4801104\ttotal: 10.3s\tremaining: 9.71s\n",
            "1030:\tlearn: 0.4800868\ttotal: 10.3s\tremaining: 9.7s\n",
            "1031:\tlearn: 0.4800435\ttotal: 10.3s\tremaining: 9.69s\n",
            "1032:\tlearn: 0.4800103\ttotal: 10.3s\tremaining: 9.67s\n",
            "1033:\tlearn: 0.4799808\ttotal: 10.3s\tremaining: 9.66s\n",
            "1034:\tlearn: 0.4799503\ttotal: 10.4s\tremaining: 9.65s\n",
            "1035:\tlearn: 0.4799104\ttotal: 10.4s\tremaining: 9.64s\n",
            "1036:\tlearn: 0.4798953\ttotal: 10.4s\tremaining: 9.63s\n",
            "1037:\tlearn: 0.4798643\ttotal: 10.4s\tremaining: 9.63s\n",
            "1038:\tlearn: 0.4798434\ttotal: 10.4s\tremaining: 9.62s\n",
            "1039:\tlearn: 0.4798139\ttotal: 10.4s\tremaining: 9.61s\n",
            "1040:\tlearn: 0.4797914\ttotal: 10.4s\tremaining: 9.59s\n",
            "1041:\tlearn: 0.4797494\ttotal: 10.4s\tremaining: 9.58s\n",
            "1042:\tlearn: 0.4797084\ttotal: 10.4s\tremaining: 9.57s\n",
            "1043:\tlearn: 0.4796868\ttotal: 10.4s\tremaining: 9.56s\n",
            "1044:\tlearn: 0.4796582\ttotal: 10.5s\tremaining: 9.55s\n",
            "1045:\tlearn: 0.4796292\ttotal: 10.5s\tremaining: 9.54s\n",
            "1046:\tlearn: 0.4795970\ttotal: 10.5s\tremaining: 9.53s\n",
            "1047:\tlearn: 0.4795740\ttotal: 10.5s\tremaining: 9.52s\n",
            "1048:\tlearn: 0.4795406\ttotal: 10.5s\tremaining: 9.52s\n",
            "1049:\tlearn: 0.4795146\ttotal: 10.5s\tremaining: 9.51s\n",
            "1050:\tlearn: 0.4794795\ttotal: 10.5s\tremaining: 9.5s\n",
            "1051:\tlearn: 0.4794628\ttotal: 10.5s\tremaining: 9.49s\n",
            "1052:\tlearn: 0.4794482\ttotal: 10.5s\tremaining: 9.47s\n",
            "1053:\tlearn: 0.4794066\ttotal: 10.5s\tremaining: 9.46s\n",
            "1054:\tlearn: 0.4793690\ttotal: 10.6s\tremaining: 9.45s\n",
            "1055:\tlearn: 0.4793505\ttotal: 10.6s\tremaining: 9.44s\n",
            "1056:\tlearn: 0.4793175\ttotal: 10.6s\tremaining: 9.43s\n",
            "1057:\tlearn: 0.4792816\ttotal: 10.6s\tremaining: 9.42s\n",
            "1058:\tlearn: 0.4792571\ttotal: 10.6s\tremaining: 9.41s\n",
            "1059:\tlearn: 0.4792216\ttotal: 10.6s\tremaining: 9.4s\n",
            "1060:\tlearn: 0.4792003\ttotal: 10.6s\tremaining: 9.39s\n",
            "1061:\tlearn: 0.4791640\ttotal: 10.6s\tremaining: 9.39s\n",
            "1062:\tlearn: 0.4791433\ttotal: 10.6s\tremaining: 9.38s\n",
            "1063:\tlearn: 0.4791052\ttotal: 10.6s\tremaining: 9.37s\n",
            "1064:\tlearn: 0.4790694\ttotal: 10.7s\tremaining: 9.36s\n",
            "1065:\tlearn: 0.4790410\ttotal: 10.7s\tremaining: 9.35s\n",
            "1066:\tlearn: 0.4789984\ttotal: 10.7s\tremaining: 9.34s\n",
            "1067:\tlearn: 0.4789636\ttotal: 10.7s\tremaining: 9.33s\n",
            "1068:\tlearn: 0.4789266\ttotal: 10.7s\tremaining: 9.32s\n",
            "1069:\tlearn: 0.4788738\ttotal: 10.7s\tremaining: 9.31s\n",
            "1070:\tlearn: 0.4788530\ttotal: 10.7s\tremaining: 9.3s\n",
            "1071:\tlearn: 0.4788227\ttotal: 10.7s\tremaining: 9.29s\n",
            "1072:\tlearn: 0.4787981\ttotal: 10.7s\tremaining: 9.28s\n",
            "1073:\tlearn: 0.4787706\ttotal: 10.8s\tremaining: 9.27s\n",
            "1074:\tlearn: 0.4787324\ttotal: 10.8s\tremaining: 9.26s\n",
            "1075:\tlearn: 0.4786948\ttotal: 10.8s\tremaining: 9.25s\n",
            "1076:\tlearn: 0.4786584\ttotal: 10.8s\tremaining: 9.24s\n",
            "1077:\tlearn: 0.4786283\ttotal: 10.8s\tremaining: 9.23s\n",
            "1078:\tlearn: 0.4785833\ttotal: 10.8s\tremaining: 9.22s\n",
            "1079:\tlearn: 0.4785489\ttotal: 10.8s\tremaining: 9.21s\n",
            "1080:\tlearn: 0.4785180\ttotal: 10.8s\tremaining: 9.2s\n",
            "1081:\tlearn: 0.4784802\ttotal: 10.8s\tremaining: 9.19s\n",
            "1082:\tlearn: 0.4784496\ttotal: 10.8s\tremaining: 9.18s\n",
            "1083:\tlearn: 0.4784171\ttotal: 10.9s\tremaining: 9.17s\n",
            "1084:\tlearn: 0.4783842\ttotal: 10.9s\tremaining: 9.16s\n",
            "1085:\tlearn: 0.4783508\ttotal: 10.9s\tremaining: 9.15s\n",
            "1086:\tlearn: 0.4783212\ttotal: 10.9s\tremaining: 9.14s\n",
            "1087:\tlearn: 0.4782748\ttotal: 10.9s\tremaining: 9.13s\n",
            "1088:\tlearn: 0.4782474\ttotal: 10.9s\tremaining: 9.12s\n",
            "1089:\tlearn: 0.4782190\ttotal: 10.9s\tremaining: 9.11s\n",
            "1090:\tlearn: 0.4781751\ttotal: 10.9s\tremaining: 9.1s\n",
            "1091:\tlearn: 0.4781442\ttotal: 10.9s\tremaining: 9.09s\n",
            "1092:\tlearn: 0.4781177\ttotal: 10.9s\tremaining: 9.08s\n",
            "1093:\tlearn: 0.4780800\ttotal: 10.9s\tremaining: 9.07s\n",
            "1094:\tlearn: 0.4780413\ttotal: 11s\tremaining: 9.06s\n",
            "1095:\tlearn: 0.4780090\ttotal: 11s\tremaining: 9.05s\n",
            "1096:\tlearn: 0.4779907\ttotal: 11s\tremaining: 9.04s\n",
            "1097:\tlearn: 0.4779486\ttotal: 11s\tremaining: 9.03s\n",
            "1098:\tlearn: 0.4779206\ttotal: 11s\tremaining: 9.02s\n",
            "1099:\tlearn: 0.4778830\ttotal: 11s\tremaining: 9.01s\n",
            "1100:\tlearn: 0.4778385\ttotal: 11s\tremaining: 9s\n",
            "1101:\tlearn: 0.4777993\ttotal: 11s\tremaining: 8.99s\n",
            "1102:\tlearn: 0.4777546\ttotal: 11s\tremaining: 8.98s\n",
            "1103:\tlearn: 0.4777238\ttotal: 11.1s\tremaining: 8.98s\n",
            "1104:\tlearn: 0.4777030\ttotal: 11.1s\tremaining: 8.96s\n",
            "1105:\tlearn: 0.4776690\ttotal: 11.1s\tremaining: 8.95s\n",
            "1106:\tlearn: 0.4776204\ttotal: 11.1s\tremaining: 8.94s\n",
            "1107:\tlearn: 0.4776100\ttotal: 11.1s\tremaining: 8.93s\n",
            "1108:\tlearn: 0.4775749\ttotal: 11.1s\tremaining: 8.92s\n",
            "1109:\tlearn: 0.4775289\ttotal: 11.1s\tremaining: 8.91s\n",
            "1110:\tlearn: 0.4775035\ttotal: 11.1s\tremaining: 8.9s\n",
            "1111:\tlearn: 0.4774709\ttotal: 11.1s\tremaining: 8.89s\n",
            "1112:\tlearn: 0.4774466\ttotal: 11.1s\tremaining: 8.88s\n",
            "1113:\tlearn: 0.4774128\ttotal: 11.2s\tremaining: 8.87s\n",
            "1114:\tlearn: 0.4773657\ttotal: 11.2s\tremaining: 8.86s\n",
            "1115:\tlearn: 0.4773364\ttotal: 11.2s\tremaining: 8.85s\n",
            "1116:\tlearn: 0.4773035\ttotal: 11.2s\tremaining: 8.85s\n",
            "1117:\tlearn: 0.4772743\ttotal: 11.2s\tremaining: 8.84s\n",
            "1118:\tlearn: 0.4772461\ttotal: 11.2s\tremaining: 8.83s\n",
            "1119:\tlearn: 0.4772197\ttotal: 11.2s\tremaining: 8.82s\n",
            "1120:\tlearn: 0.4771811\ttotal: 11.2s\tremaining: 8.81s\n",
            "1121:\tlearn: 0.4771353\ttotal: 11.2s\tremaining: 8.8s\n",
            "1122:\tlearn: 0.4771003\ttotal: 11.3s\tremaining: 8.79s\n",
            "1123:\tlearn: 0.4770672\ttotal: 11.3s\tremaining: 8.78s\n",
            "1124:\tlearn: 0.4770429\ttotal: 11.3s\tremaining: 8.77s\n",
            "1125:\tlearn: 0.4770227\ttotal: 11.3s\tremaining: 8.76s\n",
            "1126:\tlearn: 0.4769833\ttotal: 11.3s\tremaining: 8.75s\n",
            "1127:\tlearn: 0.4769519\ttotal: 11.3s\tremaining: 8.74s\n",
            "1128:\tlearn: 0.4769297\ttotal: 11.3s\tremaining: 8.73s\n",
            "1129:\tlearn: 0.4768869\ttotal: 11.3s\tremaining: 8.72s\n",
            "1130:\tlearn: 0.4768564\ttotal: 11.3s\tremaining: 8.71s\n",
            "1131:\tlearn: 0.4768266\ttotal: 11.3s\tremaining: 8.7s\n",
            "1132:\tlearn: 0.4767888\ttotal: 11.4s\tremaining: 8.69s\n",
            "1133:\tlearn: 0.4767644\ttotal: 11.4s\tremaining: 8.68s\n",
            "1134:\tlearn: 0.4767320\ttotal: 11.4s\tremaining: 8.67s\n",
            "1135:\tlearn: 0.4766984\ttotal: 11.4s\tremaining: 8.66s\n",
            "1136:\tlearn: 0.4766721\ttotal: 11.4s\tremaining: 8.65s\n",
            "1137:\tlearn: 0.4766452\ttotal: 11.4s\tremaining: 8.64s\n",
            "1138:\tlearn: 0.4766054\ttotal: 11.4s\tremaining: 8.63s\n",
            "1139:\tlearn: 0.4765790\ttotal: 11.4s\tremaining: 8.62s\n",
            "1140:\tlearn: 0.4765379\ttotal: 11.4s\tremaining: 8.61s\n",
            "1141:\tlearn: 0.4765165\ttotal: 11.4s\tremaining: 8.6s\n",
            "1142:\tlearn: 0.4764982\ttotal: 11.5s\tremaining: 8.59s\n",
            "1143:\tlearn: 0.4764756\ttotal: 11.5s\tremaining: 8.58s\n",
            "1144:\tlearn: 0.4764324\ttotal: 11.5s\tremaining: 8.57s\n",
            "1145:\tlearn: 0.4764083\ttotal: 11.5s\tremaining: 8.56s\n",
            "1146:\tlearn: 0.4763796\ttotal: 11.5s\tremaining: 8.55s\n",
            "1147:\tlearn: 0.4763372\ttotal: 11.5s\tremaining: 8.54s\n",
            "1148:\tlearn: 0.4763092\ttotal: 11.5s\tremaining: 8.53s\n",
            "1149:\tlearn: 0.4762784\ttotal: 11.5s\tremaining: 8.52s\n",
            "1150:\tlearn: 0.4762501\ttotal: 11.5s\tremaining: 8.51s\n",
            "1151:\tlearn: 0.4762189\ttotal: 11.5s\tremaining: 8.5s\n",
            "1152:\tlearn: 0.4761833\ttotal: 11.6s\tremaining: 8.49s\n",
            "1153:\tlearn: 0.4761582\ttotal: 11.6s\tremaining: 8.48s\n",
            "1154:\tlearn: 0.4761247\ttotal: 11.6s\tremaining: 8.47s\n",
            "1155:\tlearn: 0.4760912\ttotal: 11.6s\tremaining: 8.46s\n",
            "1156:\tlearn: 0.4760489\ttotal: 11.6s\tremaining: 8.45s\n",
            "1157:\tlearn: 0.4760244\ttotal: 11.6s\tremaining: 8.44s\n",
            "1158:\tlearn: 0.4759915\ttotal: 11.6s\tremaining: 8.43s\n",
            "1159:\tlearn: 0.4759749\ttotal: 11.6s\tremaining: 8.42s\n",
            "1160:\tlearn: 0.4759455\ttotal: 11.6s\tremaining: 8.41s\n",
            "1161:\tlearn: 0.4759066\ttotal: 11.6s\tremaining: 8.4s\n",
            "1162:\tlearn: 0.4758695\ttotal: 11.7s\tremaining: 8.39s\n",
            "1163:\tlearn: 0.4758449\ttotal: 11.7s\tremaining: 8.38s\n",
            "1164:\tlearn: 0.4758126\ttotal: 11.7s\tremaining: 8.37s\n",
            "1165:\tlearn: 0.4757800\ttotal: 11.7s\tremaining: 8.36s\n",
            "1166:\tlearn: 0.4757502\ttotal: 11.7s\tremaining: 8.35s\n",
            "1167:\tlearn: 0.4757027\ttotal: 11.7s\tremaining: 8.34s\n",
            "1168:\tlearn: 0.4756820\ttotal: 11.7s\tremaining: 8.33s\n",
            "1169:\tlearn: 0.4756414\ttotal: 11.7s\tremaining: 8.32s\n",
            "1170:\tlearn: 0.4756135\ttotal: 11.7s\tremaining: 8.3s\n",
            "1171:\tlearn: 0.4755744\ttotal: 11.7s\tremaining: 8.29s\n",
            "1172:\tlearn: 0.4755462\ttotal: 11.8s\tremaining: 8.29s\n",
            "1173:\tlearn: 0.4755272\ttotal: 11.8s\tremaining: 8.27s\n",
            "1174:\tlearn: 0.4755132\ttotal: 11.8s\tremaining: 8.26s\n",
            "1175:\tlearn: 0.4754930\ttotal: 11.8s\tremaining: 8.25s\n",
            "1176:\tlearn: 0.4754597\ttotal: 11.8s\tremaining: 8.24s\n",
            "1177:\tlearn: 0.4754335\ttotal: 11.8s\tremaining: 8.23s\n",
            "1178:\tlearn: 0.4753997\ttotal: 11.8s\tremaining: 8.23s\n",
            "1179:\tlearn: 0.4753692\ttotal: 11.8s\tremaining: 8.22s\n",
            "1180:\tlearn: 0.4753505\ttotal: 11.8s\tremaining: 8.21s\n",
            "1181:\tlearn: 0.4753231\ttotal: 11.9s\tremaining: 8.2s\n",
            "1182:\tlearn: 0.4752945\ttotal: 11.9s\tremaining: 8.19s\n",
            "1183:\tlearn: 0.4752633\ttotal: 11.9s\tremaining: 8.18s\n",
            "1184:\tlearn: 0.4752259\ttotal: 11.9s\tremaining: 8.17s\n",
            "1185:\tlearn: 0.4752002\ttotal: 11.9s\tremaining: 8.16s\n",
            "1186:\tlearn: 0.4751788\ttotal: 11.9s\tremaining: 8.15s\n",
            "1187:\tlearn: 0.4751594\ttotal: 11.9s\tremaining: 8.14s\n",
            "1188:\tlearn: 0.4751328\ttotal: 11.9s\tremaining: 8.13s\n",
            "1189:\tlearn: 0.4750930\ttotal: 11.9s\tremaining: 8.13s\n",
            "1190:\tlearn: 0.4750720\ttotal: 12s\tremaining: 8.12s\n",
            "1191:\tlearn: 0.4750388\ttotal: 12s\tremaining: 8.11s\n",
            "1192:\tlearn: 0.4750068\ttotal: 12s\tremaining: 8.1s\n",
            "1193:\tlearn: 0.4749625\ttotal: 12s\tremaining: 8.09s\n",
            "1194:\tlearn: 0.4749353\ttotal: 12s\tremaining: 8.08s\n",
            "1195:\tlearn: 0.4749147\ttotal: 12s\tremaining: 8.06s\n",
            "1196:\tlearn: 0.4748884\ttotal: 12s\tremaining: 8.05s\n",
            "1197:\tlearn: 0.4748707\ttotal: 12s\tremaining: 8.05s\n",
            "1198:\tlearn: 0.4748315\ttotal: 12s\tremaining: 8.04s\n",
            "1199:\tlearn: 0.4748254\ttotal: 12s\tremaining: 8.03s\n",
            "1200:\tlearn: 0.4748115\ttotal: 12s\tremaining: 8.02s\n",
            "1201:\tlearn: 0.4747965\ttotal: 12.1s\tremaining: 8s\n",
            "1202:\tlearn: 0.4747610\ttotal: 12.1s\tremaining: 7.99s\n",
            "1203:\tlearn: 0.4747239\ttotal: 12.1s\tremaining: 7.98s\n",
            "1204:\tlearn: 0.4746984\ttotal: 12.1s\tremaining: 7.97s\n",
            "1205:\tlearn: 0.4746627\ttotal: 12.1s\tremaining: 7.96s\n",
            "1206:\tlearn: 0.4746265\ttotal: 12.1s\tremaining: 7.95s\n",
            "1207:\tlearn: 0.4745866\ttotal: 12.1s\tremaining: 7.95s\n",
            "1208:\tlearn: 0.4745419\ttotal: 12.1s\tremaining: 7.94s\n",
            "1209:\tlearn: 0.4745121\ttotal: 12.2s\tremaining: 7.94s\n",
            "1210:\tlearn: 0.4744790\ttotal: 12.2s\tremaining: 7.93s\n",
            "1211:\tlearn: 0.4744315\ttotal: 12.2s\tremaining: 7.92s\n",
            "1212:\tlearn: 0.4744114\ttotal: 12.2s\tremaining: 7.91s\n",
            "1213:\tlearn: 0.4743798\ttotal: 12.2s\tremaining: 7.9s\n",
            "1214:\tlearn: 0.4743477\ttotal: 12.2s\tremaining: 7.9s\n",
            "1215:\tlearn: 0.4743247\ttotal: 12.2s\tremaining: 7.89s\n",
            "1216:\tlearn: 0.4742980\ttotal: 12.3s\tremaining: 7.88s\n",
            "1217:\tlearn: 0.4742689\ttotal: 12.3s\tremaining: 7.88s\n",
            "1218:\tlearn: 0.4742339\ttotal: 12.3s\tremaining: 7.87s\n",
            "1219:\tlearn: 0.4742006\ttotal: 12.3s\tremaining: 7.85s\n",
            "1220:\tlearn: 0.4741739\ttotal: 12.3s\tremaining: 7.84s\n",
            "1221:\tlearn: 0.4741570\ttotal: 12.3s\tremaining: 7.83s\n",
            "1222:\tlearn: 0.4741275\ttotal: 12.3s\tremaining: 7.83s\n",
            "1223:\tlearn: 0.4741063\ttotal: 12.3s\tremaining: 7.82s\n",
            "1224:\tlearn: 0.4740817\ttotal: 12.3s\tremaining: 7.81s\n",
            "1225:\tlearn: 0.4740667\ttotal: 12.3s\tremaining: 7.8s\n",
            "1226:\tlearn: 0.4740334\ttotal: 12.4s\tremaining: 7.79s\n",
            "1227:\tlearn: 0.4739983\ttotal: 12.4s\tremaining: 7.78s\n",
            "1228:\tlearn: 0.4739689\ttotal: 12.4s\tremaining: 7.77s\n",
            "1229:\tlearn: 0.4739418\ttotal: 12.4s\tremaining: 7.76s\n",
            "1230:\tlearn: 0.4739325\ttotal: 12.4s\tremaining: 7.75s\n",
            "1231:\tlearn: 0.4739075\ttotal: 12.4s\tremaining: 7.74s\n",
            "1232:\tlearn: 0.4738717\ttotal: 12.4s\tremaining: 7.72s\n",
            "1233:\tlearn: 0.4738369\ttotal: 12.4s\tremaining: 7.72s\n",
            "1234:\tlearn: 0.4738240\ttotal: 12.4s\tremaining: 7.71s\n",
            "1235:\tlearn: 0.4737785\ttotal: 12.5s\tremaining: 7.7s\n",
            "1236:\tlearn: 0.4737605\ttotal: 12.5s\tremaining: 7.69s\n",
            "1237:\tlearn: 0.4737467\ttotal: 12.5s\tremaining: 7.67s\n",
            "1238:\tlearn: 0.4737216\ttotal: 12.5s\tremaining: 7.67s\n",
            "1239:\tlearn: 0.4736931\ttotal: 12.5s\tremaining: 7.66s\n",
            "1240:\tlearn: 0.4736624\ttotal: 12.5s\tremaining: 7.64s\n",
            "1241:\tlearn: 0.4736232\ttotal: 12.5s\tremaining: 7.63s\n",
            "1242:\tlearn: 0.4735964\ttotal: 12.5s\tremaining: 7.63s\n",
            "1243:\tlearn: 0.4735601\ttotal: 12.5s\tremaining: 7.62s\n",
            "1244:\tlearn: 0.4735196\ttotal: 12.5s\tremaining: 7.6s\n",
            "1245:\tlearn: 0.4734836\ttotal: 12.6s\tremaining: 7.59s\n",
            "1246:\tlearn: 0.4734587\ttotal: 12.6s\tremaining: 7.58s\n",
            "1247:\tlearn: 0.4734317\ttotal: 12.6s\tremaining: 7.57s\n",
            "1248:\tlearn: 0.4734083\ttotal: 12.6s\tremaining: 7.56s\n",
            "1249:\tlearn: 0.4733647\ttotal: 12.6s\tremaining: 7.55s\n",
            "1250:\tlearn: 0.4733322\ttotal: 12.6s\tremaining: 7.54s\n",
            "1251:\tlearn: 0.4733065\ttotal: 12.6s\tremaining: 7.53s\n",
            "1252:\tlearn: 0.4732961\ttotal: 12.6s\tremaining: 7.52s\n",
            "1253:\tlearn: 0.4732723\ttotal: 12.6s\tremaining: 7.51s\n",
            "1254:\tlearn: 0.4732469\ttotal: 12.6s\tremaining: 7.5s\n",
            "1255:\tlearn: 0.4732013\ttotal: 12.7s\tremaining: 7.5s\n",
            "1256:\tlearn: 0.4731575\ttotal: 12.7s\tremaining: 7.49s\n",
            "1257:\tlearn: 0.4731096\ttotal: 12.7s\tremaining: 7.48s\n",
            "1258:\tlearn: 0.4730744\ttotal: 12.7s\tremaining: 7.47s\n",
            "1259:\tlearn: 0.4730502\ttotal: 12.7s\tremaining: 7.46s\n",
            "1260:\tlearn: 0.4729894\ttotal: 12.7s\tremaining: 7.45s\n",
            "1261:\tlearn: 0.4729629\ttotal: 12.7s\tremaining: 7.43s\n",
            "1262:\tlearn: 0.4729330\ttotal: 12.7s\tremaining: 7.42s\n",
            "1263:\tlearn: 0.4729089\ttotal: 12.7s\tremaining: 7.42s\n",
            "1264:\tlearn: 0.4728688\ttotal: 12.8s\tremaining: 7.41s\n",
            "1265:\tlearn: 0.4728477\ttotal: 12.8s\tremaining: 7.4s\n",
            "1266:\tlearn: 0.4727953\ttotal: 12.8s\tremaining: 7.39s\n",
            "1267:\tlearn: 0.4727753\ttotal: 12.8s\tremaining: 7.38s\n",
            "1268:\tlearn: 0.4727422\ttotal: 12.8s\tremaining: 7.37s\n",
            "1269:\tlearn: 0.4727082\ttotal: 12.8s\tremaining: 7.36s\n",
            "1270:\tlearn: 0.4726841\ttotal: 12.8s\tremaining: 7.35s\n",
            "1271:\tlearn: 0.4726629\ttotal: 12.8s\tremaining: 7.34s\n",
            "1272:\tlearn: 0.4726255\ttotal: 12.8s\tremaining: 7.33s\n",
            "1273:\tlearn: 0.4726009\ttotal: 12.8s\tremaining: 7.32s\n",
            "1274:\tlearn: 0.4725646\ttotal: 12.9s\tremaining: 7.31s\n",
            "1275:\tlearn: 0.4725312\ttotal: 12.9s\tremaining: 7.3s\n",
            "1276:\tlearn: 0.4725045\ttotal: 12.9s\tremaining: 7.29s\n",
            "1277:\tlearn: 0.4724729\ttotal: 12.9s\tremaining: 7.28s\n",
            "1278:\tlearn: 0.4724508\ttotal: 12.9s\tremaining: 7.27s\n",
            "1279:\tlearn: 0.4724203\ttotal: 12.9s\tremaining: 7.26s\n",
            "1280:\tlearn: 0.4723923\ttotal: 12.9s\tremaining: 7.25s\n",
            "1281:\tlearn: 0.4723680\ttotal: 12.9s\tremaining: 7.24s\n",
            "1282:\tlearn: 0.4723423\ttotal: 12.9s\tremaining: 7.23s\n",
            "1283:\tlearn: 0.4723114\ttotal: 12.9s\tremaining: 7.22s\n",
            "1284:\tlearn: 0.4722810\ttotal: 12.9s\tremaining: 7.21s\n",
            "1285:\tlearn: 0.4722567\ttotal: 13s\tremaining: 7.19s\n",
            "1286:\tlearn: 0.4722359\ttotal: 13s\tremaining: 7.18s\n",
            "1287:\tlearn: 0.4722079\ttotal: 13s\tremaining: 7.17s\n",
            "1288:\tlearn: 0.4721864\ttotal: 13s\tremaining: 7.16s\n",
            "1289:\tlearn: 0.4721516\ttotal: 13s\tremaining: 7.15s\n",
            "1290:\tlearn: 0.4721308\ttotal: 13s\tremaining: 7.14s\n",
            "1291:\tlearn: 0.4720937\ttotal: 13s\tremaining: 7.13s\n",
            "1292:\tlearn: 0.4720492\ttotal: 13s\tremaining: 7.13s\n",
            "1293:\tlearn: 0.4720238\ttotal: 13.1s\tremaining: 7.12s\n",
            "1294:\tlearn: 0.4720026\ttotal: 13.1s\tremaining: 7.11s\n",
            "1295:\tlearn: 0.4719688\ttotal: 13.1s\tremaining: 7.1s\n",
            "1296:\tlearn: 0.4719381\ttotal: 13.1s\tremaining: 7.09s\n",
            "1297:\tlearn: 0.4719134\ttotal: 13.1s\tremaining: 7.08s\n",
            "1298:\tlearn: 0.4718821\ttotal: 13.1s\tremaining: 7.07s\n",
            "1299:\tlearn: 0.4718627\ttotal: 13.1s\tremaining: 7.06s\n",
            "1300:\tlearn: 0.4718317\ttotal: 13.1s\tremaining: 7.05s\n",
            "1301:\tlearn: 0.4718053\ttotal: 13.1s\tremaining: 7.04s\n",
            "1302:\tlearn: 0.4717792\ttotal: 13.1s\tremaining: 7.03s\n",
            "1303:\tlearn: 0.4717399\ttotal: 13.1s\tremaining: 7.02s\n",
            "1304:\tlearn: 0.4717077\ttotal: 13.2s\tremaining: 7.01s\n",
            "1305:\tlearn: 0.4716634\ttotal: 13.2s\tremaining: 7s\n",
            "1306:\tlearn: 0.4716317\ttotal: 13.2s\tremaining: 6.99s\n",
            "1307:\tlearn: 0.4715927\ttotal: 13.2s\tremaining: 6.98s\n",
            "1308:\tlearn: 0.4715618\ttotal: 13.2s\tremaining: 6.97s\n",
            "1309:\tlearn: 0.4715317\ttotal: 13.2s\tremaining: 6.96s\n",
            "1310:\tlearn: 0.4714997\ttotal: 13.2s\tremaining: 6.95s\n",
            "1311:\tlearn: 0.4714635\ttotal: 13.2s\tremaining: 6.94s\n",
            "1312:\tlearn: 0.4714388\ttotal: 13.3s\tremaining: 6.93s\n",
            "1313:\tlearn: 0.4714181\ttotal: 13.3s\tremaining: 6.92s\n",
            "1314:\tlearn: 0.4713896\ttotal: 13.3s\tremaining: 6.91s\n",
            "1315:\tlearn: 0.4713462\ttotal: 13.3s\tremaining: 6.9s\n",
            "1316:\tlearn: 0.4713130\ttotal: 13.3s\tremaining: 6.89s\n",
            "1317:\tlearn: 0.4712851\ttotal: 13.3s\tremaining: 6.88s\n",
            "1318:\tlearn: 0.4712565\ttotal: 13.3s\tremaining: 6.87s\n",
            "1319:\tlearn: 0.4712357\ttotal: 13.3s\tremaining: 6.86s\n",
            "1320:\tlearn: 0.4712028\ttotal: 13.3s\tremaining: 6.85s\n",
            "1321:\tlearn: 0.4711767\ttotal: 13.3s\tremaining: 6.84s\n",
            "1322:\tlearn: 0.4711480\ttotal: 13.4s\tremaining: 6.83s\n",
            "1323:\tlearn: 0.4711298\ttotal: 13.4s\tremaining: 6.82s\n",
            "1324:\tlearn: 0.4710923\ttotal: 13.4s\tremaining: 6.81s\n",
            "1325:\tlearn: 0.4710551\ttotal: 13.4s\tremaining: 6.8s\n",
            "1326:\tlearn: 0.4710225\ttotal: 13.4s\tremaining: 6.79s\n",
            "1327:\tlearn: 0.4710002\ttotal: 13.4s\tremaining: 6.78s\n",
            "1328:\tlearn: 0.4709756\ttotal: 13.4s\tremaining: 6.77s\n",
            "1329:\tlearn: 0.4709476\ttotal: 13.4s\tremaining: 6.76s\n",
            "1330:\tlearn: 0.4709118\ttotal: 13.4s\tremaining: 6.75s\n",
            "1331:\tlearn: 0.4708904\ttotal: 13.4s\tremaining: 6.74s\n",
            "1332:\tlearn: 0.4708723\ttotal: 13.5s\tremaining: 6.73s\n",
            "1333:\tlearn: 0.4708397\ttotal: 13.5s\tremaining: 6.72s\n",
            "1334:\tlearn: 0.4708202\ttotal: 13.5s\tremaining: 6.71s\n",
            "1335:\tlearn: 0.4707930\ttotal: 13.5s\tremaining: 6.7s\n",
            "1336:\tlearn: 0.4707557\ttotal: 13.5s\tremaining: 6.69s\n",
            "1337:\tlearn: 0.4707258\ttotal: 13.5s\tremaining: 6.68s\n",
            "1338:\tlearn: 0.4706811\ttotal: 13.5s\tremaining: 6.67s\n",
            "1339:\tlearn: 0.4706535\ttotal: 13.5s\tremaining: 6.66s\n",
            "1340:\tlearn: 0.4706130\ttotal: 13.5s\tremaining: 6.65s\n",
            "1341:\tlearn: 0.4705802\ttotal: 13.5s\tremaining: 6.64s\n",
            "1342:\tlearn: 0.4705560\ttotal: 13.5s\tremaining: 6.63s\n",
            "1343:\tlearn: 0.4705237\ttotal: 13.6s\tremaining: 6.62s\n",
            "1344:\tlearn: 0.4704998\ttotal: 13.6s\tremaining: 6.6s\n",
            "1345:\tlearn: 0.4704716\ttotal: 13.6s\tremaining: 6.59s\n",
            "1346:\tlearn: 0.4704432\ttotal: 13.6s\tremaining: 6.58s\n",
            "1347:\tlearn: 0.4704234\ttotal: 13.6s\tremaining: 6.57s\n",
            "1348:\tlearn: 0.4704083\ttotal: 13.6s\tremaining: 6.56s\n",
            "1349:\tlearn: 0.4703972\ttotal: 13.6s\tremaining: 6.55s\n",
            "1350:\tlearn: 0.4703451\ttotal: 13.6s\tremaining: 6.54s\n",
            "1351:\tlearn: 0.4703149\ttotal: 13.6s\tremaining: 6.53s\n",
            "1352:\tlearn: 0.4702866\ttotal: 13.6s\tremaining: 6.52s\n",
            "1353:\tlearn: 0.4702605\ttotal: 13.6s\tremaining: 6.51s\n",
            "1354:\tlearn: 0.4702261\ttotal: 13.7s\tremaining: 6.5s\n",
            "1355:\tlearn: 0.4701928\ttotal: 13.7s\tremaining: 6.5s\n",
            "1356:\tlearn: 0.4701545\ttotal: 13.7s\tremaining: 6.49s\n",
            "1357:\tlearn: 0.4701315\ttotal: 13.7s\tremaining: 6.47s\n",
            "1358:\tlearn: 0.4701040\ttotal: 13.7s\tremaining: 6.46s\n",
            "1359:\tlearn: 0.4700760\ttotal: 13.7s\tremaining: 6.45s\n",
            "1360:\tlearn: 0.4700362\ttotal: 13.7s\tremaining: 6.44s\n",
            "1361:\tlearn: 0.4700135\ttotal: 13.7s\tremaining: 6.43s\n",
            "1362:\tlearn: 0.4699882\ttotal: 13.7s\tremaining: 6.42s\n",
            "1363:\tlearn: 0.4699565\ttotal: 13.8s\tremaining: 6.41s\n",
            "1364:\tlearn: 0.4699469\ttotal: 13.8s\tremaining: 6.4s\n",
            "1365:\tlearn: 0.4699314\ttotal: 13.8s\tremaining: 6.39s\n",
            "1366:\tlearn: 0.4698919\ttotal: 13.8s\tremaining: 6.38s\n",
            "1367:\tlearn: 0.4698604\ttotal: 13.8s\tremaining: 6.37s\n",
            "1368:\tlearn: 0.4698325\ttotal: 13.8s\tremaining: 6.36s\n",
            "1369:\tlearn: 0.4698021\ttotal: 13.8s\tremaining: 6.35s\n",
            "1370:\tlearn: 0.4697701\ttotal: 13.8s\tremaining: 6.34s\n",
            "1371:\tlearn: 0.4697486\ttotal: 13.8s\tremaining: 6.33s\n",
            "1372:\tlearn: 0.4697202\ttotal: 13.8s\tremaining: 6.32s\n",
            "1373:\tlearn: 0.4696954\ttotal: 13.9s\tremaining: 6.31s\n",
            "1374:\tlearn: 0.4696792\ttotal: 13.9s\tremaining: 6.3s\n",
            "1375:\tlearn: 0.4696486\ttotal: 13.9s\tremaining: 6.29s\n",
            "1376:\tlearn: 0.4696238\ttotal: 13.9s\tremaining: 6.28s\n",
            "1377:\tlearn: 0.4695986\ttotal: 13.9s\tremaining: 6.27s\n",
            "1378:\tlearn: 0.4695600\ttotal: 13.9s\tremaining: 6.26s\n",
            "1379:\tlearn: 0.4695212\ttotal: 13.9s\tremaining: 6.25s\n",
            "1380:\tlearn: 0.4694944\ttotal: 13.9s\tremaining: 6.24s\n",
            "1381:\tlearn: 0.4694779\ttotal: 13.9s\tremaining: 6.23s\n",
            "1382:\tlearn: 0.4694554\ttotal: 13.9s\tremaining: 6.22s\n",
            "1383:\tlearn: 0.4694204\ttotal: 14s\tremaining: 6.21s\n",
            "1384:\tlearn: 0.4693899\ttotal: 14s\tremaining: 6.2s\n",
            "1385:\tlearn: 0.4693778\ttotal: 14s\tremaining: 6.2s\n",
            "1386:\tlearn: 0.4693444\ttotal: 14s\tremaining: 6.18s\n",
            "1387:\tlearn: 0.4693012\ttotal: 14s\tremaining: 6.17s\n",
            "1388:\tlearn: 0.4692948\ttotal: 14s\tremaining: 6.16s\n",
            "1389:\tlearn: 0.4692741\ttotal: 14s\tremaining: 6.15s\n",
            "1390:\tlearn: 0.4692530\ttotal: 14s\tremaining: 6.14s\n",
            "1391:\tlearn: 0.4692291\ttotal: 14s\tremaining: 6.13s\n",
            "1392:\tlearn: 0.4692116\ttotal: 14.1s\tremaining: 6.13s\n",
            "1393:\tlearn: 0.4691853\ttotal: 14.1s\tremaining: 6.11s\n",
            "1394:\tlearn: 0.4691484\ttotal: 14.1s\tremaining: 6.1s\n",
            "1395:\tlearn: 0.4691181\ttotal: 14.1s\tremaining: 6.1s\n",
            "1396:\tlearn: 0.4690943\ttotal: 14.1s\tremaining: 6.09s\n",
            "1397:\tlearn: 0.4690684\ttotal: 14.1s\tremaining: 6.08s\n",
            "1398:\tlearn: 0.4690416\ttotal: 14.1s\tremaining: 6.07s\n",
            "1399:\tlearn: 0.4690154\ttotal: 14.1s\tremaining: 6.06s\n",
            "1400:\tlearn: 0.4689759\ttotal: 14.1s\tremaining: 6.05s\n",
            "1401:\tlearn: 0.4689371\ttotal: 14.2s\tremaining: 6.04s\n",
            "1402:\tlearn: 0.4689125\ttotal: 14.2s\tremaining: 6.03s\n",
            "1403:\tlearn: 0.4688757\ttotal: 14.2s\tremaining: 6.02s\n",
            "1404:\tlearn: 0.4688415\ttotal: 14.2s\tremaining: 6.01s\n",
            "1405:\tlearn: 0.4687984\ttotal: 14.2s\tremaining: 6s\n",
            "1406:\tlearn: 0.4687686\ttotal: 14.2s\tremaining: 5.99s\n",
            "1407:\tlearn: 0.4687185\ttotal: 14.2s\tremaining: 5.98s\n",
            "1408:\tlearn: 0.4686955\ttotal: 14.2s\tremaining: 5.97s\n",
            "1409:\tlearn: 0.4686670\ttotal: 14.2s\tremaining: 5.96s\n",
            "1410:\tlearn: 0.4686525\ttotal: 14.2s\tremaining: 5.95s\n",
            "1411:\tlearn: 0.4686260\ttotal: 14.3s\tremaining: 5.93s\n",
            "1412:\tlearn: 0.4685940\ttotal: 14.3s\tremaining: 5.92s\n",
            "1413:\tlearn: 0.4685520\ttotal: 14.3s\tremaining: 5.92s\n",
            "1414:\tlearn: 0.4685214\ttotal: 14.3s\tremaining: 5.91s\n",
            "1415:\tlearn: 0.4685001\ttotal: 14.3s\tremaining: 5.9s\n",
            "1416:\tlearn: 0.4684622\ttotal: 14.3s\tremaining: 5.88s\n",
            "1417:\tlearn: 0.4684489\ttotal: 14.3s\tremaining: 5.88s\n",
            "1418:\tlearn: 0.4684219\ttotal: 14.3s\tremaining: 5.86s\n",
            "1419:\tlearn: 0.4683957\ttotal: 14.3s\tremaining: 5.85s\n",
            "1420:\tlearn: 0.4683754\ttotal: 14.3s\tremaining: 5.84s\n",
            "1421:\tlearn: 0.4683516\ttotal: 14.3s\tremaining: 5.83s\n",
            "1422:\tlearn: 0.4683053\ttotal: 14.4s\tremaining: 5.82s\n",
            "1423:\tlearn: 0.4682743\ttotal: 14.4s\tremaining: 5.81s\n",
            "1424:\tlearn: 0.4682537\ttotal: 14.4s\tremaining: 5.8s\n",
            "1425:\tlearn: 0.4682322\ttotal: 14.4s\tremaining: 5.79s\n",
            "1426:\tlearn: 0.4682141\ttotal: 14.4s\tremaining: 5.78s\n",
            "1427:\tlearn: 0.4681887\ttotal: 14.4s\tremaining: 5.77s\n",
            "1428:\tlearn: 0.4681712\ttotal: 14.4s\tremaining: 5.76s\n",
            "1429:\tlearn: 0.4681294\ttotal: 14.4s\tremaining: 5.75s\n",
            "1430:\tlearn: 0.4681012\ttotal: 14.4s\tremaining: 5.74s\n",
            "1431:\tlearn: 0.4680857\ttotal: 14.4s\tremaining: 5.73s\n",
            "1432:\tlearn: 0.4680617\ttotal: 14.4s\tremaining: 5.72s\n",
            "1433:\tlearn: 0.4680413\ttotal: 14.5s\tremaining: 5.71s\n",
            "1434:\tlearn: 0.4680157\ttotal: 14.5s\tremaining: 5.7s\n",
            "1435:\tlearn: 0.4679792\ttotal: 14.5s\tremaining: 5.69s\n",
            "1436:\tlearn: 0.4679484\ttotal: 14.5s\tremaining: 5.68s\n",
            "1437:\tlearn: 0.4679251\ttotal: 14.5s\tremaining: 5.67s\n",
            "1438:\tlearn: 0.4678939\ttotal: 14.5s\tremaining: 5.66s\n",
            "1439:\tlearn: 0.4678637\ttotal: 14.5s\tremaining: 5.65s\n",
            "1440:\tlearn: 0.4678473\ttotal: 14.5s\tremaining: 5.64s\n",
            "1441:\tlearn: 0.4678117\ttotal: 14.6s\tremaining: 5.63s\n",
            "1442:\tlearn: 0.4677812\ttotal: 14.6s\tremaining: 5.62s\n",
            "1443:\tlearn: 0.4677530\ttotal: 14.6s\tremaining: 5.61s\n",
            "1444:\tlearn: 0.4677092\ttotal: 14.6s\tremaining: 5.6s\n",
            "1445:\tlearn: 0.4676877\ttotal: 14.6s\tremaining: 5.59s\n",
            "1446:\tlearn: 0.4676562\ttotal: 14.6s\tremaining: 5.58s\n",
            "1447:\tlearn: 0.4676273\ttotal: 14.6s\tremaining: 5.57s\n",
            "1448:\tlearn: 0.4676074\ttotal: 14.6s\tremaining: 5.56s\n",
            "1449:\tlearn: 0.4675871\ttotal: 14.6s\tremaining: 5.55s\n",
            "1450:\tlearn: 0.4675627\ttotal: 14.6s\tremaining: 5.54s\n",
            "1451:\tlearn: 0.4675359\ttotal: 14.6s\tremaining: 5.53s\n",
            "1452:\tlearn: 0.4675106\ttotal: 14.7s\tremaining: 5.51s\n",
            "1453:\tlearn: 0.4674995\ttotal: 14.7s\tremaining: 5.51s\n",
            "1454:\tlearn: 0.4674704\ttotal: 14.7s\tremaining: 5.5s\n",
            "1455:\tlearn: 0.4674380\ttotal: 14.7s\tremaining: 5.49s\n",
            "1456:\tlearn: 0.4674195\ttotal: 14.7s\tremaining: 5.48s\n",
            "1457:\tlearn: 0.4674012\ttotal: 14.7s\tremaining: 5.47s\n",
            "1458:\tlearn: 0.4673764\ttotal: 14.7s\tremaining: 5.46s\n",
            "1459:\tlearn: 0.4673564\ttotal: 14.7s\tremaining: 5.45s\n",
            "1460:\tlearn: 0.4673372\ttotal: 14.7s\tremaining: 5.44s\n",
            "1461:\tlearn: 0.4673007\ttotal: 14.7s\tremaining: 5.43s\n",
            "1462:\tlearn: 0.4672673\ttotal: 14.8s\tremaining: 5.42s\n",
            "1463:\tlearn: 0.4672233\ttotal: 14.8s\tremaining: 5.41s\n",
            "1464:\tlearn: 0.4672001\ttotal: 14.8s\tremaining: 5.39s\n",
            "1465:\tlearn: 0.4671656\ttotal: 14.8s\tremaining: 5.38s\n",
            "1466:\tlearn: 0.4671365\ttotal: 14.8s\tremaining: 5.37s\n",
            "1467:\tlearn: 0.4671109\ttotal: 14.8s\tremaining: 5.36s\n",
            "1468:\tlearn: 0.4670898\ttotal: 14.8s\tremaining: 5.35s\n",
            "1469:\tlearn: 0.4670725\ttotal: 14.8s\tremaining: 5.34s\n",
            "1470:\tlearn: 0.4670261\ttotal: 14.8s\tremaining: 5.33s\n",
            "1471:\tlearn: 0.4669982\ttotal: 14.8s\tremaining: 5.32s\n",
            "1472:\tlearn: 0.4669781\ttotal: 14.8s\tremaining: 5.31s\n",
            "1473:\tlearn: 0.4669552\ttotal: 14.9s\tremaining: 5.3s\n",
            "1474:\tlearn: 0.4669434\ttotal: 14.9s\tremaining: 5.29s\n",
            "1475:\tlearn: 0.4669180\ttotal: 14.9s\tremaining: 5.28s\n",
            "1476:\tlearn: 0.4668852\ttotal: 14.9s\tremaining: 5.28s\n",
            "1477:\tlearn: 0.4668586\ttotal: 14.9s\tremaining: 5.26s\n",
            "1478:\tlearn: 0.4668337\ttotal: 14.9s\tremaining: 5.25s\n",
            "1479:\tlearn: 0.4668003\ttotal: 14.9s\tremaining: 5.25s\n",
            "1480:\tlearn: 0.4667769\ttotal: 14.9s\tremaining: 5.23s\n",
            "1481:\tlearn: 0.4667440\ttotal: 14.9s\tremaining: 5.22s\n",
            "1482:\tlearn: 0.4666999\ttotal: 15s\tremaining: 5.21s\n",
            "1483:\tlearn: 0.4666727\ttotal: 15s\tremaining: 5.2s\n",
            "1484:\tlearn: 0.4666554\ttotal: 15s\tremaining: 5.19s\n",
            "1485:\tlearn: 0.4666212\ttotal: 15s\tremaining: 5.18s\n",
            "1486:\tlearn: 0.4665999\ttotal: 15s\tremaining: 5.17s\n",
            "1487:\tlearn: 0.4665822\ttotal: 15s\tremaining: 5.16s\n",
            "1488:\tlearn: 0.4665429\ttotal: 15s\tremaining: 5.15s\n",
            "1489:\tlearn: 0.4665199\ttotal: 15s\tremaining: 5.14s\n",
            "1490:\tlearn: 0.4665070\ttotal: 15s\tremaining: 5.13s\n",
            "1491:\tlearn: 0.4664754\ttotal: 15s\tremaining: 5.12s\n",
            "1492:\tlearn: 0.4664537\ttotal: 15.1s\tremaining: 5.11s\n",
            "1493:\tlearn: 0.4664217\ttotal: 15.1s\tremaining: 5.1s\n",
            "1494:\tlearn: 0.4663988\ttotal: 15.1s\tremaining: 5.09s\n",
            "1495:\tlearn: 0.4663697\ttotal: 15.1s\tremaining: 5.08s\n",
            "1496:\tlearn: 0.4663281\ttotal: 15.1s\tremaining: 5.07s\n",
            "1497:\tlearn: 0.4663021\ttotal: 15.1s\tremaining: 5.07s\n",
            "1498:\tlearn: 0.4662641\ttotal: 15.1s\tremaining: 5.06s\n",
            "1499:\tlearn: 0.4662480\ttotal: 15.1s\tremaining: 5.05s\n",
            "1500:\tlearn: 0.4662152\ttotal: 15.1s\tremaining: 5.04s\n",
            "1501:\tlearn: 0.4661850\ttotal: 15.2s\tremaining: 5.03s\n",
            "1502:\tlearn: 0.4661604\ttotal: 15.2s\tremaining: 5.01s\n",
            "1503:\tlearn: 0.4661264\ttotal: 15.2s\tremaining: 5s\n",
            "1504:\tlearn: 0.4660981\ttotal: 15.2s\tremaining: 5s\n",
            "1505:\tlearn: 0.4660520\ttotal: 15.2s\tremaining: 4.99s\n",
            "1506:\tlearn: 0.4660421\ttotal: 15.2s\tremaining: 4.97s\n",
            "1507:\tlearn: 0.4660059\ttotal: 15.2s\tremaining: 4.96s\n",
            "1508:\tlearn: 0.4659686\ttotal: 15.2s\tremaining: 4.95s\n",
            "1509:\tlearn: 0.4659468\ttotal: 15.2s\tremaining: 4.94s\n",
            "1510:\tlearn: 0.4659193\ttotal: 15.2s\tremaining: 4.93s\n",
            "1511:\tlearn: 0.4658990\ttotal: 15.3s\tremaining: 4.92s\n",
            "1512:\tlearn: 0.4658659\ttotal: 15.3s\tremaining: 4.91s\n",
            "1513:\tlearn: 0.4658301\ttotal: 15.3s\tremaining: 4.9s\n",
            "1514:\tlearn: 0.4658157\ttotal: 15.3s\tremaining: 4.89s\n",
            "1515:\tlearn: 0.4657886\ttotal: 15.3s\tremaining: 4.88s\n",
            "1516:\tlearn: 0.4657692\ttotal: 15.3s\tremaining: 4.87s\n",
            "1517:\tlearn: 0.4657469\ttotal: 15.3s\tremaining: 4.86s\n",
            "1518:\tlearn: 0.4657222\ttotal: 15.3s\tremaining: 4.85s\n",
            "1519:\tlearn: 0.4656836\ttotal: 15.3s\tremaining: 4.84s\n",
            "1520:\tlearn: 0.4656513\ttotal: 15.3s\tremaining: 4.83s\n",
            "1521:\tlearn: 0.4656210\ttotal: 15.4s\tremaining: 4.82s\n",
            "1522:\tlearn: 0.4655983\ttotal: 15.4s\tremaining: 4.81s\n",
            "1523:\tlearn: 0.4655778\ttotal: 15.4s\tremaining: 4.8s\n",
            "1524:\tlearn: 0.4655550\ttotal: 15.4s\tremaining: 4.79s\n",
            "1525:\tlearn: 0.4655472\ttotal: 15.4s\tremaining: 4.78s\n",
            "1526:\tlearn: 0.4655162\ttotal: 15.4s\tremaining: 4.77s\n",
            "1527:\tlearn: 0.4654925\ttotal: 15.4s\tremaining: 4.76s\n",
            "1528:\tlearn: 0.4654651\ttotal: 15.4s\tremaining: 4.75s\n",
            "1529:\tlearn: 0.4654456\ttotal: 15.4s\tremaining: 4.74s\n",
            "1530:\tlearn: 0.4654221\ttotal: 15.4s\tremaining: 4.73s\n",
            "1531:\tlearn: 0.4653960\ttotal: 15.5s\tremaining: 4.72s\n",
            "1532:\tlearn: 0.4653662\ttotal: 15.5s\tremaining: 4.71s\n",
            "1533:\tlearn: 0.4653476\ttotal: 15.5s\tremaining: 4.7s\n",
            "1534:\tlearn: 0.4653219\ttotal: 15.5s\tremaining: 4.69s\n",
            "1535:\tlearn: 0.4652828\ttotal: 15.5s\tremaining: 4.68s\n",
            "1536:\tlearn: 0.4652539\ttotal: 15.5s\tremaining: 4.67s\n",
            "1537:\tlearn: 0.4652282\ttotal: 15.5s\tremaining: 4.66s\n",
            "1538:\tlearn: 0.4651973\ttotal: 15.5s\tremaining: 4.65s\n",
            "1539:\tlearn: 0.4651782\ttotal: 15.5s\tremaining: 4.64s\n",
            "1540:\tlearn: 0.4651500\ttotal: 15.5s\tremaining: 4.63s\n",
            "1541:\tlearn: 0.4651202\ttotal: 15.6s\tremaining: 4.62s\n",
            "1542:\tlearn: 0.4650882\ttotal: 15.6s\tremaining: 4.61s\n",
            "1543:\tlearn: 0.4650698\ttotal: 15.6s\tremaining: 4.6s\n",
            "1544:\tlearn: 0.4650410\ttotal: 15.6s\tremaining: 4.59s\n",
            "1545:\tlearn: 0.4649988\ttotal: 15.6s\tremaining: 4.58s\n",
            "1546:\tlearn: 0.4649593\ttotal: 15.6s\tremaining: 4.57s\n",
            "1547:\tlearn: 0.4649256\ttotal: 15.6s\tremaining: 4.56s\n",
            "1548:\tlearn: 0.4649111\ttotal: 15.6s\tremaining: 4.55s\n",
            "1549:\tlearn: 0.4648864\ttotal: 15.6s\tremaining: 4.54s\n",
            "1550:\tlearn: 0.4648557\ttotal: 15.6s\tremaining: 4.53s\n",
            "1551:\tlearn: 0.4648250\ttotal: 15.6s\tremaining: 4.51s\n",
            "1552:\tlearn: 0.4648018\ttotal: 15.7s\tremaining: 4.5s\n",
            "1553:\tlearn: 0.4647741\ttotal: 15.7s\tremaining: 4.5s\n",
            "1554:\tlearn: 0.4647437\ttotal: 15.7s\tremaining: 4.48s\n",
            "1555:\tlearn: 0.4647135\ttotal: 15.7s\tremaining: 4.47s\n",
            "1556:\tlearn: 0.4646826\ttotal: 15.7s\tremaining: 4.46s\n",
            "1557:\tlearn: 0.4646653\ttotal: 15.7s\tremaining: 4.45s\n",
            "1558:\tlearn: 0.4646320\ttotal: 15.7s\tremaining: 4.44s\n",
            "1559:\tlearn: 0.4646146\ttotal: 15.7s\tremaining: 4.43s\n",
            "1560:\tlearn: 0.4645796\ttotal: 15.7s\tremaining: 4.42s\n",
            "1561:\tlearn: 0.4645603\ttotal: 15.7s\tremaining: 4.42s\n",
            "1562:\tlearn: 0.4645405\ttotal: 15.8s\tremaining: 4.4s\n",
            "1563:\tlearn: 0.4645140\ttotal: 15.8s\tremaining: 4.39s\n",
            "1564:\tlearn: 0.4644906\ttotal: 15.8s\tremaining: 4.38s\n",
            "1565:\tlearn: 0.4644692\ttotal: 15.8s\tremaining: 4.37s\n",
            "1566:\tlearn: 0.4644386\ttotal: 15.8s\tremaining: 4.36s\n",
            "1567:\tlearn: 0.4644071\ttotal: 15.8s\tremaining: 4.35s\n",
            "1568:\tlearn: 0.4643823\ttotal: 15.8s\tremaining: 4.34s\n",
            "1569:\tlearn: 0.4643502\ttotal: 15.8s\tremaining: 4.33s\n",
            "1570:\tlearn: 0.4643336\ttotal: 15.8s\tremaining: 4.32s\n",
            "1571:\tlearn: 0.4643177\ttotal: 15.8s\tremaining: 4.31s\n",
            "1572:\tlearn: 0.4642970\ttotal: 15.8s\tremaining: 4.3s\n",
            "1573:\tlearn: 0.4642867\ttotal: 15.9s\tremaining: 4.29s\n",
            "1574:\tlearn: 0.4642474\ttotal: 15.9s\tremaining: 4.28s\n",
            "1575:\tlearn: 0.4642213\ttotal: 15.9s\tremaining: 4.27s\n",
            "1576:\tlearn: 0.4641939\ttotal: 15.9s\tremaining: 4.26s\n",
            "1577:\tlearn: 0.4641653\ttotal: 15.9s\tremaining: 4.25s\n",
            "1578:\tlearn: 0.4641357\ttotal: 15.9s\tremaining: 4.24s\n",
            "1579:\tlearn: 0.4640984\ttotal: 15.9s\tremaining: 4.23s\n",
            "1580:\tlearn: 0.4640619\ttotal: 15.9s\tremaining: 4.22s\n",
            "1581:\tlearn: 0.4640485\ttotal: 15.9s\tremaining: 4.21s\n",
            "1582:\tlearn: 0.4640120\ttotal: 16s\tremaining: 4.2s\n",
            "1583:\tlearn: 0.4639951\ttotal: 16s\tremaining: 4.19s\n",
            "1584:\tlearn: 0.4639651\ttotal: 16s\tremaining: 4.18s\n",
            "1585:\tlearn: 0.4639311\ttotal: 16s\tremaining: 4.17s\n",
            "1586:\tlearn: 0.4639028\ttotal: 16s\tremaining: 4.16s\n",
            "1587:\tlearn: 0.4638853\ttotal: 16s\tremaining: 4.15s\n",
            "1588:\tlearn: 0.4638616\ttotal: 16s\tremaining: 4.14s\n",
            "1589:\tlearn: 0.4638327\ttotal: 16s\tremaining: 4.13s\n",
            "1590:\tlearn: 0.4638010\ttotal: 16s\tremaining: 4.12s\n",
            "1591:\tlearn: 0.4637744\ttotal: 16s\tremaining: 4.11s\n",
            "1592:\tlearn: 0.4637419\ttotal: 16.1s\tremaining: 4.1s\n",
            "1593:\tlearn: 0.4637317\ttotal: 16.1s\tremaining: 4.09s\n",
            "1594:\tlearn: 0.4637019\ttotal: 16.1s\tremaining: 4.08s\n",
            "1595:\tlearn: 0.4636779\ttotal: 16.1s\tremaining: 4.07s\n",
            "1596:\tlearn: 0.4636506\ttotal: 16.1s\tremaining: 4.06s\n",
            "1597:\tlearn: 0.4636276\ttotal: 16.1s\tremaining: 4.05s\n",
            "1598:\tlearn: 0.4635981\ttotal: 16.1s\tremaining: 4.04s\n",
            "1599:\tlearn: 0.4635698\ttotal: 16.1s\tremaining: 4.04s\n",
            "1600:\tlearn: 0.4635480\ttotal: 16.2s\tremaining: 4.03s\n",
            "1601:\tlearn: 0.4635119\ttotal: 16.2s\tremaining: 4.01s\n",
            "1602:\tlearn: 0.4634965\ttotal: 16.2s\tremaining: 4s\n",
            "1603:\tlearn: 0.4634774\ttotal: 16.2s\tremaining: 4s\n",
            "1604:\tlearn: 0.4634493\ttotal: 16.2s\tremaining: 3.98s\n",
            "1605:\tlearn: 0.4634243\ttotal: 16.2s\tremaining: 3.97s\n",
            "1606:\tlearn: 0.4634168\ttotal: 16.2s\tremaining: 3.96s\n",
            "1607:\tlearn: 0.4634028\ttotal: 16.2s\tremaining: 3.95s\n",
            "1608:\tlearn: 0.4633709\ttotal: 16.2s\tremaining: 3.94s\n",
            "1609:\tlearn: 0.4633532\ttotal: 16.2s\tremaining: 3.93s\n",
            "1610:\tlearn: 0.4633239\ttotal: 16.2s\tremaining: 3.92s\n",
            "1611:\tlearn: 0.4632901\ttotal: 16.3s\tremaining: 3.91s\n",
            "1612:\tlearn: 0.4632652\ttotal: 16.3s\tremaining: 3.9s\n",
            "1613:\tlearn: 0.4632440\ttotal: 16.3s\tremaining: 3.89s\n",
            "1614:\tlearn: 0.4632132\ttotal: 16.3s\tremaining: 3.88s\n",
            "1615:\tlearn: 0.4631833\ttotal: 16.3s\tremaining: 3.87s\n",
            "1616:\tlearn: 0.4631562\ttotal: 16.3s\tremaining: 3.86s\n",
            "1617:\tlearn: 0.4631379\ttotal: 16.3s\tremaining: 3.85s\n",
            "1618:\tlearn: 0.4631140\ttotal: 16.3s\tremaining: 3.84s\n",
            "1619:\tlearn: 0.4630858\ttotal: 16.3s\tremaining: 3.83s\n",
            "1620:\tlearn: 0.4630530\ttotal: 16.3s\tremaining: 3.82s\n",
            "1621:\tlearn: 0.4630237\ttotal: 16.4s\tremaining: 3.81s\n",
            "1622:\tlearn: 0.4630085\ttotal: 16.4s\tremaining: 3.8s\n",
            "1623:\tlearn: 0.4629708\ttotal: 16.4s\tremaining: 3.79s\n",
            "1624:\tlearn: 0.4629361\ttotal: 16.4s\tremaining: 3.78s\n",
            "1625:\tlearn: 0.4629093\ttotal: 16.4s\tremaining: 3.77s\n",
            "1626:\tlearn: 0.4628768\ttotal: 16.4s\tremaining: 3.76s\n",
            "1627:\tlearn: 0.4628558\ttotal: 16.4s\tremaining: 3.75s\n",
            "1628:\tlearn: 0.4628306\ttotal: 16.4s\tremaining: 3.74s\n",
            "1629:\tlearn: 0.4628120\ttotal: 16.4s\tremaining: 3.73s\n",
            "1630:\tlearn: 0.4627960\ttotal: 16.4s\tremaining: 3.72s\n",
            "1631:\tlearn: 0.4627715\ttotal: 16.4s\tremaining: 3.71s\n",
            "1632:\tlearn: 0.4627543\ttotal: 16.5s\tremaining: 3.7s\n",
            "1633:\tlearn: 0.4627152\ttotal: 16.5s\tremaining: 3.69s\n",
            "1634:\tlearn: 0.4626906\ttotal: 16.5s\tremaining: 3.68s\n",
            "1635:\tlearn: 0.4626609\ttotal: 16.5s\tremaining: 3.67s\n",
            "1636:\tlearn: 0.4626352\ttotal: 16.5s\tremaining: 3.66s\n",
            "1637:\tlearn: 0.4626218\ttotal: 16.5s\tremaining: 3.65s\n",
            "1638:\tlearn: 0.4625929\ttotal: 16.5s\tremaining: 3.64s\n",
            "1639:\tlearn: 0.4625691\ttotal: 16.5s\tremaining: 3.63s\n",
            "1640:\tlearn: 0.4625390\ttotal: 16.5s\tremaining: 3.62s\n",
            "1641:\tlearn: 0.4625075\ttotal: 16.6s\tremaining: 3.61s\n",
            "1642:\tlearn: 0.4624720\ttotal: 16.6s\tremaining: 3.6s\n",
            "1643:\tlearn: 0.4624509\ttotal: 16.6s\tremaining: 3.59s\n",
            "1644:\tlearn: 0.4624190\ttotal: 16.6s\tremaining: 3.58s\n",
            "1645:\tlearn: 0.4623975\ttotal: 16.6s\tremaining: 3.57s\n",
            "1646:\tlearn: 0.4623605\ttotal: 16.6s\tremaining: 3.56s\n",
            "1647:\tlearn: 0.4623297\ttotal: 16.6s\tremaining: 3.55s\n",
            "1648:\tlearn: 0.4622981\ttotal: 16.6s\tremaining: 3.54s\n",
            "1649:\tlearn: 0.4622686\ttotal: 16.6s\tremaining: 3.53s\n",
            "1650:\tlearn: 0.4622340\ttotal: 16.6s\tremaining: 3.52s\n",
            "1651:\tlearn: 0.4622102\ttotal: 16.6s\tremaining: 3.51s\n",
            "1652:\tlearn: 0.4621810\ttotal: 16.7s\tremaining: 3.5s\n",
            "1653:\tlearn: 0.4621528\ttotal: 16.7s\tremaining: 3.49s\n",
            "1654:\tlearn: 0.4621293\ttotal: 16.7s\tremaining: 3.48s\n",
            "1655:\tlearn: 0.4620856\ttotal: 16.7s\tremaining: 3.47s\n",
            "1656:\tlearn: 0.4620475\ttotal: 16.7s\tremaining: 3.46s\n",
            "1657:\tlearn: 0.4620248\ttotal: 16.7s\tremaining: 3.45s\n",
            "1658:\tlearn: 0.4619957\ttotal: 16.7s\tremaining: 3.44s\n",
            "1659:\tlearn: 0.4619847\ttotal: 16.7s\tremaining: 3.43s\n",
            "1660:\tlearn: 0.4619506\ttotal: 16.7s\tremaining: 3.42s\n",
            "1661:\tlearn: 0.4619203\ttotal: 16.8s\tremaining: 3.41s\n",
            "1662:\tlearn: 0.4619086\ttotal: 16.8s\tremaining: 3.4s\n",
            "1663:\tlearn: 0.4618720\ttotal: 16.8s\tremaining: 3.39s\n",
            "1664:\tlearn: 0.4618494\ttotal: 16.8s\tremaining: 3.38s\n",
            "1665:\tlearn: 0.4618200\ttotal: 16.8s\tremaining: 3.37s\n",
            "1666:\tlearn: 0.4617974\ttotal: 16.8s\tremaining: 3.36s\n",
            "1667:\tlearn: 0.4617798\ttotal: 16.8s\tremaining: 3.35s\n",
            "1668:\tlearn: 0.4617577\ttotal: 16.8s\tremaining: 3.34s\n",
            "1669:\tlearn: 0.4617438\ttotal: 16.8s\tremaining: 3.33s\n",
            "1670:\tlearn: 0.4617184\ttotal: 16.8s\tremaining: 3.31s\n",
            "1671:\tlearn: 0.4616763\ttotal: 16.9s\tremaining: 3.31s\n",
            "1672:\tlearn: 0.4616435\ttotal: 16.9s\tremaining: 3.29s\n",
            "1673:\tlearn: 0.4616147\ttotal: 16.9s\tremaining: 3.29s\n",
            "1674:\tlearn: 0.4615812\ttotal: 16.9s\tremaining: 3.27s\n",
            "1675:\tlearn: 0.4615651\ttotal: 16.9s\tremaining: 3.26s\n",
            "1676:\tlearn: 0.4615293\ttotal: 16.9s\tremaining: 3.25s\n",
            "1677:\tlearn: 0.4615068\ttotal: 16.9s\tremaining: 3.24s\n",
            "1678:\tlearn: 0.4614732\ttotal: 16.9s\tremaining: 3.23s\n",
            "1679:\tlearn: 0.4614448\ttotal: 16.9s\tremaining: 3.23s\n",
            "1680:\tlearn: 0.4614190\ttotal: 17s\tremaining: 3.22s\n",
            "1681:\tlearn: 0.4614017\ttotal: 17s\tremaining: 3.21s\n",
            "1682:\tlearn: 0.4613631\ttotal: 17s\tremaining: 3.2s\n",
            "1683:\tlearn: 0.4613469\ttotal: 17s\tremaining: 3.19s\n",
            "1684:\tlearn: 0.4613176\ttotal: 17s\tremaining: 3.17s\n",
            "1685:\tlearn: 0.4612852\ttotal: 17s\tremaining: 3.17s\n",
            "1686:\tlearn: 0.4612557\ttotal: 17s\tremaining: 3.15s\n",
            "1687:\tlearn: 0.4612195\ttotal: 17s\tremaining: 3.15s\n",
            "1688:\tlearn: 0.4612082\ttotal: 17s\tremaining: 3.13s\n",
            "1689:\tlearn: 0.4611751\ttotal: 17s\tremaining: 3.13s\n",
            "1690:\tlearn: 0.4611499\ttotal: 17s\tremaining: 3.11s\n",
            "1691:\tlearn: 0.4611197\ttotal: 17.1s\tremaining: 3.1s\n",
            "1692:\tlearn: 0.4610963\ttotal: 17.1s\tremaining: 3.1s\n",
            "1693:\tlearn: 0.4610769\ttotal: 17.1s\tremaining: 3.09s\n",
            "1694:\tlearn: 0.4610537\ttotal: 17.1s\tremaining: 3.08s\n",
            "1695:\tlearn: 0.4610203\ttotal: 17.1s\tremaining: 3.07s\n",
            "1696:\tlearn: 0.4609813\ttotal: 17.1s\tremaining: 3.06s\n",
            "1697:\tlearn: 0.4609530\ttotal: 17.1s\tremaining: 3.05s\n",
            "1698:\tlearn: 0.4609310\ttotal: 17.1s\tremaining: 3.04s\n",
            "1699:\tlearn: 0.4609017\ttotal: 17.2s\tremaining: 3.03s\n",
            "1700:\tlearn: 0.4608631\ttotal: 17.2s\tremaining: 3.02s\n",
            "1701:\tlearn: 0.4608309\ttotal: 17.2s\tremaining: 3.01s\n",
            "1702:\tlearn: 0.4608035\ttotal: 17.2s\tremaining: 3s\n",
            "1703:\tlearn: 0.4607851\ttotal: 17.2s\tremaining: 2.98s\n",
            "1704:\tlearn: 0.4607622\ttotal: 17.2s\tremaining: 2.98s\n",
            "1705:\tlearn: 0.4607316\ttotal: 17.2s\tremaining: 2.96s\n",
            "1706:\tlearn: 0.4607218\ttotal: 17.2s\tremaining: 2.96s\n",
            "1707:\tlearn: 0.4607005\ttotal: 17.2s\tremaining: 2.94s\n",
            "1708:\tlearn: 0.4606803\ttotal: 17.2s\tremaining: 2.94s\n",
            "1709:\tlearn: 0.4606618\ttotal: 17.2s\tremaining: 2.92s\n",
            "1710:\tlearn: 0.4606155\ttotal: 17.3s\tremaining: 2.92s\n",
            "1711:\tlearn: 0.4605843\ttotal: 17.3s\tremaining: 2.9s\n",
            "1712:\tlearn: 0.4605462\ttotal: 17.3s\tremaining: 2.89s\n",
            "1713:\tlearn: 0.4605055\ttotal: 17.3s\tremaining: 2.88s\n",
            "1714:\tlearn: 0.4604834\ttotal: 17.3s\tremaining: 2.87s\n",
            "1715:\tlearn: 0.4604655\ttotal: 17.3s\tremaining: 2.86s\n",
            "1716:\tlearn: 0.4604332\ttotal: 17.3s\tremaining: 2.85s\n",
            "1717:\tlearn: 0.4604168\ttotal: 17.3s\tremaining: 2.84s\n",
            "1718:\tlearn: 0.4603923\ttotal: 17.3s\tremaining: 2.83s\n",
            "1719:\tlearn: 0.4603510\ttotal: 17.3s\tremaining: 2.82s\n",
            "1720:\tlearn: 0.4603396\ttotal: 17.4s\tremaining: 2.81s\n",
            "1721:\tlearn: 0.4603300\ttotal: 17.4s\tremaining: 2.8s\n",
            "1722:\tlearn: 0.4602975\ttotal: 17.4s\tremaining: 2.79s\n",
            "1723:\tlearn: 0.4602739\ttotal: 17.4s\tremaining: 2.78s\n",
            "1724:\tlearn: 0.4602549\ttotal: 17.4s\tremaining: 2.77s\n",
            "1725:\tlearn: 0.4602328\ttotal: 17.4s\tremaining: 2.76s\n",
            "1726:\tlearn: 0.4602072\ttotal: 17.4s\tremaining: 2.75s\n",
            "1727:\tlearn: 0.4601834\ttotal: 17.4s\tremaining: 2.74s\n",
            "1728:\tlearn: 0.4601718\ttotal: 17.4s\tremaining: 2.73s\n",
            "1729:\tlearn: 0.4601471\ttotal: 17.4s\tremaining: 2.72s\n",
            "1730:\tlearn: 0.4601176\ttotal: 17.5s\tremaining: 2.71s\n",
            "1731:\tlearn: 0.4600872\ttotal: 17.5s\tremaining: 2.7s\n",
            "1732:\tlearn: 0.4600614\ttotal: 17.5s\tremaining: 2.69s\n",
            "1733:\tlearn: 0.4600265\ttotal: 17.5s\tremaining: 2.68s\n",
            "1734:\tlearn: 0.4600002\ttotal: 17.5s\tremaining: 2.67s\n",
            "1735:\tlearn: 0.4599658\ttotal: 17.5s\tremaining: 2.66s\n",
            "1736:\tlearn: 0.4599578\ttotal: 17.5s\tremaining: 2.65s\n",
            "1737:\tlearn: 0.4599332\ttotal: 17.5s\tremaining: 2.64s\n",
            "1738:\tlearn: 0.4598986\ttotal: 17.5s\tremaining: 2.63s\n",
            "1739:\tlearn: 0.4598696\ttotal: 17.5s\tremaining: 2.62s\n",
            "1740:\tlearn: 0.4598473\ttotal: 17.6s\tremaining: 2.61s\n",
            "1741:\tlearn: 0.4598225\ttotal: 17.6s\tremaining: 2.6s\n",
            "1742:\tlearn: 0.4597935\ttotal: 17.6s\tremaining: 2.59s\n",
            "1743:\tlearn: 0.4597662\ttotal: 17.6s\tremaining: 2.58s\n",
            "1744:\tlearn: 0.4597491\ttotal: 17.6s\tremaining: 2.57s\n",
            "1745:\tlearn: 0.4597307\ttotal: 17.6s\tremaining: 2.56s\n",
            "1746:\tlearn: 0.4596991\ttotal: 17.6s\tremaining: 2.55s\n",
            "1747:\tlearn: 0.4596797\ttotal: 17.6s\tremaining: 2.54s\n",
            "1748:\tlearn: 0.4596644\ttotal: 17.6s\tremaining: 2.53s\n",
            "1749:\tlearn: 0.4596342\ttotal: 17.7s\tremaining: 2.52s\n",
            "1750:\tlearn: 0.4596118\ttotal: 17.7s\tremaining: 2.51s\n",
            "1751:\tlearn: 0.4595890\ttotal: 17.7s\tremaining: 2.5s\n",
            "1752:\tlearn: 0.4595448\ttotal: 17.7s\tremaining: 2.49s\n",
            "1753:\tlearn: 0.4595162\ttotal: 17.7s\tremaining: 2.48s\n",
            "1754:\tlearn: 0.4594911\ttotal: 17.7s\tremaining: 2.47s\n",
            "1755:\tlearn: 0.4594625\ttotal: 17.7s\tremaining: 2.46s\n",
            "1756:\tlearn: 0.4594271\ttotal: 17.7s\tremaining: 2.45s\n",
            "1757:\tlearn: 0.4593923\ttotal: 17.7s\tremaining: 2.44s\n",
            "1758:\tlearn: 0.4593583\ttotal: 17.7s\tremaining: 2.43s\n",
            "1759:\tlearn: 0.4593263\ttotal: 17.8s\tremaining: 2.42s\n",
            "1760:\tlearn: 0.4592879\ttotal: 17.8s\tremaining: 2.41s\n",
            "1761:\tlearn: 0.4592632\ttotal: 17.8s\tremaining: 2.4s\n",
            "1762:\tlearn: 0.4592484\ttotal: 17.8s\tremaining: 2.39s\n",
            "1763:\tlearn: 0.4592255\ttotal: 17.8s\tremaining: 2.38s\n",
            "1764:\tlearn: 0.4592013\ttotal: 17.8s\tremaining: 2.37s\n",
            "1765:\tlearn: 0.4591786\ttotal: 17.8s\tremaining: 2.36s\n",
            "1766:\tlearn: 0.4591546\ttotal: 17.8s\tremaining: 2.35s\n",
            "1767:\tlearn: 0.4591384\ttotal: 17.8s\tremaining: 2.34s\n",
            "1768:\tlearn: 0.4591259\ttotal: 17.8s\tremaining: 2.33s\n",
            "1769:\tlearn: 0.4591003\ttotal: 17.9s\tremaining: 2.32s\n",
            "1770:\tlearn: 0.4590895\ttotal: 17.9s\tremaining: 2.31s\n",
            "1771:\tlearn: 0.4590673\ttotal: 17.9s\tremaining: 2.3s\n",
            "1772:\tlearn: 0.4590398\ttotal: 17.9s\tremaining: 2.29s\n",
            "1773:\tlearn: 0.4590055\ttotal: 17.9s\tremaining: 2.28s\n",
            "1774:\tlearn: 0.4589873\ttotal: 17.9s\tremaining: 2.27s\n",
            "1775:\tlearn: 0.4589556\ttotal: 17.9s\tremaining: 2.26s\n",
            "1776:\tlearn: 0.4589285\ttotal: 17.9s\tremaining: 2.25s\n",
            "1777:\tlearn: 0.4588977\ttotal: 17.9s\tremaining: 2.24s\n",
            "1778:\tlearn: 0.4588849\ttotal: 17.9s\tremaining: 2.23s\n",
            "1779:\tlearn: 0.4588669\ttotal: 17.9s\tremaining: 2.22s\n",
            "1780:\tlearn: 0.4588555\ttotal: 18s\tremaining: 2.21s\n",
            "1781:\tlearn: 0.4588341\ttotal: 18s\tremaining: 2.2s\n",
            "1782:\tlearn: 0.4588177\ttotal: 18s\tremaining: 2.19s\n",
            "1783:\tlearn: 0.4587898\ttotal: 18s\tremaining: 2.18s\n",
            "1784:\tlearn: 0.4587624\ttotal: 18s\tremaining: 2.17s\n",
            "1785:\tlearn: 0.4587311\ttotal: 18s\tremaining: 2.16s\n",
            "1786:\tlearn: 0.4587022\ttotal: 18s\tremaining: 2.15s\n",
            "1787:\tlearn: 0.4586786\ttotal: 18s\tremaining: 2.14s\n",
            "1788:\tlearn: 0.4586580\ttotal: 18.1s\tremaining: 2.13s\n",
            "1789:\tlearn: 0.4586384\ttotal: 18.1s\tremaining: 2.12s\n",
            "1790:\tlearn: 0.4586127\ttotal: 18.1s\tremaining: 2.11s\n",
            "1791:\tlearn: 0.4585784\ttotal: 18.1s\tremaining: 2.1s\n",
            "1792:\tlearn: 0.4585627\ttotal: 18.1s\tremaining: 2.09s\n",
            "1793:\tlearn: 0.4585410\ttotal: 18.1s\tremaining: 2.08s\n",
            "1794:\tlearn: 0.4585234\ttotal: 18.1s\tremaining: 2.07s\n",
            "1795:\tlearn: 0.4584781\ttotal: 18.1s\tremaining: 2.06s\n",
            "1796:\tlearn: 0.4584605\ttotal: 18.1s\tremaining: 2.05s\n",
            "1797:\tlearn: 0.4584311\ttotal: 18.1s\tremaining: 2.04s\n",
            "1798:\tlearn: 0.4584030\ttotal: 18.2s\tremaining: 2.03s\n",
            "1799:\tlearn: 0.4583786\ttotal: 18.2s\tremaining: 2.02s\n",
            "1800:\tlearn: 0.4583514\ttotal: 18.2s\tremaining: 2.01s\n",
            "1801:\tlearn: 0.4583156\ttotal: 18.2s\tremaining: 2s\n",
            "1802:\tlearn: 0.4582957\ttotal: 18.2s\tremaining: 1.99s\n",
            "1803:\tlearn: 0.4582641\ttotal: 18.2s\tremaining: 1.98s\n",
            "1804:\tlearn: 0.4582598\ttotal: 18.2s\tremaining: 1.97s\n",
            "1805:\tlearn: 0.4582335\ttotal: 18.2s\tremaining: 1.96s\n",
            "1806:\tlearn: 0.4582038\ttotal: 18.2s\tremaining: 1.95s\n",
            "1807:\tlearn: 0.4581754\ttotal: 18.3s\tremaining: 1.94s\n",
            "1808:\tlearn: 0.4581552\ttotal: 18.3s\tremaining: 1.93s\n",
            "1809:\tlearn: 0.4581273\ttotal: 18.3s\tremaining: 1.92s\n",
            "1810:\tlearn: 0.4581171\ttotal: 18.3s\tremaining: 1.91s\n",
            "1811:\tlearn: 0.4581016\ttotal: 18.3s\tremaining: 1.9s\n",
            "1812:\tlearn: 0.4580754\ttotal: 18.3s\tremaining: 1.89s\n",
            "1813:\tlearn: 0.4580538\ttotal: 18.3s\tremaining: 1.88s\n",
            "1814:\tlearn: 0.4580260\ttotal: 18.3s\tremaining: 1.87s\n",
            "1815:\tlearn: 0.4580001\ttotal: 18.3s\tremaining: 1.86s\n",
            "1816:\tlearn: 0.4579822\ttotal: 18.3s\tremaining: 1.85s\n",
            "1817:\tlearn: 0.4579482\ttotal: 18.3s\tremaining: 1.84s\n",
            "1818:\tlearn: 0.4579260\ttotal: 18.4s\tremaining: 1.83s\n",
            "1819:\tlearn: 0.4578982\ttotal: 18.4s\tremaining: 1.82s\n",
            "1820:\tlearn: 0.4578509\ttotal: 18.4s\tremaining: 1.81s\n",
            "1821:\tlearn: 0.4578322\ttotal: 18.4s\tremaining: 1.8s\n",
            "1822:\tlearn: 0.4578051\ttotal: 18.4s\tremaining: 1.79s\n",
            "1823:\tlearn: 0.4577739\ttotal: 18.4s\tremaining: 1.78s\n",
            "1824:\tlearn: 0.4577700\ttotal: 18.4s\tremaining: 1.77s\n",
            "1825:\tlearn: 0.4577383\ttotal: 18.4s\tremaining: 1.76s\n",
            "1826:\tlearn: 0.4577262\ttotal: 18.4s\tremaining: 1.75s\n",
            "1827:\tlearn: 0.4576999\ttotal: 18.5s\tremaining: 1.74s\n",
            "1828:\tlearn: 0.4576671\ttotal: 18.5s\tremaining: 1.73s\n",
            "1829:\tlearn: 0.4576343\ttotal: 18.5s\tremaining: 1.72s\n",
            "1830:\tlearn: 0.4576075\ttotal: 18.5s\tremaining: 1.71s\n",
            "1831:\tlearn: 0.4575845\ttotal: 18.5s\tremaining: 1.7s\n",
            "1832:\tlearn: 0.4575653\ttotal: 18.5s\tremaining: 1.69s\n",
            "1833:\tlearn: 0.4575399\ttotal: 18.5s\tremaining: 1.68s\n",
            "1834:\tlearn: 0.4575182\ttotal: 18.5s\tremaining: 1.67s\n",
            "1835:\tlearn: 0.4575089\ttotal: 18.5s\tremaining: 1.66s\n",
            "1836:\tlearn: 0.4574751\ttotal: 18.5s\tremaining: 1.65s\n",
            "1837:\tlearn: 0.4574465\ttotal: 18.6s\tremaining: 1.64s\n",
            "1838:\tlearn: 0.4574258\ttotal: 18.6s\tremaining: 1.63s\n",
            "1839:\tlearn: 0.4574014\ttotal: 18.6s\tremaining: 1.61s\n",
            "1840:\tlearn: 0.4573850\ttotal: 18.6s\tremaining: 1.6s\n",
            "1841:\tlearn: 0.4573571\ttotal: 18.6s\tremaining: 1.59s\n",
            "1842:\tlearn: 0.4573287\ttotal: 18.6s\tremaining: 1.58s\n",
            "1843:\tlearn: 0.4573023\ttotal: 18.6s\tremaining: 1.57s\n",
            "1844:\tlearn: 0.4572792\ttotal: 18.6s\tremaining: 1.56s\n",
            "1845:\tlearn: 0.4572467\ttotal: 18.6s\tremaining: 1.55s\n",
            "1846:\tlearn: 0.4572117\ttotal: 18.6s\tremaining: 1.54s\n",
            "1847:\tlearn: 0.4571779\ttotal: 18.7s\tremaining: 1.53s\n",
            "1848:\tlearn: 0.4571520\ttotal: 18.7s\tremaining: 1.52s\n",
            "1849:\tlearn: 0.4571215\ttotal: 18.7s\tremaining: 1.51s\n",
            "1850:\tlearn: 0.4571115\ttotal: 18.7s\tremaining: 1.5s\n",
            "1851:\tlearn: 0.4570758\ttotal: 18.7s\tremaining: 1.49s\n",
            "1852:\tlearn: 0.4570407\ttotal: 18.7s\tremaining: 1.48s\n",
            "1853:\tlearn: 0.4570214\ttotal: 18.7s\tremaining: 1.47s\n",
            "1854:\tlearn: 0.4569942\ttotal: 18.7s\tremaining: 1.46s\n",
            "1855:\tlearn: 0.4569604\ttotal: 18.7s\tremaining: 1.45s\n",
            "1856:\tlearn: 0.4569478\ttotal: 18.7s\tremaining: 1.44s\n",
            "1857:\tlearn: 0.4569147\ttotal: 18.8s\tremaining: 1.43s\n",
            "1858:\tlearn: 0.4568854\ttotal: 18.8s\tremaining: 1.42s\n",
            "1859:\tlearn: 0.4568564\ttotal: 18.8s\tremaining: 1.41s\n",
            "1860:\tlearn: 0.4568205\ttotal: 18.8s\tremaining: 1.4s\n",
            "1861:\tlearn: 0.4567851\ttotal: 18.8s\tremaining: 1.39s\n",
            "1862:\tlearn: 0.4567606\ttotal: 18.8s\tremaining: 1.38s\n",
            "1863:\tlearn: 0.4567341\ttotal: 18.8s\tremaining: 1.37s\n",
            "1864:\tlearn: 0.4567084\ttotal: 18.8s\tremaining: 1.36s\n",
            "1865:\tlearn: 0.4566806\ttotal: 18.8s\tremaining: 1.35s\n",
            "1866:\tlearn: 0.4566559\ttotal: 18.8s\tremaining: 1.34s\n",
            "1867:\tlearn: 0.4566286\ttotal: 18.9s\tremaining: 1.33s\n",
            "1868:\tlearn: 0.4566005\ttotal: 18.9s\tremaining: 1.32s\n",
            "1869:\tlearn: 0.4565794\ttotal: 18.9s\tremaining: 1.31s\n",
            "1870:\tlearn: 0.4565591\ttotal: 18.9s\tremaining: 1.3s\n",
            "1871:\tlearn: 0.4565365\ttotal: 18.9s\tremaining: 1.29s\n",
            "1872:\tlearn: 0.4565201\ttotal: 18.9s\tremaining: 1.28s\n",
            "1873:\tlearn: 0.4564914\ttotal: 18.9s\tremaining: 1.27s\n",
            "1874:\tlearn: 0.4564682\ttotal: 18.9s\tremaining: 1.26s\n",
            "1875:\tlearn: 0.4564299\ttotal: 18.9s\tremaining: 1.25s\n",
            "1876:\tlearn: 0.4563998\ttotal: 18.9s\tremaining: 1.24s\n",
            "1877:\tlearn: 0.4563746\ttotal: 19s\tremaining: 1.23s\n",
            "1878:\tlearn: 0.4563631\ttotal: 19s\tremaining: 1.22s\n",
            "1879:\tlearn: 0.4563381\ttotal: 19s\tremaining: 1.21s\n",
            "1880:\tlearn: 0.4563144\ttotal: 19s\tremaining: 1.2s\n",
            "1881:\tlearn: 0.4562968\ttotal: 19s\tremaining: 1.19s\n",
            "1882:\tlearn: 0.4562730\ttotal: 19s\tremaining: 1.18s\n",
            "1883:\tlearn: 0.4562521\ttotal: 19s\tremaining: 1.17s\n",
            "1884:\tlearn: 0.4562214\ttotal: 19s\tremaining: 1.16s\n",
            "1885:\tlearn: 0.4561930\ttotal: 19.1s\tremaining: 1.15s\n",
            "1886:\tlearn: 0.4561765\ttotal: 19.1s\tremaining: 1.14s\n",
            "1887:\tlearn: 0.4561494\ttotal: 19.1s\tremaining: 1.13s\n",
            "1888:\tlearn: 0.4561206\ttotal: 19.1s\tremaining: 1.12s\n",
            "1889:\tlearn: 0.4561090\ttotal: 19.1s\tremaining: 1.11s\n",
            "1890:\tlearn: 0.4560795\ttotal: 19.1s\tremaining: 1.1s\n",
            "1891:\tlearn: 0.4560548\ttotal: 19.1s\tremaining: 1.09s\n",
            "1892:\tlearn: 0.4560322\ttotal: 19.1s\tremaining: 1.08s\n",
            "1893:\tlearn: 0.4560028\ttotal: 19.1s\tremaining: 1.07s\n",
            "1894:\tlearn: 0.4559606\ttotal: 19.1s\tremaining: 1.06s\n",
            "1895:\tlearn: 0.4559537\ttotal: 19.1s\tremaining: 1.05s\n",
            "1896:\tlearn: 0.4559245\ttotal: 19.2s\tremaining: 1.04s\n",
            "1897:\tlearn: 0.4559141\ttotal: 19.2s\tremaining: 1.03s\n",
            "1898:\tlearn: 0.4558981\ttotal: 19.2s\tremaining: 1.02s\n",
            "1899:\tlearn: 0.4558710\ttotal: 19.2s\tremaining: 1.01s\n",
            "1900:\tlearn: 0.4558380\ttotal: 19.2s\tremaining: 1000ms\n",
            "1901:\tlearn: 0.4558056\ttotal: 19.2s\tremaining: 990ms\n",
            "1902:\tlearn: 0.4557927\ttotal: 19.2s\tremaining: 980ms\n",
            "1903:\tlearn: 0.4557609\ttotal: 19.2s\tremaining: 970ms\n",
            "1904:\tlearn: 0.4557341\ttotal: 19.2s\tremaining: 959ms\n",
            "1905:\tlearn: 0.4557179\ttotal: 19.3s\tremaining: 949ms\n",
            "1906:\tlearn: 0.4557008\ttotal: 19.3s\tremaining: 939ms\n",
            "1907:\tlearn: 0.4556870\ttotal: 19.3s\tremaining: 929ms\n",
            "1908:\tlearn: 0.4556625\ttotal: 19.3s\tremaining: 919ms\n",
            "1909:\tlearn: 0.4556365\ttotal: 19.3s\tremaining: 909ms\n",
            "1910:\tlearn: 0.4556097\ttotal: 19.3s\tremaining: 899ms\n",
            "1911:\tlearn: 0.4555894\ttotal: 19.3s\tremaining: 889ms\n",
            "1912:\tlearn: 0.4555771\ttotal: 19.3s\tremaining: 879ms\n",
            "1913:\tlearn: 0.4555583\ttotal: 19.3s\tremaining: 868ms\n",
            "1914:\tlearn: 0.4555305\ttotal: 19.3s\tremaining: 858ms\n",
            "1915:\tlearn: 0.4555021\ttotal: 19.3s\tremaining: 848ms\n",
            "1916:\tlearn: 0.4554867\ttotal: 19.4s\tremaining: 838ms\n",
            "1917:\tlearn: 0.4554608\ttotal: 19.4s\tremaining: 828ms\n",
            "1918:\tlearn: 0.4554392\ttotal: 19.4s\tremaining: 818ms\n",
            "1919:\tlearn: 0.4554171\ttotal: 19.4s\tremaining: 808ms\n",
            "1920:\tlearn: 0.4553940\ttotal: 19.4s\tremaining: 798ms\n",
            "1921:\tlearn: 0.4553623\ttotal: 19.4s\tremaining: 788ms\n",
            "1922:\tlearn: 0.4553550\ttotal: 19.4s\tremaining: 778ms\n",
            "1923:\tlearn: 0.4553294\ttotal: 19.4s\tremaining: 768ms\n",
            "1924:\tlearn: 0.4553081\ttotal: 19.4s\tremaining: 758ms\n",
            "1925:\tlearn: 0.4552724\ttotal: 19.5s\tremaining: 747ms\n",
            "1926:\tlearn: 0.4552499\ttotal: 19.5s\tremaining: 737ms\n",
            "1927:\tlearn: 0.4552178\ttotal: 19.5s\tremaining: 727ms\n",
            "1928:\tlearn: 0.4551883\ttotal: 19.5s\tremaining: 717ms\n",
            "1929:\tlearn: 0.4551622\ttotal: 19.5s\tremaining: 707ms\n",
            "1930:\tlearn: 0.4551344\ttotal: 19.5s\tremaining: 697ms\n",
            "1931:\tlearn: 0.4551143\ttotal: 19.5s\tremaining: 687ms\n",
            "1932:\tlearn: 0.4550842\ttotal: 19.5s\tremaining: 677ms\n",
            "1933:\tlearn: 0.4550507\ttotal: 19.5s\tremaining: 666ms\n",
            "1934:\tlearn: 0.4550246\ttotal: 19.5s\tremaining: 656ms\n",
            "1935:\tlearn: 0.4549952\ttotal: 19.5s\tremaining: 646ms\n",
            "1936:\tlearn: 0.4549631\ttotal: 19.6s\tremaining: 636ms\n",
            "1937:\tlearn: 0.4549273\ttotal: 19.6s\tremaining: 626ms\n",
            "1938:\tlearn: 0.4549075\ttotal: 19.6s\tremaining: 616ms\n",
            "1939:\tlearn: 0.4548814\ttotal: 19.6s\tremaining: 606ms\n",
            "1940:\tlearn: 0.4548635\ttotal: 19.6s\tremaining: 596ms\n",
            "1941:\tlearn: 0.4548541\ttotal: 19.6s\tremaining: 586ms\n",
            "1942:\tlearn: 0.4548268\ttotal: 19.6s\tremaining: 575ms\n",
            "1943:\tlearn: 0.4547985\ttotal: 19.6s\tremaining: 565ms\n",
            "1944:\tlearn: 0.4547634\ttotal: 19.6s\tremaining: 555ms\n",
            "1945:\tlearn: 0.4547316\ttotal: 19.6s\tremaining: 545ms\n",
            "1946:\tlearn: 0.4547138\ttotal: 19.7s\tremaining: 535ms\n",
            "1947:\tlearn: 0.4546937\ttotal: 19.7s\tremaining: 525ms\n",
            "1948:\tlearn: 0.4546714\ttotal: 19.7s\tremaining: 515ms\n",
            "1949:\tlearn: 0.4546536\ttotal: 19.7s\tremaining: 505ms\n",
            "1950:\tlearn: 0.4546351\ttotal: 19.7s\tremaining: 495ms\n",
            "1951:\tlearn: 0.4546134\ttotal: 19.7s\tremaining: 484ms\n",
            "1952:\tlearn: 0.4545914\ttotal: 19.7s\tremaining: 474ms\n",
            "1953:\tlearn: 0.4545699\ttotal: 19.7s\tremaining: 464ms\n",
            "1954:\tlearn: 0.4545413\ttotal: 19.7s\tremaining: 454ms\n",
            "1955:\tlearn: 0.4545215\ttotal: 19.7s\tremaining: 444ms\n",
            "1956:\tlearn: 0.4544997\ttotal: 19.7s\tremaining: 434ms\n",
            "1957:\tlearn: 0.4544646\ttotal: 19.8s\tremaining: 424ms\n",
            "1958:\tlearn: 0.4544542\ttotal: 19.8s\tremaining: 414ms\n",
            "1959:\tlearn: 0.4544170\ttotal: 19.8s\tremaining: 404ms\n",
            "1960:\tlearn: 0.4543769\ttotal: 19.8s\tremaining: 393ms\n",
            "1961:\tlearn: 0.4543465\ttotal: 19.8s\tremaining: 383ms\n",
            "1962:\tlearn: 0.4543268\ttotal: 19.8s\tremaining: 373ms\n",
            "1963:\tlearn: 0.4543105\ttotal: 19.8s\tremaining: 363ms\n",
            "1964:\tlearn: 0.4542918\ttotal: 19.8s\tremaining: 353ms\n",
            "1965:\tlearn: 0.4542710\ttotal: 19.8s\tremaining: 343ms\n",
            "1966:\tlearn: 0.4542500\ttotal: 19.9s\tremaining: 333ms\n",
            "1967:\tlearn: 0.4542256\ttotal: 19.9s\tremaining: 323ms\n",
            "1968:\tlearn: 0.4541996\ttotal: 19.9s\tremaining: 313ms\n",
            "1969:\tlearn: 0.4541748\ttotal: 19.9s\tremaining: 303ms\n",
            "1970:\tlearn: 0.4541518\ttotal: 19.9s\tremaining: 293ms\n",
            "1971:\tlearn: 0.4541288\ttotal: 19.9s\tremaining: 283ms\n",
            "1972:\tlearn: 0.4541054\ttotal: 19.9s\tremaining: 273ms\n",
            "1973:\tlearn: 0.4540823\ttotal: 19.9s\tremaining: 262ms\n",
            "1974:\tlearn: 0.4540547\ttotal: 19.9s\tremaining: 252ms\n",
            "1975:\tlearn: 0.4540310\ttotal: 19.9s\tremaining: 242ms\n",
            "1976:\tlearn: 0.4539968\ttotal: 20s\tremaining: 232ms\n",
            "1977:\tlearn: 0.4539803\ttotal: 20s\tremaining: 222ms\n",
            "1978:\tlearn: 0.4539677\ttotal: 20s\tremaining: 212ms\n",
            "1979:\tlearn: 0.4539401\ttotal: 20s\tremaining: 202ms\n",
            "1980:\tlearn: 0.4539089\ttotal: 20s\tremaining: 192ms\n",
            "1981:\tlearn: 0.4538907\ttotal: 20s\tremaining: 182ms\n",
            "1982:\tlearn: 0.4538742\ttotal: 20s\tremaining: 172ms\n",
            "1983:\tlearn: 0.4538496\ttotal: 20s\tremaining: 162ms\n",
            "1984:\tlearn: 0.4538158\ttotal: 20s\tremaining: 151ms\n",
            "1985:\tlearn: 0.4538040\ttotal: 20s\tremaining: 141ms\n",
            "1986:\tlearn: 0.4537753\ttotal: 20.1s\tremaining: 131ms\n",
            "1987:\tlearn: 0.4537476\ttotal: 20.1s\tremaining: 121ms\n",
            "1988:\tlearn: 0.4537230\ttotal: 20.1s\tremaining: 111ms\n",
            "1989:\tlearn: 0.4536960\ttotal: 20.1s\tremaining: 101ms\n",
            "1990:\tlearn: 0.4536768\ttotal: 20.1s\tremaining: 90.8ms\n",
            "1991:\tlearn: 0.4536492\ttotal: 20.1s\tremaining: 80.7ms\n",
            "1992:\tlearn: 0.4536390\ttotal: 20.1s\tremaining: 70.6ms\n",
            "1993:\tlearn: 0.4536279\ttotal: 20.1s\tremaining: 60.5ms\n",
            "1994:\tlearn: 0.4536159\ttotal: 20.1s\tremaining: 50.5ms\n",
            "1995:\tlearn: 0.4535909\ttotal: 20.1s\tremaining: 40.4ms\n",
            "1996:\tlearn: 0.4535727\ttotal: 20.2s\tremaining: 30.3ms\n",
            "1997:\tlearn: 0.4535522\ttotal: 20.2s\tremaining: 20.2ms\n",
            "1998:\tlearn: 0.4535323\ttotal: 20.2s\tremaining: 10.1ms\n",
            "1999:\tlearn: 0.4535155\ttotal: 20.2s\tremaining: 0us\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCfyY6arJ3GN"
      },
      "source": [
        "_subModelP(df.FinalP,'MBlendSAvg07.csv')"
      ],
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2zgBy1WgN5h"
      },
      "source": [
        "_subModelP(CBmprdT,'MBlend-CB.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xibu8LcnJ5A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}